<!DOCTYPE html>
<html lang="zh" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/docs/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=docs/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.150.0">
    <meta name="generator" content="Relearn 8.0.1+b23cf6629eada0c2802f34ae4012e04343497862">
    <meta name="description" content="多项式回归 概念 线性回归研究的是一个因变量与一个自变量之间的回归问题。 多项式回归是指在线性回归的基础上，通过增加非线性特征来拟合非线性数据的方法。多项式回归模型可以用一个 n 次多项式函数来近似描述目标变量和输入变量之间的关系。例如，对于只有一个自变量 x 的情况，可以将拟合函数写作： 其中 y 表示目标变量，x 表示自变量， 是模型的参数。模型的目标是通过调整参数来使预测值与真实值的误差最小化。
多项式回归可以通过 Scikit-Learn 的 PolynomialFeatures 类来实现，它可以将原始的自变量数据转化为包含了多项式特征的新自变量数据。这样，我们就可以使用线性回归算法来处理增广后的非线性特征，从而得到多项式回归模型。
拟合实例 生成一个多项式的模拟数据 y=3x&#43;2x**2
import numpy as npimport matplotlib.pyplot as pltx = np.random.uniform(-3, 3, size=100)X = x.reshape(-1, 1)y = 3*x&#43; 2*x**2&#43; np.random.normal(0, 1, size=100)plt.scatter(x, y)plt.show() 如果直接使用线性回归，看一下效果：">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="机器学习实战教程（八）：多项式回归 :: liaomin416100569博客">
    <meta name="twitter:description" content="多项式回归 概念 线性回归研究的是一个因变量与一个自变量之间的回归问题。 多项式回归是指在线性回归的基础上，通过增加非线性特征来拟合非线性数据的方法。多项式回归模型可以用一个 n 次多项式函数来近似描述目标变量和输入变量之间的关系。例如，对于只有一个自变量 x 的情况，可以将拟合函数写作： 其中 y 表示目标变量，x 表示自变量， 是模型的参数。模型的目标是通过调整参数来使预测值与真实值的误差最小化。
多项式回归可以通过 Scikit-Learn 的 PolynomialFeatures 类来实现，它可以将原始的自变量数据转化为包含了多项式特征的新自变量数据。这样，我们就可以使用线性回归算法来处理增广后的非线性特征，从而得到多项式回归模型。
拟合实例 生成一个多项式的模拟数据 y=3x&#43;2x**2
import numpy as npimport matplotlib.pyplot as pltx = np.random.uniform(-3, 3, size=100)X = x.reshape(-1, 1)y = 3*x&#43; 2*x**2&#43; np.random.normal(0, 1, size=100)plt.scatter(x, y)plt.show() 如果直接使用线性回归，看一下效果：">
    <meta property="og:url" content="http://localhost:1313/docs/programming/ai/machine_learning/algorithms/action_08_multinomial-copy/index.html">
    <meta property="og:site_name" content="liaomin416100569博客">
    <meta property="og:title" content="机器学习实战教程（八）：多项式回归 :: liaomin416100569博客">
    <meta property="og:description" content="多项式回归 概念 线性回归研究的是一个因变量与一个自变量之间的回归问题。 多项式回归是指在线性回归的基础上，通过增加非线性特征来拟合非线性数据的方法。多项式回归模型可以用一个 n 次多项式函数来近似描述目标变量和输入变量之间的关系。例如，对于只有一个自变量 x 的情况，可以将拟合函数写作： 其中 y 表示目标变量，x 表示自变量， 是模型的参数。模型的目标是通过调整参数来使预测值与真实值的误差最小化。
多项式回归可以通过 Scikit-Learn 的 PolynomialFeatures 类来实现，它可以将原始的自变量数据转化为包含了多项式特征的新自变量数据。这样，我们就可以使用线性回归算法来处理增广后的非线性特征，从而得到多项式回归模型。
拟合实例 生成一个多项式的模拟数据 y=3x&#43;2x**2
import numpy as npimport matplotlib.pyplot as pltx = np.random.uniform(-3, 3, size=100)X = x.reshape(-1, 1)y = 3*x&#43; 2*x**2&#43; np.random.normal(0, 1, size=100)plt.scatter(x, y)plt.show() 如果直接使用线性回归，看一下效果：">
    <meta property="og:locale" content="zh">
    <meta property="og:type" content="article">
    <meta property="article:section" content="编程开发">
    <meta property="article:published_time" content="2025-09-18T16:55:17+08:00">
    <meta property="article:modified_time" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="name" content="机器学习实战教程（八）：多项式回归 :: liaomin416100569博客">
    <meta itemprop="description" content="多项式回归 概念 线性回归研究的是一个因变量与一个自变量之间的回归问题。 多项式回归是指在线性回归的基础上，通过增加非线性特征来拟合非线性数据的方法。多项式回归模型可以用一个 n 次多项式函数来近似描述目标变量和输入变量之间的关系。例如，对于只有一个自变量 x 的情况，可以将拟合函数写作： 其中 y 表示目标变量，x 表示自变量， 是模型的参数。模型的目标是通过调整参数来使预测值与真实值的误差最小化。
多项式回归可以通过 Scikit-Learn 的 PolynomialFeatures 类来实现，它可以将原始的自变量数据转化为包含了多项式特征的新自变量数据。这样，我们就可以使用线性回归算法来处理增广后的非线性特征，从而得到多项式回归模型。
拟合实例 生成一个多项式的模拟数据 y=3x&#43;2x**2
import numpy as npimport matplotlib.pyplot as pltx = np.random.uniform(-3, 3, size=100)X = x.reshape(-1, 1)y = 3*x&#43; 2*x**2&#43; np.random.normal(0, 1, size=100)plt.scatter(x, y)plt.show() 如果直接使用线性回归，看一下效果：">
    <meta itemprop="datePublished" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="dateModified" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="wordCount" content="858">
    <title>机器学习实战教程（八）：多项式回归 :: liaomin416100569博客</title>
    <link href="/docs/css/auto-complete/auto-complete.min.css?1758336532" rel="stylesheet">
    <script src="/docs/js/auto-complete/auto-complete.min.js?1758336532" defer></script>
    <script src="/docs/js/search-lunr.js?1758336532" defer></script>
    <script src="/docs/js/search.js?1758336532" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/docs/searchindex.en.js?1758336532";
    </script>
    <script src="/docs/js/lunr/lunr.min.js?1758336532" defer></script>
    <script src="/docs/js/lunr/lunr.stemmer.support.min.js?1758336532" defer></script>
    <script src="/docs/js/lunr/lunr.multi.min.js?1758336532" defer></script>
    <script src="/docs/js/lunr/lunr.zh.min.js?1758336532" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['zh'];
    </script>
    <link href="/docs/fonts/fontawesome/css/fontawesome-all.min.css?1758336532" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/docs/fonts/fontawesome/css/fontawesome-all.min.css?1758336532" rel="stylesheet"></noscript>
    <link href="/docs/css/perfect-scrollbar/perfect-scrollbar.min.css?1758336532" rel="stylesheet">
    <link href="/docs/css/theme.css?1758336532" rel="stylesheet">
    <link href="/docs/css/format-html.css?1758336532" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/programming\/ai\/machine_learning\/algorithms\/action_08_multinomial-copy\/index.html';
      window.relearn.relBasePath='..\/..\/..\/..\/..';
      window.relearn.relBaseUri='..\/..\/..\/..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/docs';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
    <link href="/docs/css/custom.css?1758336532" rel="stylesheet">
  </head>
  <body class="mobile-support html" data-url="/docs/programming/ai/machine_learning/algorithms/action_08_multinomial-copy/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li><a href="#多项式回归">多项式回归</a>
      <ul>
        <li><a href="#概念">概念</a></li>
        <li><a href="#拟合实例">拟合实例</a></li>
      </ul>
    </li>
    <li><a href="#scikit-learn中的多项式回归">scikit-learn中的多项式回归</a>
      <ul>
        <li><a href="#polynomialfeatures">polynomialFeatures</a></li>
        <li><a href="#sklearn中的pipeline">sklearn中的Pipeline</a></li>
      </ul>
    </li>
    <li><a href="#过拟合和欠拟合">过拟合和欠拟合</a>
      <ul>
        <li><a href="#均方误差">均方误差</a></li>
        <li><a href="#拟合效果">拟合效果</a>
          <ul>
            <li><a href="#线性拟合">线性拟合</a></li>
            <li><a href="#二次多项式拟合">二次多项式拟合</a></li>
            <li><a href="#十次多项式拟合">十次多项式拟合</a></li>
            <li><a href="#百次多项式拟合">百次多项式拟合</a></li>
            <li><a href="#百次多项式生成数据集测试">百次多项式生成数据集测试</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#解决过拟合问题">解决过拟合问题</a>
      <ul>
        <li>
          <ul>
            <li><a href="#学习曲线">学习曲线</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/index.html"><span itemprop="name">liaomin416100569博客</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/index.html"><span itemprop="name">编程开发</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/index.html"><span itemprop="name">人工智能</span></a><meta itemprop="position" content="3">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/machine_learning/index.html"><span itemprop="name">机器学习</span></a><meta itemprop="position" content="4">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/machine_learning/algorithms/index.html"><span itemprop="name">核心算法</span></a><meta itemprop="position" content="5">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">机器学习实战教程（八）：多项式回归</span><meta itemprop="position" content="6"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/docs/programming/ai/machine_learning/algorithms/action_07_bays/index.html" title="机器学习实战教程（七）：朴素贝叶斯 (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/docs/programming/ai/machine_learning/algorithms/action_08_multinomial/index.html" title="机器学习实战教程（八）：多项式回归 (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable programming" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="机器学习实战教程八多项式回归">机器学习实战教程（八）：多项式回归</h1>

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<h1 id="多项式回归">多项式回归</h1>
<h2 id="概念">概念</h2>
<p>线性回归研究的是一个因变量与一个自变量之间的回归问题。
多项式回归是指在线性回归的基础上，通过增加非线性特征来拟合非线性数据的方法。多项式回归模型可以用一个 n 次多项式函数来近似描述目标变量和输入变量之间的关系。例如，对于只有一个自变量
x 的情况，可以将拟合函数写作：
<a href="#R-image-d5025a46b97e6dbf84c749ff5274cf36" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/2e0d741c67e2e2635ba1b240ba2aac0b.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-d5025a46b97e6dbf84c749ff5274cf36"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/2e0d741c67e2e2635ba1b240ba2aac0b.png"></a>
其中
y 表示目标变量，x 表示自变量，
<a href="#R-image-f7a93a7c1f9c7e68336666ea02cc929f" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/a1f2a63f24b72389288e856f31b95735.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-f7a93a7c1f9c7e68336666ea02cc929f"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/a1f2a63f24b72389288e856f31b95735.png"></a>是模型的参数。模型的目标是通过调整参数来使预测值与真实值的误差最小化。</p>
<p>多项式回归可以通过 Scikit-Learn 的 PolynomialFeatures 类来实现，它可以将原始的自变量数据转化为包含了多项式特征的新自变量数据。这样，我们就可以使用线性回归算法来处理增广后的非线性特征，从而得到多项式回归模型。</p>
<h2 id="拟合实例">拟合实例</h2>
<p>生成一个多项式的模拟数据 y=3<em>x+2</em>x**2</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>import numpy as np
import matplotlib.pyplot as plt

x = np.random.uniform(-3, 3, size=100)
X = x.reshape(-1, 1)
y =  3*x+ 2*x**2+ np.random.normal(0, 1, size=100)
plt.scatter(x, y)
plt.show()</code></pre></div>
<p><a href="#R-image-f89bc77c68310f584e02b9eab6851914" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/7e893e71b32b49803797a6888d40f218.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-f89bc77c68310f584e02b9eab6851914"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/7e893e71b32b49803797a6888d40f218.png"></a>
如果直接使用线性回归，看一下效果：</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(X, y)
y_predict = lin_reg.predict(X)
plt.scatter(x, y)
plt.plot(x, y_predict, color=&#39;r&#39;)
plt.show()</code></pre></div>
<p><a href="#R-image-5cba89fbbba4c0f06cc7bb5ee6bf3072" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/28a470c5794942b5fbd71922ce698358.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-5cba89fbbba4c0f06cc7bb5ee6bf3072"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/28a470c5794942b5fbd71922ce698358.png"></a>
很显然，拟合效果并不好。那么解决呢？
解决方案：添加一个特征。  x**2</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>X2 = np.hstack([X, X**2])
lin_reg2 = LinearRegression()
lin_reg2.fit(X2, y)
y_predict2 = lin_reg2.predict(X2)
plt.scatter(x, y)
plt.plot(np.sort(x), y_predict2[np.argsort(x)], color=&#39;r&#39;)
plt.show()</code></pre></div>
<p><a href="#R-image-3bd4427d18b3601fc2aa6dc9d0cd6280" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/981347a8bf373e614ab1ed6fdb2bd28d.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-3bd4427d18b3601fc2aa6dc9d0cd6280"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/981347a8bf373e614ab1ed6fdb2bd28d.png"></a>
这样就比直线拟合要好很多,斜率和截距是。</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[2.9391452  1.94366894]
0.04332751905483523</code></pre></div>
<h1 id="scikit-learn中的多项式回归">scikit-learn中的多项式回归</h1>
<h2 id="polynomialfeatures">polynomialFeatures</h2>
<p>polynomialFeatures是Scikit-Learn中的一个函数，用于将输入数据转化为多项式特征集合。其作用是在对非线性数据进行线性回归时，通过增加非线性特征来拟合非线性数据。</p>
<p>具体地，PolynomialFeatures函数将原始的特征向量转化为包含了所有多项式组合的新特征向量。例如，如果原始特征向量为 [a,b]，且使用degree=2，那么通过PolynomialFeatures生成的新特征向量为 [1,a,b,a^2, ab,b^2]。如果原始特征向量为 [x]，且使用degree=2，那么通过PolynomialFeatures生成的新特征向量为 [1,x,x^2]</p>
<p>这样，由于新特征向量包含了原始特征向量的所有多项式，可以更好地拟合非线性函数。</p>
<p>PolynomialFeatures主要有以下参数：</p>
<ul>
<li>degree：表示多项式的次数，决定了到多少次项的多项式将被生成。</li>
<li>interaction_only：默认为False，表示新特征向量包含交叉项和高次项，如a×b、a^2等等。</li>
<li>include_bias：默认为True，表示是否创建偏差列。</li>
</ul>
<p>总之，PolynomialFeatures是一个非常有用的函数，可以帮助我们更好地处理非线性数据，从而提高模型的预测能力。</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from sklearn.preprocessing import PolynomialFeatures
# 这个degree表示我们使用多少次幂的多项式
poly = PolynomialFeatures(degree=2)    
poly.fit(X)
X2 = poly.transform(X)
print(X2.shape)
print(X2)</code></pre></div>
<p>输出结果(第一列是常量1，第二列是之前的x，第三列是x**2)：</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>(100, 3)
[[ 1.00000000e+00 -2.37462045e+00  5.63882230e+00]
 [ 1.00000000e+00 -7.90962247e-01  6.25621276e-01]
 [ 1.00000000e+00 -7.02888543e-01  4.94052304e-01]
 [ 1.00000000e+00 -6.54589498e-01  4.28487411e-01]]</code></pre></div>
<p>使用线性回归拟合</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from sklearn.linear_model import LinearRegression
reg = LinearRegression() 
reg.fit(X2, y)
y_predict = reg.predict(X2) 
plt.scatter(x, y) 
plt.plot(np.sort(x), y_predict2[np.argsort(x)], color=&#39;r&#39;)
plt.show()
print(lin_reg2.coef_)
# array([0.90802935, 1.04112467])
print(lin_reg2.intercept_)</code></pre></div>
<p><a href="#R-image-c83c5c57c701c0ab434b84313638f764" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/147811c5ebc8cbc64bc5d6a4b2617a33.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-c83c5c57c701c0ab434b84313638f764"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/147811c5ebc8cbc64bc5d6a4b2617a33.png"></a>
输出截距和斜率</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[3.02468873 1.94228967]
0.41539122650325755</code></pre></div>
<p>之前使用的都是1维数据，如果使用2维3维甚至更高维呢？
生成一个二维数据（1到10，转换为5行2列）</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>import numpy as np
x = np.arange(1, 11).reshape(5, 2)
print(x)</code></pre></div>
<p>输出</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[[ 1  2]
 [ 3  4]
 [ 5  6]
 [ 7  8]
 [ 9 10]]</code></pre></div>
<p>使用PolynomialFeatures构造</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures()
poly.fit(x)
x2 = poly.transform(x)
print(x2)</code></pre></div>
<p>输出</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[[  1.   1.   2.   1.   2.   4.]
 [  1.   3.   4.   9.  12.  16.]
 [  1.   5.   6.  25.  30.  36.]
 [  1.   7.   8.  49.  56.  64.]
 [  1.   9.  10.  81.  90. 100.]]</code></pre></div>
<p>此时，可以看出当数据维度是2维是，经过多项式预处理生成了6维数据，第一列很显然是0次项系数，第二列和第三列也很好理解，分别是x1，x2，第四列和第六列分别是 x1<strong>2和x2</strong>2 ,还有一列，其实是x1*x2,这就是第5列，总共6列。由此可以猜想一下如果数据是3维的时候是什么情况？</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>poly = PolynomialFeatures(degree=3)
poly.fit(x)
x3 = poly.transform(x)
print(x3)</code></pre></div>
<p>输出</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[[   1.    1.    2.    1.    2.    4.    1.    2.    4.    8.]
 [   1.    3.    4.    9.   12.   16.   27.   36.   48.   64.]
 [   1.    5.    6.   25.   30.   36.  125.  150.  180.  216.]
 [   1.    7.    8.   49.   56.   64.  343.  392.  448.  512.]
 [   1.    9.   10.   81.   90.  100.  729.  810.  900. 1000.]]</code></pre></div>
<p><a href="#R-image-5463347e6358658e522cdfc7a4213a2a" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/00901a077dbca2293be548d865244840.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-5463347e6358658e522cdfc7a4213a2a"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/00901a077dbca2293be548d865244840.png"></a>
那么这10列，分别对应着什么？通过PolynomiaFeatures，将所有的可能组合，升维的方式呈指数型增长。这也会带来一定的问题。 如何解决这种爆炸式的增长？如果不控制一下，试想x和x[^100]相比差异就太大了。这就是传说中的过拟合。</p>
<h2 id="sklearn中的pipeline">sklearn中的Pipeline</h2>
<p>sklearn中的Pipeline是一个工具，可以将多个数据预处理步骤（transformer）和一个机器学习模型（estimator）串联在一起，形成一个完整的机器学习流程。Pipeline 中的每个步骤都是一个包含 fit 和 transform 方法的对象，其中 fit 方法用于拟合训练数据，transform 方法用于对数据进行转换。</p>
<p>通过 Pipeline 可以将多个预处理算法和机器学习算法组合在一起，使得整个流程变得规范化和简化，同时可以方便地进行交叉验证和参数调节等操作。Pipeline 中的每个步骤都可以使用一个字符串来标识，这个字符串可以用于对模型中的超参数进行调节。</p>
<p>Pipeline 通常用于机器学习中的特征工程，在数据预处理的过程中构建完整的机器学习流程，并将其应用于训练集和测试集中。通过将多个步骤组合在一起，避免了手动地进行特征工程和模型选择的各种组合操作，同时也提高了代码复用性和可维护性。</p>
<p>一般情况下多项式回归，我们会对数据进行<a href="https://blog.csdn.net/liaomin416100569/article/details/84035678?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168181861116800213034671%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=168181861116800213034671&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-6-84035678-null-null.blog_rank_default&utm_term=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&spm=1018.2226.3001.4450" rel="external" target="_blank">归一化</a>，然后进行多项式升维，再接着进行线性回归。因为sklearn中并没有对多项式回归进行封装，不过可以使用Pipeline对这些操作进行整合。</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>#%%

import numpy as np
import matplotlib.pyplot as plt

x = np.random.uniform(-3, 3, size=100)
X = x.reshape(-1, 1)
y =  3*x+ 2*x**2+ np.random.normal(0, 1, size=100)
plt.scatter(x, y)
plt.show()

#%%

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

poly_reg = Pipeline([
    (&#39;poly&#39;, PolynomialFeatures(degree=2)),   
    (&#39;std_scale&#39;, StandardScaler()),
    (&#39;lin_reg&#39;, LinearRegression())
])  
poly_reg.fit(X, y)
y_predict = poly_reg.predict(X)

plt.scatter(x, y)
plt.plot(np.sort(x), y_predict[np.argsort(x)], color=&#39;r&#39;)
plt.show()</code></pre></div>
<h1 id="过拟合和欠拟合">过拟合和欠拟合</h1>
<p>​ 多项式回归的最大优点就是可以通过增加x的高次项对实测点进行逼近，直至满意为止。但是这也正是它最大的缺点，因为通常情况下试过过高的维度对数据进行拟合，在训练集上会有很好的表现，但是测试集可能就不那么理想了，这也正是解决过拟合的一种办法。</p>
<h2 id="均方误差">均方误差</h2>
<p>mean_squared_error 是一个用于计算两个数组之间均方误差（Mean Squared Error，简称MSE）的函数。它是评价回归模型准确度的一种常见指标。
该函数的输入参数包括：</p>
<ul>
<li>y_true: 真实值数组；</li>
<li>y_pred: 预测值数组；</li>
<li>sample_weight: 用于对样本赋权重的数组，可以不传入，默认值为 None</li>
</ul>
<p>函数返回的是一个数值，表示两个数组之间的均方误差。</p>
<p>均方误差是回归模型中使用广泛的一种衡量模型预测能力的指标。均方误差越小说明模型的预测越准确。它的定义是：将每个样本预测值与真实值之间的偏差进行平方后求和，再除以样本总数得到的平均值，即
<a href="#R-image-cf5bae3195b251a81c64a7a03de27a88" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/1d6003991f15993927b3df2741387f13.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-cf5bae3195b251a81c64a7a03de27a88"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/1d6003991f15993927b3df2741387f13.png"></a></p>
<blockquote>
<p>均方误差越小就意味着模型的预测能力越准确</p></blockquote>
<h2 id="拟合效果">拟合效果</h2>
<p>以下使用同一个方式生成数据集之后，使用不同的拟合方式，并使用均方误差来对比几种拟合的效果。</p>
<h3 id="线性拟合">线性拟合</h3>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
lin_reg = LinearRegression()
lin_reg.fit(X, y)
y_predict = lin_reg.predict(X)
plt.scatter(x, y)
plt.plot(np.sort(x), y_predict[np.argsort(x)], color=&#39;r&#39;)
plt.show()
print(&#34;线性均方误差&#34;,mean_squared_error(y, y_predict))</code></pre></div>
<p>输出：3.0750025765636577
显然，直接使用简单的一次线性回归，拟合的结果就是欠拟合(underfiting)，
<a href="#R-image-ddb5f7c819644aaa2e1d2a1496e77f01" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/e74058c8902f1f7bf936530e9d8238f7.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-ddb5f7c819644aaa2e1d2a1496e77f01"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/e74058c8902f1f7bf936530e9d8238f7.png"></a></p>
<h3 id="二次多项式拟合">二次多项式拟合</h3>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

def PolynomialRegression(degree):
    return Pipeline([
        (&#39;poly&#39;, PolynomialFeatures(degree=degree)),
        (&#39;std_scale&#39;, StandardScaler()),
        (&#39;lin_reg&#39;, LinearRegression())
    ])  

poly_reg = PolynomialRegression(degree=2)
poly_reg.fit(X, y)
Pipeline(memory=None,
     steps=[(&#39;poly&#39;, PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), (&#39;std_scale&#39;, StandardScaler(copy=True, with_mean=True, with_std=True)), (&#39;lin_reg&#39;, LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize=False))])
y_predict = poly_reg.predict(X)
print(&#34;2次多项式均方误差&#34;,mean_squared_error(y, y_predict))
plt.scatter(x, y)
plt.plot(np.sort(x), y_predict[np.argsort(x)], color=&#39;r&#39;)
plt.show()</code></pre></div>
<p>输出：1.0987392142417856
二次多项式回归的拟合程度要高于线性回归。
<a href="#R-image-4d70c6cf4db9867d844df5d08052788e" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/9efedc399a95c6b52b168637ba4571ae.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-4d70c6cf4db9867d844df5d08052788e"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/9efedc399a95c6b52b168637ba4571ae.png"></a></p>
<h3 id="十次多项式拟合">十次多项式拟合</h3>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>poly10_reg = PolynomialRegression(degree=10)
poly10_reg.fit(X, y)

y10_predict = poly10_reg.predict(X)
print(&#34;10次多项式均方误差&#34;,mean_squared_error(y, y10_predict))
plt.scatter(x, y)
plt.plot(np.sort(x), y10_predict[np.argsort(x)], color=&#39;r&#39;)
plt.show()</code></pre></div>
<p>输出：1.0508466763764202
<a href="#R-image-be39e8934aa7d8dfdec7185119892d80" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/6975d23c4f02b2c41ab797ff9cd9f291.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-be39e8934aa7d8dfdec7185119892d80"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/6975d23c4f02b2c41ab797ff9cd9f291.png"></a></p>
<h3 id="百次多项式拟合">百次多项式拟合</h3>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>poly10_reg = PolynomialRegression(degree=100)
poly10_reg.fit(X, y)

y10_predict = poly10_reg.predict(X)
print(&#34;100次多项式均方误差&#34;,mean_squared_error(y, y10_predict))
plt.scatter(x, y)
plt.plot(np.sort(x), y10_predict[np.argsort(x)], color=&#39;r&#39;)
plt.show()</code></pre></div>
<p>输出：0.6870911922673567
<a href="#R-image-e5b53cb0437ccb848723c37b5df5780d" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/b0bcb450c857ed0f8efc0298d7531857.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-e5b53cb0437ccb848723c37b5df5780d"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/b0bcb450c857ed0f8efc0298d7531857.png"></a></p>
<h3 id="百次多项式生成数据集测试">百次多项式生成数据集测试</h3>
<p>从上面的图形看出uniform生成的数据预测的y值都在-1到10之间，我们使用相同的模型预测下 x=3的值</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>y_plot = poly100_reg.predict([[3]])
print(y_plot)</code></pre></div>
<p>输出：[-2.49133715e+06 -6.32965634e+24]
转换下：-2.49133715e+06==-2491337.16790313</p>
<p>发现&gt;=3后，如果按照这个弯月形的图形，明显是不正常的。
我们生成一个等差数列作为测试集</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from sklearn.preprocessing import PolynomialFeatures
x_plot = np.linspace(-3, 3, 100).reshape(100, 1)
y_plot = poly100_reg.predict(x_plot)
plt.scatter(x, y)
plt.plot(x_plot[:,0], y_plot, color=&#39;r&#39;)
# plt.axis([-3, 3, -1, 10])
plt.show()</code></pre></div>
<p><a href="#R-image-c5253f166611e1de4c27de3f09146608" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/331ae065da11cff0f94bb5f7510e387b.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-c5253f166611e1de4c27de3f09146608"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/331ae065da11cff0f94bb5f7510e387b.png"></a>
这样因为x=3图形都乱了，我们截图图形x从-3到3 y从-1到10</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from sklearn.preprocessing import PolynomialFeatures
x_plot = np.linspace(-3, 3, 100).reshape(100, 1)
y_plot = poly100_reg.predict(x_plot)
plt.scatter(x, y)
plt.plot(x_plot[:,0], y_plot, color=&#39;r&#39;)
plt.axis([-3, 3, -1, 10])
plt.show()</code></pre></div>
<p><a href="#R-image-ded1b24d6ee9ecd77d49573203b1464b" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/b31d9b79618684d2ee6409a2b8af1032.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-ded1b24d6ee9ecd77d49573203b1464b"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/b31d9b79618684d2ee6409a2b8af1032.png"></a></p>
<blockquote>
<p>说明通过训练集训练出的模型对测试集没有很好的表现能力</p></blockquote>
<h1 id="解决过拟合问题">解决过拟合问题</h1>
<p>通常在机器学习的过程中，主要解决的都是过拟合问题，因为这牵涉到模型的泛化能力。所谓泛化能力，就是模型在验证训练集之外的数据时能够给出很好的解答。只是对训练集的数据拟合的有多好是没有意义的，我们需要的模型的泛化能力有多好。</p>
<p>为什么要训练数据集与测试数据集？</p>
<p>通常情况下我们会将数据集分为训练集和测试集，通过训练数据训练出来的模型如果能对测试集具有较好的表现，才有意义。</p>
<p>以下使用train_test_split将生成的数据拆分为训练集和测试集，重新生成模型并计算均方误差
使用线性回归</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(666)
np.random.seed(666)
x = np.random.uniform(-3.0, 3.0, size=100)
X = x.reshape(-1, 1)
y = 0.5 * x**2 + x + 2 + np.random.normal(0, 1, size=100)

x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=666)
lin_reg = LinearRegression()
lin_reg.fit(x_train, y_train)
y_predict = lin_reg.predict(x_test)
mean_squared_error(y_test, y_predict)</code></pre></div>
<p>输出结果：2.2199965269396573</p>
<p>使用二项式</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

def PolynomialRegression(degree):
    return Pipeline([
        (&#39;poly&#39;, PolynomialFeatures(degree=degree)),
        (&#39;std_scale&#39;, StandardScaler()),
        (&#39;lin_reg&#39;, LinearRegression())
    ])
poly2_reg = PolynomialRegression(degree=2)
poly2_reg.fit(x_train, y_train)
y2_predict = poly2_reg.predict(x_test)
mean_squared_error(y_test, y2_predict)</code></pre></div>
<p>输出结果： 0.8035641056297901</p>
<p>使用10项式</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>poly10_reg = PolynomialRegression(degree=10)
poly10_reg.fit(x_train, y_train)
y10_predict = poly10_reg.predict(x_test)
mean_squared_error(y_test, y10_predict)</code></pre></div>
<p>输出结果：0.9212930722150781</p>
<p>通过上面的例子可以发现，当degree=2的时候在测试集上的均方误差和直线拟合相比好了很多，但是当degree=10的时候再测试集上的均方误差相对degree=2的时候效果差了很多，这就说名训练出来的模型已经过拟合了。</p>
<p>100项式</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>poly100_reg = PolynomialRegression(degree=100)
poly100_reg.fit(x_train, y_train)
y100_predict = poly100_reg.predict(x_test)
mean_squared_error(y_test, y100_predict)</code></pre></div>
<p>输出结果：14440175276.314638
<a href="#R-image-08917d81defe90f96b0a11ca1e5e5c28" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/f547f041c0bad624de22d4f247a74689.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-08917d81defe90f96b0a11ca1e5e5c28"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/f547f041c0bad624de22d4f247a74689.png"></a></p>
<p>小结：对于模型复杂度与模型准确率中寻找泛化能力最好的地方。</p>
<ol>
<li>欠拟合：underfitting，算法所训练的模型不能完整表述数据关系。</li>
<li>过拟合：overfitting，算法所训练的模型过多地表达数据间的噪音关系。
<a href="#R-image-073c6169aec07e2818c98b1b02c37652" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/457b5bce8c0e1c23284ba6fe98e8f868.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-073c6169aec07e2818c98b1b02c37652"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/457b5bce8c0e1c23284ba6fe98e8f868.png"></a></li>
</ol>
<h3 id="学习曲线">学习曲线</h3>
<p>机器学习的学习曲线是一种图形化表示机器学习算法在训练数据上表现的方式，通常以训练数据集大小或训练迭代次数为横轴，以模型性能指标（如准确率、误差等）为纵轴。这条曲线可以帮助我们了解算法的学习过程，评估学习效果和调整模型。</p>
<p>随着训练数据集的增加，我们希望看到模型的性能不断提高；而如果在训练集上性能较好但在测试集上表现欠佳，则说明出现了过拟合（overfitting）问题；相反，如果在训练集和测试集上的表现都不好，则可能需要重新考虑数据预处理、特征工程和模型结构等问题。</p>
<p>与学习曲线相关的概念还包括偏差（bias）和方差（variance），它们通常被用来对模型进行诊断和调整。当模型的偏差较大时，说明模型太简单，不能准确地拟合训练集和测试集，需要增加模型复杂度；而当模型的方差较大时，说明模型过于复杂，出现了过拟合问题，需要缩减模型复杂度或增加训练数据集的大小。</p>
<p>我们尝试将整个数据集拆分为训练集和测试机，训练集的大小从1到len（训练集）依次增加，生成训练集对应的模型（使用线性回归，2次多项式，100次多项式），使用相同的测试集测试对应的模型，并且绘制成x=训练集的个数，y=均方误差来看下欠拟合（线性回归），最佳拟合（二项式），过拟合（20项式）</p>
<p>下面绘制学习曲线的函数封装一下，方便后面调用</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>def plot_learning_curve(algo, x_train, x_test, y_train, y_test):

    train_score = []
    test_score = []
    for i in range(1, len(x_train)+1):
        algo.fit(x_train[:i], y_train[:i])

        y_train_predict = algo.predict(x_train[:i])
        train_score.append(mean_squared_error(y_train[:i], y_train_predict))

        y_test_predict = algo.predict(x_test)
        test_score.append(mean_squared_error(y_test, y_test_predict))

    plt.plot([i for i in range(1, len(x_train)+1)], np.sqrt(train_score), label=&#39;train&#39;)
    plt.plot([i for i in range(1, len(x_train)+1)], np.sqrt(test_score), label=&#39;test&#39;)
    plt.legend()
    plt.axis([0, len(x_train)+1, 0, 4])
    plt.show()
plot_learning_curve(LinearRegression(), x_train, x_test, y_train, y_test)</code></pre></div>
<p>生成数据集</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>np.random.seed(666)
np.random.seed(666)
x = np.random.uniform(-3.0, 3.0, size=100)
X = x.reshape(-1, 1)
y = 0.5 * x**2 + x + 2 + np.random.normal(0, 1, size=100)

x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=10)</code></pre></div>
<p>使用线性回归，图像是欠拟合（欠拟合指模型不能在训练集上获得足够低的误差），训练数据误差都达到2.0了
<a href="#R-image-6d4c828b4828bcdad4e6aaece664a2d6" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/f19dc8ab2e61e8186a6147be8377e470.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-6d4c828b4828bcdad4e6aaece664a2d6"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/f19dc8ab2e61e8186a6147be8377e470.png"></a>
使用二项式回顾，图像是最佳拟合</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>def PolynomialRegression(degree):
    return Pipeline([
        (&#39;poly&#39;, PolynomialFeatures(degree=degree)),
        (&#39;std_scale&#39;, StandardScaler()),
        (&#39;lin_reg&#39;, LinearRegression())
    ])
poly2_reg = PolynomialRegression(degree=2)
plot_learning_curve(poly2_reg, x_train, x_test, y_train, y_test)</code></pre></div>
<p><a href="#R-image-a71ae136bf4f610c722ae62722027329" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/1d09425105b4c2bc92833ef1d6422d69.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-a71ae136bf4f610c722ae62722027329"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/1d09425105b4c2bc92833ef1d6422d69.png"></a>
使用20项式，过拟合（过拟合则是指模型在训练集上表现很好，但在测试集上却表现很差）</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>poly2_reg = PolynomialRegression(degree=20)
plot_learning_curve(poly2_reg, x_train, x_test, y_train, y_test)</code></pre></div>
<p><a href="#R-image-045bc15bee6917170893ef3e93d67aa7" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/7ffb3d1dca479098ad62eddc8dda46b0.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-045bc15bee6917170893ef3e93d67aa7"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="https://i-blog.csdnimg.cn/blog_migrate/7ffb3d1dca479098ad62eddc8dda46b0.png"></a></p>

  <footer class="footline">
              <i class='fa-fw fas fa-calendar'></i> Sep 18, 2025
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/docs/index.html">
            <div class="logo-title">liaomin416100569博客</div>
          </a>
        </div>
        <search><form action="/docs/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/docs/index.html"><a class="padding" href="/docs/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="parent " data-nav-id="/docs/programming/index.html"><a class="padding" href="/docs/programming/index.html">编程开发</a><ul id="R-subsections-e3fc01b477dbaf64a8f5013a3dab5c5b" class="collapsible-menu">
            <li class="alwaysopen " data-nav-id="/docs/programming/languages/index.html"><a class="padding" href="/docs/programming/languages/index.html">编程语言</a><ul id="R-subsections-1bbde7fb0c312ba940b425df5a4caf67" class="collapsible-menu"></ul></li>
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/index.html"><a class="padding" href="/docs/programming/ai/index.html">人工智能</a><ul id="R-subsections-9d06be7bd8c736c09a65fb0b91b71d0e" class="collapsible-menu">
            <li class="alwaysopen " data-nav-id="/docs/programming/ai/tools_libraries/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/index.html">工具库</a><ul id="R-subsections-e43804740042696aa314af8cc1e28fa9" class="collapsible-menu"></ul></li>
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/machine_learning/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/index.html">机器学习</a><ul id="R-subsections-d3b98ca0beda96811b8c41829d886d7f" class="collapsible-menu">
            <li class="alwaysopen " data-nav-id="/docs/programming/ai/machine_learning/basic/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/basic/index.html">基础理论</a><ul id="R-subsections-2f18a18645b7652a148815c1a6786b18" class="collapsible-menu"></ul></li>
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/machine_learning/algorithms/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/algorithms/index.html">核心算法</a><ul id="R-subsections-921418d1d7190828278c689c88df6881" class="collapsible-menu">
            <li class="" data-nav-id="/docs/programming/ai/machine_learning/algorithms/action_05_pcaface/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/algorithms/action_05_pcaface/index.html">机器学习实战教程（⑤）：使用PCA实战人脸降维</a></li>
            <li class="" data-nav-id="/docs/programming/ai/machine_learning/algorithms/action_01_knn/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/algorithms/action_01_knn/index.html">机器学习实战教程（一）：K-近邻（KNN）算法</a></li>
            <li class="" data-nav-id="/docs/programming/ai/machine_learning/algorithms/action_07_bays/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/algorithms/action_07_bays/index.html">机器学习实战教程（七）：朴素贝叶斯</a></li>
            <li class="active " data-nav-id="/docs/programming/ai/machine_learning/algorithms/action_08_multinomial-copy/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/algorithms/action_08_multinomial-copy/index.html">机器学习实战教程（八）：多项式回归</a></li>
            <li class="" data-nav-id="/docs/programming/ai/machine_learning/algorithms/action_08_multinomial/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/algorithms/action_08_multinomial/index.html">机器学习实战教程（八）：多项式回归</a></li>
            <li class="" data-nav-id="/docs/programming/ai/machine_learning/algorithms/action_06_decidetree/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/algorithms/action_06_decidetree/index.html">机器学习实战教程（六）：决策树</a></li>
            <li class="" data-nav-id="/docs/programming/ai/machine_learning/algorithms/action_04_pca/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/algorithms/action_04_pca/index.html">机器学习实战教程（四）：从特征分解到协方差矩阵：详细剖析和实现PCA算法</a></li></ul></li>
            <li class="alwaysopen " data-nav-id="/docs/programming/ai/machine_learning/evaluation/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/evaluation/index.html">模型评估</a><ul id="R-subsections-d83b378e097742dc59073d128d99d653" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/docs/programming/ai/machine_learning/tools/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/tools/index.html">实践工具</a></li></ul></li>
            <li class="alwaysopen " data-nav-id="/docs/programming/ai/deep_learning/index.html"><a class="padding" href="/docs/programming/ai/deep_learning/index.html">深度学习</a><ul id="R-subsections-8e4f2a2c63b9f66a19e3b2a7c957ccda" class="collapsible-menu"></ul></li></ul></li>
            <li class="alwaysopen " data-nav-id="/docs/programming/plugins/index.html"><a class="padding" href="/docs/programming/plugins/index.html">插件开发</a><ul id="R-subsections-de66f54cff99288ca68bfcb5bb0439ae" class="collapsible-menu"></ul></li></ul></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script src="/docs/js/clipboard/clipboard.min.js?1758336532" defer></script>
    <script src="/docs/js/perfect-scrollbar/perfect-scrollbar.min.js?1758336532" defer></script>
    <script src="/docs/js/theme.js?1758336532" defer></script>
  </body>
</html>
