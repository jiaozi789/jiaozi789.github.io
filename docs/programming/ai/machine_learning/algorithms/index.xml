<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>核心算法 :: liaomin416100569博客</title>
    <link>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/index.html</link>
    <description></description>
    <generator>Hugo</generator>
    <language>zh</language>
    <lastBuildDate>Thu, 18 Sep 2025 16:55:17 +0800</lastBuildDate>
    <atom:link href="https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>机器学习实战教程（一）：K-近邻（KNN）算法</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_01_knn/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_01_knn/index.html</guid>
      <description>一、简单k-近邻算法 本文将从k-近邻算法的思想开始讲起，使用python3一步一步编写代码进行实战训练。并且，我也提供了相应的数据集，对代码进行了详细的注释。除此之外，本文也对sklearn实现k-近邻算法的方法进行了讲解。实战实例：电影类别分类、约会网站配对效果判定、手写数字识别。&#xA;文章中大部分文字和例题参考自https://cuijiahua.com/blog/2017/11/ml_1_knn.html 对原文很多代码进行了简化&#xA;感谢这篇文章加速本人入门速度&#xA;1、k-近邻法简介 k近邻法(k-nearest neighbor, k-NN)是1967年由Cover T和Hart P提出的一种基本分类与回归方法。它的工作原理是：存在一个样本数据集合，也称作为训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一个数据与所属分类的对应关系。输入没有标签的新数据后，将新的数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本最相似数据(最近邻)的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。&#xA;举个简单的例子，我们可以使用k-近邻算法分类一个电影是爱情片还是动作片。&#xA;表1.1 每部电影的打斗镜头数、接吻镜头数以及电影类型&#xA;表1.1 就是我们已有的数据集合，也就是训练样本集。这个数据集有两个特征，即打斗镜头数和接吻镜头数。除此之外，我们也知道每个电影的所属类型，即分类标签。用肉眼粗略地观察，接吻镜头多的，是爱情片。打斗镜头多的，是动作片。以我们多年的看片经验，这个分类还算合理。如果现在给我一部电影，你告诉我这个电影打斗镜头数和接吻镜头数。不告诉我这个电影类型，我可以根据你给我的信息进行判断，这个电影是属于爱情片还是动作片。而k-近邻算法也可以像我们人一样做到这一点，不同的地方在于，我们的经验更&#34;牛逼&#34;，而k-近邻算法是靠已有的数据。比如，你告诉我这个电影打斗镜头数为2，接吻镜头数为102，我的经验会告诉你这个是爱情片，k-近邻算法也会告诉你这个是爱情片。你又告诉我另一个电影打斗镜头数为49，接吻镜头数为51，我&#34;邪恶&#34;的经验可能会告诉你，这有可能是个&#34;爱情动作片&#34;，画面太美，我不敢想象。 (如果说，你不知道&#34;爱情动作片&#34;是什么？请评论留言与我联系，我需要你这样像我一样纯洁的朋友。) 但是k-近邻算法不会告诉你这些，因为在它的眼里，电影类型只有爱情片和动作片，它会提取样本集中特征最相似数据(最邻近)的分类标签，得到的结果可能是爱情片，也可能是动作片，但绝不会是&#34;爱情动作片&#34;。当然，这些取决于数据集的大小以及最近邻的判断标准等因素。&#xA;2、距离度量 我们已经知道k-近邻算法根据特征比较，然后提取样本集中特征最相似数据(最邻近)的分类标签。那么，如何进行比较呢？比如，我们还是以表1.1为例，怎么判断红色圆点标记的电影所属的类别呢？ 如下图所示。&#xA;我们可以从散点图大致推断，这个红色圆点标记的电影可能属于动作片，因为距离已知的那两个动作片的圆点更近。k-近邻算法用什么方法进行判断呢？没错，就是距离度量。这个电影分类的例子有2个特征，也就是在2维实数向量空间，可以使用我们高中学过的两点距离公式计算距离，如图1.2所示。&#xA;通过计算，我们可以得到如下结果：&#xA;(101,20)-&gt;动作片(108,5)的距离约为16.55 (101,20)-&gt;动作片(115,8)的距离约为18.44 (101,20)-&gt;爱情片(5,89)的距离约为118.22 (101,20)-&gt;爱情片(1,101)的距离约为128.69 通过计算可知，红色圆点标记的电影到动作片 (108,5)的距离最近，为16.55。如果算法直接根据这个结果，判断该红色圆点标记的电影为动作片，这个算法就是最近邻算法，而非k-近邻算法。那么k-近邻算法是什么呢？k-近邻算法步骤如下：&#xA;计算已知类别数据集中的点与当前点之间的距离； 按照距离递增次序排序； 选取与当前点距离最小的k个点； 确定前k个点所在类别的出现频率； 返回前k个点所出现频率最高的类别作为当前点的预测分类。 比如，现在我这个k值取3，那么在电影例子中，按距离依次排序的三个点分别是动作片(108,5)、动作片(115,8)、爱情片(5,89)。在这三个点中，动作片出现的频率为三分之二，爱情片出现的频率为三分之一，所以该红色圆点标记的电影为动作片。这个判别过程就是k-近邻算法。&#xA;其他距离公式：&#xA;曼哈顿距离（ManhattanDistance）：设平面空间内存在两点，它们的坐标为(x1,y1)(x1,y1)，(x2,y2)(x2,y2)&#xA;则 dis=|x1−x2|+|y1−y2|&#xA;比如 每个小正方形距离是1 红，栏，黄色都是12个方格都是曼哈顿距离&#xA;绿色线是欧氏距离(欧几里德距离：在二维和三维空间中的欧氏距离的就是两点之间的直线距离）&#xA;切比雪夫距离（Chebyshev Distance ）：设平面空间内存在两点，它们的坐标为(x1,y1)(x1,y1)，(x2,y2)(x2,y2)&#xA;则dis=max(|x1−x2|,|y1−y2|)</description>
    </item>
    <item>
      <title>机器学习实战教程（四）：从特征分解到协方差矩阵：详细剖析和实现PCA算法</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_04_pca/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_04_pca/index.html</guid>
      <description>1. 协方差 概念 方差和标准差的原理和实例演示，请参考&#xA;方差 方差（Variance）是度量一组数据的分散程度。方差是各个样本与样本均值的差的平方和的均值： 标准差 标准差是数值分散的测量。 标准差的符号是 σ （希腊语字母 西格马，英语 sigma） 公式很简单：方差的平方根。 协方差 通俗理解 可以通俗的理解为：两个变量在变化过程中是同方向变化？还是反方向变化？同向或反向程度如何？ 你变大，同时我也变大，说明两个变量是同向变化的，这时协方差就是正的。 你变大，同时我变小，说明两个变量是反向变化的，这时协方差就是负的。 从数值来看，协方差的数值越大，两个变量同向程度也就越大。反之亦然。 通俗易懂的理解看知乎文章 或者 gitlab转载&#xA;协方差矩阵 协方差（Covariance）在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。 这个解释摘自维基百科，看起来很是抽象，不好理解。其实简单来讲，协方差就是衡量两个变量相关性的变量。当协方差为正时，两个变量呈正相关关系（同增同减）；当协方差为负时，两个变量呈负相关关系（一增一减）。而协方差矩阵，只是将所有变量的协方差关系用矩阵的形式表现出来而已。通过矩阵这一工具，可以更方便地进行数学运算。 数学定义 回想概率统计里面关于方差的数学定义： 协方差的数学定义异曲同工： 这里的 x和y表示两个变量空间。用机器学习的话讲，就是样本有 x和 y两种特征， 而 X 就是包含所有样本的 x特征的集合， Y就是包含所有样本的 y特征的集合。 用一个例子来解释会更加形象。 用一个矩阵表示为： 现在，我们用两个变量空间X ，Y 来表示这两个特征： 由于协方差反应的是两个变量之间的相关性，因此，协方差矩阵表示的是所有变量之间两两相关的关系，具体来讲，一个包含两个特征的矩阵，其协方差矩阵应该有 2*2 大小： 接下来，就来逐一计算 Cov(Z)的值。 首先，我们需要先计算出 X，Y 两个特征空间的平均值： AVG(X)=3.25,AVG(Y)=3 ， 。 然后，根据协方差的数学定义，计算协方差矩阵的每个元素： 所以协方差矩阵 好了，虽然这只是一个二维特征的例子，但我们已经可以从中总结出协方差矩阵 的「计算套路」： python协方差原理</description>
    </item>
    <item>
      <title>机器学习实战教程（五）：使用PCA实战人脸降维</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_05_pcaface/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_05_pcaface/index.html</guid>
      <description>1.引言 在互联网大数据场景下，我们经常需要面对高维数据，在对这些数据做分析和可视化的时候，我们通常会面对「高维」这个障碍。在数据挖掘和建模的过程中，高维数据也同样带来大的计算量，占据更多的资源，而且许多变量之间可能存在相关性，从而增加了分析与建模的复杂性。&#xA;我们希望找到一种方法，在对数据完成降维「压缩」的同时，尽量减少信息损失。由于各变量之间存在一定的相关关系，因此可以考虑将关系紧密的变量变成尽可能少的新变量，使这些新变量是两两不相关的，那么就可以用较少的综合指标分别代表存在于各个变量中的各类信息。机器学习中的降维算法就是这样的一类算法。&#xA;主成分分析（Principal Components Analysis，简称PCA）是最重要的数据降维方法之一。在数据压缩消除冗余和数据噪音消除等领域都有广泛的应用。本篇我们来展开讲解一下这个算法。&#xA;2.相关概念 协方差矩阵 协方差(Covariance)目的是度量两个变量(只能为两个)线性相关的程度。 cov=0为可以说明两个变量线性无关，但不能证明两个变量相互独立，当cov&gt;0时，二者呈正相关，cov&lt;0时，二者呈负相关。&#xA;协方差矩阵可以处理多维度问题。 协方差矩阵是一个对称的矩阵，而且对角线是各个维度上的方差。 协方差矩阵计算的是不同维度之间的协方差，而不是不同样本之间的。 样本矩阵中若每行是一个样本，则每列为一个维度。 假设数据是3维的，那么对应协方差矩阵为： 这里简要概括一下协方差矩阵是怎么求得的，假设一个数据集有3维特征、每个特征有m个变量，这个数据集对应的数据矩阵如下： 若假设他们的均值都为0，可以得到下面等式： 可以看到对角线上为每个特征方差，其余位置为两个特征之间的协方差， 求得的就为协方差矩阵。 推导： 如果列是特征，公式为： &#39;&#39;&#39;&#xD;假设列是矩阵特征，代数里面是行表示特征&#xD;[&#xD;[x1,y2]&#xD;[x2，y2]&#xD;]&#xD;求协方差是&#xD;[&#xD;[cov(x,x),cov(x,y)],&#xD;[cov(y,x),cov(y,y)],&#xD;]&#xD;&#39;&#39;&#39;&#xD;pc=np.array([[-1,4],&#xD;[-2,8],&#xD;[-7,2]&#xD;]);&#xD;mean_pa=np.mean(pc,axis=0)&#xD;print(&#34;均值&#34;,mean_pa)&#xD;pc_zero=pc-mean_pa&#xD;print(pc_zero)&#xD;print(pc_zero.T.dot(pc_zero)/(len(pc_zero)-1)) #注意样本的话是n-1啊，全部数据集是n，否则和np.cov对不上&#xD;print(&#34;conv&#34;,np.cov(pc,rowvar=False)) #rowvar=False表示列是特征，默认行是特征 结果为：</description>
    </item>
    <item>
      <title>机器学习实战教程（六）：决策树</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_06_decidetree/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_06_decidetree/index.html</guid>
      <description>决策树 决策树是什么？决策树(decision tree)是一种基本的分类与回归方法。举个通俗易懂的例子，如下图所示的流程图就是一个决策树，长方形代表判断模块(decision block)，椭圆形成代表终止模块(terminating block)，表示已经得出结论，可以终止运行。从判断模块引出的左右箭头称作为分支(branch)，它可以达到另一个判断模块或者终止模块。我们还可以这样理解，分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点(node)和有向边(directed edge)组成。结点有两种类型：内部结点(internal node)和叶结点(leaf node)。内部结点表示一个特征或属性，叶结点表示一个类。蒙圈没？？如下图所示的决策树，长方形和椭圆形都是结点。长方形的结点属于内部结点，椭圆形的结点属于叶结点，从结点引出的左右箭头就是有向边。而最上面的结点就是决策树的根结点(root node)。这样，结点说法就与模块说法对应上了，理解就好。&#xA;本文大部分文字转载自https://cuijiahua.com/blog/2017/11/ml_2_decision_tree_1.html，代码和部分原创&#xA;我们回到这个流程图，对，你没看错，这就是一个假想的相亲对象分类系统。它首先检测相亲对方是否有房。如果有房，则对于这个相亲对象可以考虑进一步接触。如果没有房，则观察相亲对象是否有上进心，如果没有，直接Say Goodbye，此时可以说：“你人很好，但是我们不合适。“如果有，则可以把这个相亲对象列入候选名单，好听点叫候选名单，有点瑕疵地讲，那就是备胎。&#xA;不过这只是个简单的相亲对象分类系统，只是做了简单的分类。真实情况可能要复杂得多，考虑因素也可以是五花八门。脾气好吗？会做饭吗？愿意做家务吗？家里几个孩子？父母是干什么的？天啊，我不想再说下去了，想想都可怕。&#xA;我们可以把决策树看成一个if-then规则的集合，将决策树转换成if-then规则的过程是这样的：由决策树的根结点(root node)到叶结点(leaf node)的每一条路径构建一条规则；路径上内部结点的特征对应着规则的条件，而叶结点的类对应着规则的结论。决策树的路径或其对应的if-then规则集合具有一个重要的性质：互斥并且完备。这就是说，每一个实例都被一条路径或一条规则所覆盖，而且只被一条路径或一条规则所覆盖。这里所覆盖是指实例的特征与路径上的特征一致或实例满足规则的条件。&#xA;使用决策树做预测需要以下过程：&#xA;收集数据：可以使用任何方法。比如想构建一个相亲系统，我们可以从媒婆那里，或者通过采访相亲对象获取数据。根据他们考虑的因素和最终的选择结果，就可以得到一些供我们利用的数据了。 准备数据：收集完的数据，我们要进行整理，将这些所有收集的信息按照一定规则整理出来，并排版，方便我们进行后续处理。 分析数据：可以使用任何方法，决策树构造完成之后，我们可以检查决策树图形是否符合预期。 训练算法：这个过程也就是构造决策树，同样也可以说是决策树学习，就是构造一个决策树的数据结构。 测试算法：使用经验树计算错误率。当错误率达到了可接收范围，这个决策树就可以投放使用了。 使用算法：此步骤可以使用适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。 决策树的构建的准备工作 使用决策树做预测的每一步骤都很重要，数据收集不到位，将会导致没有足够的特征让我们构建错误率低的决策树。数据特征充足，但是不知道用哪些特征好，将会导致无法构建出分类效果好的决策树模型。从算法方面看，决策树的构建是我们的核心内容。&#xA;决策树要如何构建呢？通常，这一过程可以概括为3个步骤：特征选择、决策树的生成和决策树的修剪。&#xA;特征选择 特征选择在于选取对训练数据具有分类能力的特征。这样可以提高决策树学习的效率，如果利用一个特征进行分类的结果与随机分类的结果没有很大差别，则称这个特征是没有分类能力的。经验上扔掉这样的特征对决策树学习的精度影响不大。通常特征选择的标准是信息增益(information gain)或信息增益比，为了简单，本文使用信息增益作为选择特征的标准。那么，什么是信息增益？在讲解信息增益之前，让我们看一组实例，贷款申请样本数据表。&#xA;希望通过所给的训练数据学习一个贷款申请的决策树，用于对未来的贷款申请进行分类，即当新的客户提出贷款申请时，根据申请人的特征利用决策树决定是否批准贷款申请。&#xA;特征选择就是决定用哪个特征来划分特征空间。比如，我们通过上述数据表得到两个可能的决策树，分别由两个不同特征的根结点构成。 图(a)所示的根结点的特征是年龄，有3个取值，对应于不同的取值有不同的子结点。图(b)所示的根节点的特征是工作，有2个取值，对应于不同的取值有不同的子结点。两个决策树都可以从此延续下去。问题是：究竟选择哪个特征更好些？这就要求确定选择特征的准则。直观上，如果一个特征具有更好的分类能力，或者说，按照这一特征将训练数据集分割成子集，使得各个子集在当前条件下有最好的分类，那么就更应该选择这个特征。信息增益就能够很好地表示这一直观的准则。&#xA;什么是信息增益呢？在划分数据集之后信息发生的变化称为信息增益，知道如何计算信息增益，我们就可以计算每个特征值划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择。 信息增益=整个数据的不确定性-某个特征条件的不确定=这个特征增强了多少确定性&#xA;那怎么确定数据的不确定性了，引出了香农熵的概念</description>
    </item>
    <item>
      <title>机器学习实战教程（七）：朴素贝叶斯</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_07_bays/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_07_bays/index.html</guid>
      <description>一 简介 朴素贝叶斯算法是有监督的学习算法，解决的是分类问题，如客户是否流失、是否值得投资、信用等级评定等多分类问题。该算法的优点在于简单易懂、学习效率高、在某些领域的分类问题中能够与决策树、神经网络相媲美。但由于该算法以自变量之间的独立（条件特征独立）性和连续变量的正态性假设为前提，就会导致算法精度在某种程度上受影响。&#xA;二 朴素贝叶斯理论 把样本空间划分成容易研究的几种情况。&#xA;全概率公式（由原因到结果）考察在每一种情况下事件B发生的概率，计算B的概率。 Bayes公式（由结果到原因）在事件B发生的条件下，考察每种情况出现的条件概率。 条件概率 公式推导 我们需要了解什么是条件概率(Conditional probability)，就是指在事件B发生的情况下，事件A发生的概率，用P(A|B)来表示。 根据文氏图，可以很清楚地看到在事件B发生的情况下，事件A发生的概率就是P(A∩B)除以P(B)。 因此， 同理根据条件概率知道A发生时B的概率 转换下 所以 即 这就是条件概率的计算公式。</description>
    </item>
    <item>
      <title>机器学习实战教程（八）：多项式回归</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_08_multinomial/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_08_multinomial/index.html</guid>
      <description>多项式回归 概念 线性回归研究的是一个因变量与一个自变量之间的回归问题。 多项式回归是指在线性回归的基础上，通过增加非线性特征来拟合非线性数据的方法。多项式回归模型可以用一个 n 次多项式函数来近似描述目标变量和输入变量之间的关系。例如，对于只有一个自变量 x 的情况，可以将拟合函数写作： 其中 y 表示目标变量，x 表示自变量， 是模型的参数。模型的目标是通过调整参数来使预测值与真实值的误差最小化。&#xA;多项式回归可以通过 Scikit-Learn 的 PolynomialFeatures 类来实现，它可以将原始的自变量数据转化为包含了多项式特征的新自变量数据。这样，我们就可以使用线性回归算法来处理增广后的非线性特征，从而得到多项式回归模型。&#xA;拟合实例 生成一个多项式的模拟数据 y=3x+2x**2&#xA;import numpy as np&#xD;import matplotlib.pyplot as plt&#xD;x = np.random.uniform(-3, 3, size=100)&#xD;X = x.reshape(-1, 1)&#xD;y = 3*x+ 2*x**2+ np.random.normal(0, 1, size=100)&#xD;plt.scatter(x, y)&#xD;plt.show() 如果直接使用线性回归，看一下效果：</description>
    </item>
    <item>
      <title>机器学习实战教程（十）：逻辑回归</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_10_logic/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_10_logic/index.html</guid>
      <description>概述 逻辑回归（Logistic Regression）是一种用于解决二分类或多分类问题的统计学习方法。它以自变量线性组合的形式进行建模，并使用Sigmoid函数将结果映射到[0, 1]的值域内，表示样本属于某个类别的概率。 Logistic Regression是最广泛使用的一种算法，逻辑回归常年在机器学习算法排名前10。&#xA;逻辑回归推导 线性回归 线性回归的表达式： $f(x)=\theta_0+\theta_1x_1+\theta_2x_2+….+\theta_nx_n$ 转换为矩阵乘法： $[[x_1,x_2….,x_n]]$点乘$[[\theta_1,\theta_2…..,\theta_n]]^T$ 矩阵演示： 首先，假设我们有一个包含3个样本、每个样本有2个特征的训练集X：&#xA;X = [[1, 2], [3, 4], [5, 6]] 其中，每个样本都有两个特征。接着，我们随机初始化参数向量θ：&#xA;θ = [[0.5,0.5]]&#xD;θ.T=[[0.5],[0.5]]&#xD;X * θ = [[1, 2], [3, 4], [5, 6]] * [[0.5], [0.5]] = [[10.5+20.5], [30.5+40.5], [50.5+60.5]] = [[1.5], [3.5], [5.5]] 所以： $f(x)=\theta_0+\theta^Tx$ 如果在x数据集加上一列常量1，$\theta_0$加入到$\theta$矩阵中，也就能再次缩写 $f(x)=\theta^Tx$&#xA;$\theta$是权值,它与输出y之间的关系强度。如果权值越大，则输入特征对输出的影响就越大；如果权值越小，则输入特征对输出的影响就越小。。&#xA;逻辑回归 逻辑回归(Logistic Regression, LR)模型其实仅在线性回归的基础上，套用了一个逻辑函数，但也就由于这个逻辑函数，使得逻辑回归模型成为了机器学习领域一颗耀眼的明星，更是计算广告学的核心。 通常线性方程的值域为 $(-\infty，+\infty)$,而概率的值域为[0, 1]，因此我们在这个基础上做一个变形，完成从 $(-\infty，+\infty)$,到[0,1]的转换。 逻辑回归的假设函数可以表示为 $$h_\theta(x)=g(\theta^Tx)$$ 这个转换函数g就叫做Sigmoid函数，函数的表达式： $$g(z)={1\over(1+e^{-z})}$$ 我们来看下Sigmoid函数的图形&#xA;import numpy as np&#xD;import matplotlib.pyplot as plt&#xD;def sigmoid(t):&#xD;return 1 / (1 + np.exp(-t))&#xD;x = np.linspace(-10, 10, 500)&#xD;y = sigmoid(x)&#xD;plt.plot(x, y)&#xD;plt.show() 于是我们得到了这样的关系式：</description>
    </item>
    <item>
      <title>机器学习实战教程（十一）：支持向量机SVM</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_11_vectormachine/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_11_vectormachine/index.html</guid>
      <description>什么是SVM？ VM的英文全称是Support Vector Machines，我们叫它支持向量机。支持向量机是我们用于分类的一种算法。让我们以一个小故事的形式，开启我们的SVM之旅吧。&#xA;在很久以前的情人节，一位大侠要去救他的爱人，但天空中的魔鬼和他玩了一个游戏。&#xA;魔鬼在桌子上似乎有规律放了两种颜色的球，说：“你用一根棍分开它们？要求：尽量在放更多球之后，仍然适用。” 于是大侠这样放，干的不错？ 然后魔鬼，又在桌上放了更多的球，似乎有一个球站错了阵营。显然，大侠需要对棍做出调整。 SVM就是试图把棍放在最佳位置，好让在棍的两边有尽可能大的间隙。这个间隙就是球到棍的距离。 现在好了，即使魔鬼放了更多的球，棍仍然是一个好的分界线。 现在，大侠没有棍可以很好帮他分开两种球了，现在怎么办呢？当然像所有武侠片中一样大侠桌子一拍，球飞到空中。然后，凭借大侠的轻功，大侠抓起一张纸，插到了两种球的中间。 现在，从空中的魔鬼的角度看这些球，这些球看起来像是被一条曲线分开了。 再之后，无聊的大人们，把这些球叫做data，把棍子叫做classifier, 找到最大间隙的trick叫做optimization，拍桌子叫做kernelling, 那张纸叫做hyperplane。</description>
    </item>
    <item>
      <title>机器学习实战教程（十二）：聚类算法Kmeans</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_12_cluster/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_12_cluster/index.html</guid>
      <description>聚类概念 聚类是一种无监督的机器学习方法，它主要是通过在数据集中找到相似的样本并将它们分组来发现数据中的模式和结构。聚类算法可以将数据分成具有相似特征的组，每个组被称为一个簇。&#xA;常见的聚类算法有以下几种：&#xA;K-means聚类算法：它是最常见的聚类算法之一，它的目标是将数据集分为K个簇，使得每个簇内的数据点相似度最高，不同簇之间的差异最大。&#xA;层次聚类算法：该算法将数据集中的样本逐渐合并到一起，直到形成一个完整的聚类结构，从而形成一颗聚类树。&#xA;密度聚类算法：它是一种基于数据点密度的聚类算法，它将数据点分为密集的区域和稀疏的区域，并将密集区域看作是一个簇。&#xA;均值漂移聚类算法：该算法使用核密度估计来找到数据点的局部最大值，以确定簇的质心。&#xA;DBSCAN聚类算法：它基于在数据集中的密度来确定簇的个数和形状，它可以识别任意形状的簇。&#xA;K-means简介 K-means是一种基于距离度量的聚类算法，其主要思想是将数据集分成K个簇，每个簇包含距离最近的K个数据点。该算法通过迭代优化簇的中心点，来不断调整簇的划分，最终得到一组最优的簇划分结果。&#xA;通俗来说，K-means算法就像是一位假设聪明的小学生在玩“猜数字”游戏。他会先猜一个数字，然后根据猜测与正确答案的距离（越接近答案距离越小），将答案所在的数字范围分成两个区域。接着，他会重复这个过程，直到将数字范围分成了K个区域为止，并记录下每个区域的中心点。最后，他会告诉你每个数字应该属于哪个区域（或者说簇），并告诉你每个区域的中心点。&#xA;在K-means算法中，我们需要指定簇的个数K，然后随机选择K个数据点作为初始中心点。接着，我们计算每个数据点距离各个中心点的距离，并将其归入距离最近的簇中。然后，重新计算每个簇的中心点，并重复上述过程（在计算每个点到新中心的举例重新归类到簇），直到簇的中心点不再发生变化为止。最终，我们将得到K个簇，每个簇包含一组距离最近的数据点，并且每个数据点只属于一个簇。&#xA;需要注意的是，由于K-means算法的初始中心点是随机选择的，因此可能会得到不同的簇划分结果。为了获得更好的结果，可以多次运行算法，并选择最优的簇划分结果。&#xA;K-means和KNN区别 K-Means和K-NN是两种不同的机器学习算法，其区别如下：&#xA;K-Means是一种聚类算法，它将数据集划分为K个簇，并将每个数据点分配到其最近的簇中心。K-NN是一种分类算法，它根据最近邻居的标签来预测新数据点的标签。&#xA;K-Means需要指定簇的数量K，而K-NN不需要。&#xA;K-Means是一种无监督学习算法，它不需要标记数据，而K-NN是一种监督学习算法，需要标记数据。&#xA;K-Means使用欧几里得距离来计算数据点之间的相似度，而K-NN可以使用不同的距离度量，如曼哈顿距离、余弦相似度等。&#xA;K-Means在处理大规模数据时可能会遇到性能问题，而K-NN可以轻松处理大规模数据。&#xA;总的来说，K-Means和K-NN是两种不同的机器学习算法，适用于不同的问题和数据集。&#xA;Kmeans的计算过程 （1）适当选择c个类的初始中心； （2）在k次迭代中，对任意一个样本，求其到c各中心的距离（欧式距离），将该样本归到距离更短的中心所在的类； （3）利用均值等方法更新该类的中心值； （4）对于所有的c个聚类中心，如果利用（2）（3）的迭代法更新后，值保持不变，则迭代结束，否则继续迭代。&#xA;假设 现在有4组数据，每组数据有2个维度，对其进行聚类分为2类，将其可视化一下。 $A=(1,1),B=(2,1),C=(4,3),D=(5,4)$ 假设选取两个星的位置为初始中心 $c_1=(1,1),c_2=(2,1)$，计算每个点到初始中心的距离，使用欧式距离得到4个点分别距离两个初始中心的距离，归于最近的类： $D^0第一行表示ABCD四个点到c1的举例，第二行表示ABCD四个点到c2的举例，举例使用欧氏距离公式计算出来，以C为例，到c1这一组的举例是3.61,到c2这一组的举例是2.83说明第一次迭代C是属于group-2$&#xA;通过比较，将其进行归类。并使用平均法更新中心位置。 由于归于group1的只有一个点，一次更新后的中心位置$c_1=(1,1)$，而 $c_{2} = (\frac{11}{3}, \frac{8}{3})$&#xA;group2的新中心点也就是$x={(x1+x2+x3)\over 3} ={(2+4+5)\over3}={11\over3}$ $y={(y1+y2+y3)\over 3} ={(1+3+4)\over3}={8\over3}$ 再次计算每个点与更新后的位置中心的距离</description>
    </item>
    <item>
      <title>机器学习实战教程（十三）：集成学习</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_13_intelearn/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/machine_learning/algorithms/action_13_intelearn/index.html</guid>
      <description>简介 集成学习是一种机器学习方法，它旨在通过将多个单独的学习器（称为基分类器或基学习器）的预测结果进行组合，来提高整体的预测准确率。&#xA;集成学习可以看作是一种“多个人一起合作做事”的方法。每个基分类器都是独立的学习器，它们在训练数据上进行训练并产生一个预测结果。这些基分类器可以使用不同的算法、不同的参数设置或不同的训练数据。最后，将所有基分类器的预测结果汇总起来，通过一定的组合方式（例如投票、加权投票等）得到最终的预测结果。&#xA;与单个分类器相比，集成学习可以显著提高分类器的准确率和泛化能力。这是因为集成学习可以有效地减少分类器的偏差和方差，从而避免过拟合和欠拟合问题。此外，集成学习还可以增加分类器的鲁棒性，使其对噪声和异常值具有更强的容忍性。&#xA;目前，集成学习已经被广泛应用于各种领域，例如图像识别、自然语言处理、金融风险评估等。常见的集成学习方法包括Bagging、Boosting、Stacking等。&#xA;在集成学习中，通常会涉及到几个概念，包括：&#xA;基分类器（Base Classifier）：指的是单独的、独立的学习器，它们的预测结果会被组合起来生成最终的预测结果，集成学习中常用的基分类器有决策树、支持向量机、逻辑回归、朴素贝叶斯、神经网络等。不同的基分类器在不同的数据集和任务中可能会表现出不同的性能，因此在实际应用中需要根据具体情况选择合适的基分类器。。&#xA;集成分类器（Ensemble Classifier）：指的是由多个基分类器组成的分类器。集成分类器可以看作是一个“元分类器”，它可以对多个基分类器的预测结果进行组合，从而得到更加准确的预测结果。&#xA;Bagging（Bootstrap Aggregating）：是一种基于自助采样法的集成学习方法。它通过对原始训练集进行多次有放回的采样，来产生多个训练集，并使用每个训练集产生一个基分类器。最后，将所有基分类器的预测结果进行投票或平均，得到最终的预测结果。&#xA;Boosting：是一种迭代的、逐步提升基分类器性能的集成学习方法。它通过对训练集进行加权，使得基分类器更加关注那些被错误分类的样本，从而提高分类器的准确率。Boosting方法有很多种，比如AdaBoost、Gradient Boosting等。&#xA;Stacking：是一种将多个基分类器的预测结果作为输入，再训练一个“元分类器”的集成学习方法。Stacking方法可以看作是一种二级学习方法，它将基分类器的预测结果作为新的特征，再进行训练，从而得到更加准确的预测结果。&#xA;这些概念是集成学习中非常基础且重要的内容，理解它们可以帮助我们更好地理解和应用集成学习算法。&#xA;集成分类方法 常用的集成分类方法有以下几种：&#xA;Bagging：基于自助采样的方法，通过训练多个相互独立的基分类器，然后将它们的输出进行投票或平均。&#xA;Boosting：通过逐步训练一系列弱分类器，每一轮训练都会根据前一轮分类器的错误情况来调整样本权重，使得被错误分类的样本得到更多的关注，从而提高分类器的性能。&#xA;以下是两种集成方法的集成分类器实现&#xA;Random Forest（随机森林）：是一种基于决策树的Bagging集成方法，通过随机选择特征和样本来生成多个决策树，然后将它们的输出进行投票。&#xA;AdaBoost：是一种基于Boosting的集成方法，通过逐步训练一系列弱分类器，每一轮训练都会根据前一轮分类器的错误情况来调整样本权重，并且在训练过程中给每个分类器分配一个权重，然后将它们的输出进行加权平均。&#xA;Gradient Boosting Decision Tree (GBDT)：是一种基于Boosting的集成方法，通过逐步训练一系列决策树来提高分类器的性能，每个决策树都是基于前一棵树的残差来进行训练的，然后将所有决策树的输出进行加权平均。&#xA;这些集成分类器在不同的数据集和任务中可能会表现出不同的性能，因此在实际应用中需要根据具体情况选择合适的集成分类器。&#xA;Bagging 自举汇聚法（bootstrap aggregating），也称为bagging方法。Bagging对训练数据采用自举采样（boostrap sampling），即有放回地采样数据，主要思想：&#xA;从原始样本集中抽取训练集。每轮从原始样本集中使用Bootstraping的方法抽取n个训练样本（在训练集中，有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中）。共进行k轮抽取，得到k个训练集。（k个训练集之间是相互独立的） 每次使用一个训练集得到一个模型，k个训练集共得到k个模型。（注：这里并没有具体的分类算法或回归方法，我们可以根据具体问题采用不同的分类或回归方法，如决策树、感知器等） 对分类问题：将上步得到的k个模型采用投票的方式得到分类结果；对回归问题，计算上述模型的均值作为最后的结果。（所有模型的重要性相同） Boosting Boosting是一种与Bagging很类似的技术。Boosting的思路则是采用重赋权（re-weighting）法迭代地训练基分类器，主要思想：&#xA;每一轮的训练数据样本赋予一个权重，并且每一轮样本的权值分布依赖上一轮的分类结果，也就是说当前样本的权重，受分类结果的权重影响，当前分类结果的错误率越高，当前样本的权重也就越高，利用指数函数放大。 基分类器之间采用序列式的线性加权方式进行组合。 Bagging、Boosting二者之间的区别 样本选择上：&#xA;Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。 Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。 样例权重：&#xA;Bagging：使用均匀取样，每个样例的权重相等。 Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大，也就是每个样本都有一个权重，错误率越高权重越大，需要被重新训练的概率越大。 预测函数： 在集成学习中，我们通常会为每个基分类器分配一个权重，这个权重取决于该分类器在训练集上的表现。对于表现好的分类器，我们会赋予更高的权重，以使它们在投票决策中占据更重要的地位。相反，表现差的分类器会被分配较低的权重，以减少它们对最终结果的影响。&#xA;Bagging：所有预测函数的权重相等。 Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。 并行计算：</description>
    </item>
  </channel>
</rss>