<!DOCTYPE html>
<html lang="zh" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/docs/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=docs/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.150.0">
    <meta name="generator" content="Relearn 8.0.1+b23cf6629eada0c2802f34ae4012e04343497862">
    <meta name="description" content="@TOC
1.线性回归简介 线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。其表达形式为y = w’x&#43;e，e为误差服从均值为0的正态分布。 回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。
1.1 正态分布 正态分布（Normal distribution），也称“常态分布”，又名高斯分布（Gaussian distribution），最早由A.棣莫弗在求二项分布的渐近公式中得到。C.F.高斯在研究测量误差时从另一个角度导出了它。P.S.拉普拉斯和高斯研究了它的性质。是一个在数学、物理及工程等领域都非常重要的概率分布，在统计学的许多方面有着重大的影响力。 以下两图来自网络 对于正态分布的理解更加简单： 高斯函数是一种常见的概率密度函数，也被称为正态分布函数。具体地说，高斯函数描述了随机变量在某个区间内取值的概率密度，其形式为： $f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ 其中， μ 是均值，σ 是标准差。这个函数的图像呈钟形，且左右对称，最高点位于均值处，随着距离均值越远，函数值逐渐减小。
概率密度函数是用来描述随机变量分布情况的函数，而高斯函数是其中的一种形式。当随机变量服从正态分布时，其概率密度函数就是高斯函数。因此，可以将高斯函数看作是概率密度函数的一种特殊形式。
1.2 Linear Regression线性回归 它是最为人熟知的建模技术之一。线性回归通常是人们在学习预测模型时首选的技术之一。在这种技术中，因变量是连续的，自变量可以是连续的也可以是离散的，回归线的性质是线性的。 线性回归使用最佳的拟合直线（也就是回归线）在因变量（Y）和一个或多个自变量（X）之间建立一种关系。 多元线性回归可表示为Y=a&#43;b1X &#43;b2X2&#43; e，其中a表示截距，b表示直线的斜率，e是误差项。多元线性回归可以根据给定的预测变量（s）来预测目标变量的值。
1.2.1 一元线程回归（简单线性回归） 在统计学中，线性回归是利用称为线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。一个带有一个自变量的线性回归方程代表一条直线。我们需要对线性回归结果进行统计分析 回归线其实可以理解为一条直线，数学表示方式为： Y=b0 &#43; b1X&#43;e 在统计学中，假设有一系列的自变量和因变量的统计数据，可以推算出最佳拟合的b0和b1">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="机器学习实战教程（二）：线性回归 :: liaomin416100569博客">
    <meta name="twitter:description" content="@TOC
1.线性回归简介 线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。其表达形式为y = w’x&#43;e，e为误差服从均值为0的正态分布。 回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。
1.1 正态分布 正态分布（Normal distribution），也称“常态分布”，又名高斯分布（Gaussian distribution），最早由A.棣莫弗在求二项分布的渐近公式中得到。C.F.高斯在研究测量误差时从另一个角度导出了它。P.S.拉普拉斯和高斯研究了它的性质。是一个在数学、物理及工程等领域都非常重要的概率分布，在统计学的许多方面有着重大的影响力。 以下两图来自网络 对于正态分布的理解更加简单： 高斯函数是一种常见的概率密度函数，也被称为正态分布函数。具体地说，高斯函数描述了随机变量在某个区间内取值的概率密度，其形式为： $f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ 其中， μ 是均值，σ 是标准差。这个函数的图像呈钟形，且左右对称，最高点位于均值处，随着距离均值越远，函数值逐渐减小。
概率密度函数是用来描述随机变量分布情况的函数，而高斯函数是其中的一种形式。当随机变量服从正态分布时，其概率密度函数就是高斯函数。因此，可以将高斯函数看作是概率密度函数的一种特殊形式。
1.2 Linear Regression线性回归 它是最为人熟知的建模技术之一。线性回归通常是人们在学习预测模型时首选的技术之一。在这种技术中，因变量是连续的，自变量可以是连续的也可以是离散的，回归线的性质是线性的。 线性回归使用最佳的拟合直线（也就是回归线）在因变量（Y）和一个或多个自变量（X）之间建立一种关系。 多元线性回归可表示为Y=a&#43;b1X &#43;b2X2&#43; e，其中a表示截距，b表示直线的斜率，e是误差项。多元线性回归可以根据给定的预测变量（s）来预测目标变量的值。
1.2.1 一元线程回归（简单线性回归） 在统计学中，线性回归是利用称为线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。一个带有一个自变量的线性回归方程代表一条直线。我们需要对线性回归结果进行统计分析 回归线其实可以理解为一条直线，数学表示方式为： Y=b0 &#43; b1X&#43;e 在统计学中，假设有一系列的自变量和因变量的统计数据，可以推算出最佳拟合的b0和b1">
    <meta property="og:url" content="http://localhost:1313/docs/programming/ai/machine_learning/algorithms/action_02_linear/index.html">
    <meta property="og:site_name" content="liaomin416100569博客">
    <meta property="og:title" content="机器学习实战教程（二）：线性回归 :: liaomin416100569博客">
    <meta property="og:description" content="@TOC
1.线性回归简介 线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。其表达形式为y = w’x&#43;e，e为误差服从均值为0的正态分布。 回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。
1.1 正态分布 正态分布（Normal distribution），也称“常态分布”，又名高斯分布（Gaussian distribution），最早由A.棣莫弗在求二项分布的渐近公式中得到。C.F.高斯在研究测量误差时从另一个角度导出了它。P.S.拉普拉斯和高斯研究了它的性质。是一个在数学、物理及工程等领域都非常重要的概率分布，在统计学的许多方面有着重大的影响力。 以下两图来自网络 对于正态分布的理解更加简单： 高斯函数是一种常见的概率密度函数，也被称为正态分布函数。具体地说，高斯函数描述了随机变量在某个区间内取值的概率密度，其形式为： $f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ 其中， μ 是均值，σ 是标准差。这个函数的图像呈钟形，且左右对称，最高点位于均值处，随着距离均值越远，函数值逐渐减小。
概率密度函数是用来描述随机变量分布情况的函数，而高斯函数是其中的一种形式。当随机变量服从正态分布时，其概率密度函数就是高斯函数。因此，可以将高斯函数看作是概率密度函数的一种特殊形式。
1.2 Linear Regression线性回归 它是最为人熟知的建模技术之一。线性回归通常是人们在学习预测模型时首选的技术之一。在这种技术中，因变量是连续的，自变量可以是连续的也可以是离散的，回归线的性质是线性的。 线性回归使用最佳的拟合直线（也就是回归线）在因变量（Y）和一个或多个自变量（X）之间建立一种关系。 多元线性回归可表示为Y=a&#43;b1X &#43;b2X2&#43; e，其中a表示截距，b表示直线的斜率，e是误差项。多元线性回归可以根据给定的预测变量（s）来预测目标变量的值。
1.2.1 一元线程回归（简单线性回归） 在统计学中，线性回归是利用称为线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。一个带有一个自变量的线性回归方程代表一条直线。我们需要对线性回归结果进行统计分析 回归线其实可以理解为一条直线，数学表示方式为： Y=b0 &#43; b1X&#43;e 在统计学中，假设有一系列的自变量和因变量的统计数据，可以推算出最佳拟合的b0和b1">
    <meta property="og:locale" content="zh">
    <meta property="og:type" content="article">
    <meta property="article:section" content="编程开发">
    <meta property="article:published_time" content="2025-09-18T16:55:17+08:00">
    <meta property="article:modified_time" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="name" content="机器学习实战教程（二）：线性回归 :: liaomin416100569博客">
    <meta itemprop="description" content="@TOC
1.线性回归简介 线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。其表达形式为y = w’x&#43;e，e为误差服从均值为0的正态分布。 回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。
1.1 正态分布 正态分布（Normal distribution），也称“常态分布”，又名高斯分布（Gaussian distribution），最早由A.棣莫弗在求二项分布的渐近公式中得到。C.F.高斯在研究测量误差时从另一个角度导出了它。P.S.拉普拉斯和高斯研究了它的性质。是一个在数学、物理及工程等领域都非常重要的概率分布，在统计学的许多方面有着重大的影响力。 以下两图来自网络 对于正态分布的理解更加简单： 高斯函数是一种常见的概率密度函数，也被称为正态分布函数。具体地说，高斯函数描述了随机变量在某个区间内取值的概率密度，其形式为： $f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ 其中， μ 是均值，σ 是标准差。这个函数的图像呈钟形，且左右对称，最高点位于均值处，随着距离均值越远，函数值逐渐减小。
概率密度函数是用来描述随机变量分布情况的函数，而高斯函数是其中的一种形式。当随机变量服从正态分布时，其概率密度函数就是高斯函数。因此，可以将高斯函数看作是概率密度函数的一种特殊形式。
1.2 Linear Regression线性回归 它是最为人熟知的建模技术之一。线性回归通常是人们在学习预测模型时首选的技术之一。在这种技术中，因变量是连续的，自变量可以是连续的也可以是离散的，回归线的性质是线性的。 线性回归使用最佳的拟合直线（也就是回归线）在因变量（Y）和一个或多个自变量（X）之间建立一种关系。 多元线性回归可表示为Y=a&#43;b1X &#43;b2X2&#43; e，其中a表示截距，b表示直线的斜率，e是误差项。多元线性回归可以根据给定的预测变量（s）来预测目标变量的值。
1.2.1 一元线程回归（简单线性回归） 在统计学中，线性回归是利用称为线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。一个带有一个自变量的线性回归方程代表一条直线。我们需要对线性回归结果进行统计分析 回归线其实可以理解为一条直线，数学表示方式为： Y=b0 &#43; b1X&#43;e 在统计学中，假设有一系列的自变量和因变量的统计数据，可以推算出最佳拟合的b0和b1">
    <meta itemprop="datePublished" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="dateModified" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="wordCount" content="323">
    <title>机器学习实战教程（二）：线性回归 :: liaomin416100569博客</title>
    <link href="/docs/css/auto-complete/auto-complete.min.css?1758334729" rel="stylesheet">
    <script src="/docs/js/auto-complete/auto-complete.min.js?1758334729" defer></script>
    <script src="/docs/js/search-lunr.js?1758334729" defer></script>
    <script src="/docs/js/search.js?1758334729" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/docs/searchindex.en.js?1758334729";
    </script>
    <script src="/docs/js/lunr/lunr.min.js?1758334729" defer></script>
    <script src="/docs/js/lunr/lunr.stemmer.support.min.js?1758334729" defer></script>
    <script src="/docs/js/lunr/lunr.multi.min.js?1758334729" defer></script>
    <script src="/docs/js/lunr/lunr.zh.min.js?1758334729" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['zh'];
    </script>
    <link href="/docs/fonts/fontawesome/css/fontawesome-all.min.css?1758334729" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/docs/fonts/fontawesome/css/fontawesome-all.min.css?1758334729" rel="stylesheet"></noscript>
    <link href="/docs/css/perfect-scrollbar/perfect-scrollbar.min.css?1758334729" rel="stylesheet">
    <link href="/docs/css/theme.css?1758334729" rel="stylesheet">
    <link href="/docs/css/format-html.css?1758334729" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/programming\/ai\/machine_learning\/algorithms\/action_02_linear\/index.html';
      window.relearn.relBasePath='..\/..\/..\/..\/..';
      window.relearn.relBaseUri='..\/..\/..\/..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/docs';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
    <link href="/docs/css/custom.css?1758334729" rel="stylesheet">
  </head>
  <body class="mobile-support html" data-url="/docs/programming/ai/machine_learning/algorithms/action_02_linear/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li><a href="#1线性回归简介">1.线性回归简介</a>
      <ul>
        <li><a href="#11-正态分布">1.1 正态分布</a></li>
        <li><a href="#12-linear-regression线性回归">1.2 Linear Regression线性回归</a>
          <ul>
            <li><a href="#121-一元线程回归简单线性回归">1.2.1 一元线程回归（简单线性回归）</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#2线性回归实践">2.线性回归实践</a>
      <ul>
        <li><a href="#21-sklearn数据集介绍">2.1 sklearn数据集介绍</a></li>
        <li><a href="#22-简单线性回归">2.2 简单线性回归</a>
          <ul>
            <li><a href="#221-加载数据集">2.2.1 加载数据集</a></li>
            <li><a href="#222使用线程回归计算系数和截距">2,2.2使用线程回归计算系数和截距</a></li>
          </ul>
        </li>
        <li><a href="#23-多元线性回归">2.3 多元线性回归</a>
          <ul>
            <li><a href="#231-关于系数的可解释性">2.3.1 关于系数的可解释性</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/index.html"><span itemprop="name">liaomin416100569博客</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/index.html"><span itemprop="name">编程开发</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/index.html"><span itemprop="name">人工智能</span></a><meta itemprop="position" content="3">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/machine_learning/index.html"><span itemprop="name">机器学习</span></a><meta itemprop="position" content="4">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/machine_learning/algorithms/index.html"><span itemprop="name">核心算法</span></a><meta itemprop="position" content="5">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">机器学习实战教程（二）：线性回归</span><meta itemprop="position" content="6"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/docs/programming/ai/machine_learning/algorithms/index.html" title="核心算法 (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/docs/programming/ai/machine_learning/tools/index.html" title="实践工具 (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable programming" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="机器学习实战教程二线性回归">机器学习实战教程（二）：线性回归</h1>

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<p>@<a href="%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92">TOC</a></p>
<h1 id="1线性回归简介">1.线性回归简介</h1>
<p>线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。其表达形式为y = w&rsquo;x+e，e为误差服从均值为0的正态分布。
回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。</p>
<h2 id="11-正态分布"><!-- raw HTML omitted -->1.1 正态分布<!-- raw HTML omitted --></h2>
<p>正态分布（Normal distribution），也称“常态分布”，又名高斯分布（Gaussian distribution），最早由A.棣莫弗在求二项分布的渐近公式中得到。C.F.高斯在研究测量误差时从另一个角度导出了它。P.S.拉普拉斯和高斯研究了它的性质。是一个在数学、物理及工程等领域都非常重要的概率分布，在统计学的许多方面有着重大的影响力。
以下两图来自网络 对于正态分布的理解更加简单：
<a href="#R-image-209f3b1588eb8c38e547406e271ac80f" class="lightbox-link"><img alt="正态分布概念" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/cf95f8cb53ad1e2e9b34df26d59d1555.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-209f3b1588eb8c38e547406e271ac80f"><img alt="正态分布概念" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/cf95f8cb53ad1e2e9b34df26d59d1555.png"></a>
<a href="#R-image-3a70439ea7d61b4bb6b001d8cef816fb" class="lightbox-link"><img alt="正态分布密度函数" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/664e88d6c60a33516f00b773736f35b1.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-3a70439ea7d61b4bb6b001d8cef816fb"><img alt="正态分布密度函数" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/664e88d6c60a33516f00b773736f35b1.png"></a>
<a href="#R-image-733c8bff0b334b69fbafd711f58f187b" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/e3fbec55c476d81d3893b611b319d8fa.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-733c8bff0b334b69fbafd711f58f187b"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/e3fbec55c476d81d3893b611b319d8fa.png"></a>
高斯函数是一种常见的概率密度函数，也被称为正态分布函数。具体地说，高斯函数描述了随机变量在某个区间内取值的概率密度，其形式为：
$f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
其中，
μ 是均值，σ 是标准差。这个函数的图像呈钟形，且左右对称，最高点位于均值处，随着距离均值越远，函数值逐渐减小。</p>
<p>概率密度函数是用来描述随机变量分布情况的函数，而高斯函数是其中的一种形式。当随机变量服从正态分布时，其概率密度函数就是高斯函数。因此，可以将高斯函数看作是概率密度函数的一种特殊形式。</p>
<h2 id="12-linear-regression线性回归">1.2 Linear Regression线性回归</h2>
<p>它是最为人熟知的建模技术之一。线性回归通常是人们在学习预测模型时首选的技术之一。在这种技术中，因变量是连续的，自变量可以是连续的也可以是离散的，回归线的性质是线性的。
线性回归使用最佳的拟合直线（也就是回归线）在因变量（Y）和一个或多个自变量（X）之间建立一种关系。
多元线性回归可表示为Y=a+b1X +b2X2+ e，其中a表示截距，b表示直线的斜率，e是误差项。多元线性回归可以根据给定的预测变量（s）来预测目标变量的值。</p>
<h3 id="121-一元线程回归简单线性回归">1.2.1 一元线程回归（简单线性回归）</h3>
<p>在统计学中，线性回归是利用称为线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。一个带有一个自变量的线性回归方程代表一条直线。我们需要对线性回归结果进行统计分析
回归线其实可以理解为一条直线，数学表示方式为：
<!-- raw HTML omitted --><!-- raw HTML omitted -->Y=b0 + b1X+e<!-- raw HTML omitted --><!-- raw HTML omitted -->
在统计学中，假设有一系列的自变量和因变量的统计数据，可以推算出最佳拟合的b0和b1</p>
<ul>
<li>Y - 表示因变量；</li>
<li>X - 表示独立变量；</li>
<li>b0 - 回归线的截距；</li>
<li>b1 - 回归线的斜率 <!-- raw HTML omitted -->参考<!-- raw HTML omitted -->；</li>
<li>e - 误差，预测值和真实值之间的误差；</li>
</ul>
<p>假设我们将数据 （x1， y1），（x2， y2），（x3， y3）…….（xn， yn）的 n 个点拟合到上面的回归线上。
<a href="#R-image-f85f28af72ac63e010bcc4065b45acbf" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/e1bb1c0db00ad04ea649d06a990b85ad.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-f85f28af72ac63e010bcc4065b45acbf"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/e1bb1c0db00ad04ea649d06a990b85ad.png"></a>
其中，ei 是第 i 个观测值与我们回归线预测值之间的差值。
比如 函数 y=3x+5  假设统计数据存在 (5,19),(1,9)。
其中b1=3就是斜率， b0=5就是截距， (5,19)就是第1个值 x1=5 y1=19。
如果明确了函数，当x1=5时 预测的值=3*5+5=20  。
ei=20-19=1 误差为1。
在线性回归中， 我们只有统计数据 下面蓝色的点即为统计数据。
我们需要通过这些蓝色的统计数据 计算出一条最佳的拟合线，计算出截距和斜率。
<a href="#R-image-0c1b61951f694884592ceb0e245b4582" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/9f4a2fed1d5332275e35e5cde20a7adc.jpeg" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-0c1b61951f694884592ceb0e245b4582"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/9f4a2fed1d5332275e35e5cde20a7adc.jpeg"></a>
一般计算就是通过将所有数据的误差平方求和求的最小值也就是最佳的拟合方程
<a href="#R-image-573901da383765cd2e34eb6dbdb04d9e" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/7348c76cf0d606218eaf27167786bbc6.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-573901da383765cd2e34eb6dbdb04d9e"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/7348c76cf0d606218eaf27167786bbc6.png"></a>
我们如何最小化平方误差总和（SSE）呢？
请记住，b1 和 b0 对我们来说仍然是未知的。
在最小二乘法中，我们通过选择 b1 和 b0 的值来最小化平方误差总和（SSE），如下：
<a href="#R-image-3a6a1dd98313ee4b042e4d02f1d7c45e" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/6460040ae59cf4880e5ef07501e18e44.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-3a6a1dd98313ee4b042e4d02f1d7c45e"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/6460040ae59cf4880e5ef07501e18e44.png"></a>
最小二乘法最容易理解解释（https://www.matongxue.com/madocs/818.html）
关于最小二分法需要掌握数学中，导数，极限，偏导概念才能实现推导出该公式
一定要弄明白，请移步梯度下降法解决线性回归问题 ：
<a href="https://blog.csdn.net/liaomin416100569/article/details/84644283" rel="external" target="_blank">https://blog.csdn.net/liaomin416100569/article/details/84644283</a></p>
<h1 id="2线性回归实践">2.线性回归实践</h1>
<p>这里因为懒于自己封装这些公式，使用sklearn已经实现的api来实现</p>
<h2 id="21-sklearn数据集介绍">2.1 sklearn数据集介绍</h2>
<p>sklearn 的数据集有好多种</p>
<ul>
<li>自带的小数据集（packaged dataset）：sklearn.datasets.load_<!-- raw HTML omitted --></li>
<li>可在线下载的数据集（Downloaded Dataset）：sklearn.datasets.fetch_<!-- raw HTML omitted --></li>
<li>计算机生成的数据集（Generated Dataset）：sklearn.datasets.make_<!-- raw HTML omitted --></li>
<li>svmlight/libsvm格式的数据集:sklearn.datasets.load_svmlight_file(&hellip;)</li>
<li>从买了data.org在线下载获取的数据集:sklearn.datasets.fetch_mldata(&hellip;)</li>
</ul>
<p>自带的小数据集（packageddataset）：sklearn.datasets.load_<!-- raw HTML omitted --></p>
<ul>
<li>鸢尾花数据集：load_iris（）：用于分类任务的数据集</li>
<li>手写数字数据集：load_digits（）:用于分类任务或者降维任务的数据集</li>
<li>乳腺癌数据集load-barest-cancer（）：简单经典的用于二分类任务的数据集</li>
<li>糖尿病数据集：load-diabetes（）：经典的用于回归认为的数据集，值得注意的是，这10个特征中的每个特征都   已经被处理成0均值，方差归一化的特征值。</li>
<li>波士顿房价数据集：load-boston（）：经典的用于回归任务的数据集</li>
<li>体能训练数据集：load-linnerud（）：经典的用于多变量回归任务的数据集。</li>
</ul>
<h2 id="22-简单线性回归">2.2 简单线性回归</h2>
<p>这里使用sklearn中提供的波士顿房价 ，房价和房间数量的关系来演示简单线性回归，明显房间数量越多，面积越大，自然房价越高，成正向线性关系。</p>
<h3 id="221-加载数据集">2.2.1 加载数据集</h3>
<p>波士顿房价数据集特征介绍
<a href="#R-image-7c202e8d62e4395f26d16a1af6ed0859" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/0b63f35acd66362ff23cb68400e08019.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-7c202e8d62e4395f26d16a1af6ed0859"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/0b63f35acd66362ff23cb68400e08019.png"></a>
编程加载数据处理</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plot;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sklearn.linear_model <span style="color:#66d9ef">as</span> lm;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sklearn.datasets <span style="color:#66d9ef">as</span> ds;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sklearn.model_selection <span style="color:#66d9ef">as</span> ms;
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  返回一个json数据（结构）
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    data表示房价数据
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    target
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    feature_names 表示每个列的字段名称
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    DESCR 是描述信息
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    filename：存储的数据文件的位置
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  关于该数据所有字段：  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    CRIM：城镇人均犯罪率。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ZN：住宅用地超过 25000 sq.ft. 的比例。   
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    INDUS：城镇非零售商用土地的比例。   
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    CHAS：查理斯河空变量（如果边界是河流，则为1；否则为0）    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    NOX：一氧化氮浓度。  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    RM：住宅平均房间数。   
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    AGE：1940 年之前建成的自用房屋比例。   
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    DIS：到波士顿五个中心区域的加权距离。   
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    RAD：辐射性公路的接近指数。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    TAX：每 10000 美元的全值财产税率。   
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    PTRATIO：城镇师生比例。    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    B：1000（Bk-0.63）^ 2，其中 Bk 指代城镇中黑人的比例。  
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    LSTAT：人口中地位低下者的比例。 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    MEDV：自住房的平均房价，以千美元计。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    target是房价 以千美元计
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>bd<span style="color:#f92672">=</span>ds<span style="color:#f92672">.</span>load_boston();
</span></span><span style="display:flex;"><span><span style="color:#75715e">#获取波士顿房价的所有特征数据</span>
</span></span><span style="display:flex;"><span>data<span style="color:#f92672">=</span>bd<span style="color:#f92672">.</span>data;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#获取每行特征对应的房价</span>
</span></span><span style="display:flex;"><span>label<span style="color:#f92672">=</span>bd<span style="color:#f92672">.</span>target;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#为了演示简单线性回归 获取一个特征</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#RM：住宅平均房间数。</span>
</span></span><span style="display:flex;"><span>nox<span style="color:#f92672">=</span>data[: ,<span style="color:#ae81ff">5</span>:<span style="color:#ae81ff">6</span>]
</span></span><span style="display:flex;"><span><span style="color:#75715e">#将数据拆分成80%的训练数据  20%的测试数据</span>
</span></span><span style="display:flex;"><span>xtrain,xtest,ytrain,ytest<span style="color:#f92672">=</span>ms<span style="color:#f92672">.</span>train_test_split(nox,label,test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>,random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#将 [[4],[2]]这样的特征矩阵转换成 [4,2]这样的向量 绘制散点图</span>
</span></span><span style="display:flex;"><span>plot<span style="color:#f92672">.</span>scatter(xtrain[:,<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>],ytrain,c<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;red&#34;</span>)
</span></span><span style="display:flex;"><span>plot<span style="color:#f92672">.</span>show();</span></span></code></pre></div>
<p>图像效果：
<a href="#R-image-43c4a3957c269d0f52d942d607cb35f9" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/746675b7b8f81ac1aac5323c1ce843c4.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-43c4a3957c269d0f52d942d607cb35f9"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/746675b7b8f81ac1aac5323c1ce843c4.png"></a></p>
<h3 id="222使用线程回归计算系数和截距">2,2.2使用线程回归计算系数和截距</h3>
<p>使用sklearn的LinearRegression类实现机器训练和预测</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#创建线程回归的类</span>
</span></span><span style="display:flex;"><span>lr<span style="color:#f92672">=</span>lm<span style="color:#f92672">.</span>LinearRegression();
</span></span><span style="display:flex;"><span>lr<span style="color:#f92672">.</span>fit(xtrain,ytrain);
</span></span><span style="display:flex;"><span><span style="color:#75715e">#系数也就是斜率</span>
</span></span><span style="display:flex;"><span>print(lr<span style="color:#f92672">.</span>coef_)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#截距</span>
</span></span><span style="display:flex;"><span>print(lr<span style="color:#f92672">.</span>intercept_)
</span></span><span style="display:flex;"><span>plot<span style="color:#f92672">.</span>scatter(xtrain[:,<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>],ytrain,c<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;red&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#绘制 80%的真实数据</span>
</span></span><span style="display:flex;"><span>plot<span style="color:#f92672">.</span>plot(xtrain[:,<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>],xtrain[:,<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]<span style="color:#f92672">*</span>lr<span style="color:#f92672">.</span>coef_<span style="color:#f92672">+</span>lr<span style="color:#f92672">.</span>intercept_);
</span></span><span style="display:flex;"><span>plot<span style="color:#f92672">.</span>show();</span></span></code></pre></div>
<p>得到的散点图和线性方程图下：
<a href="#R-image-6a7a632aaec4cd1542c5bf0f9775793a" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/2c7affbf017eafcb7e4933ac6c73ca95.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-6a7a632aaec4cd1542c5bf0f9775793a"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/2c7affbf017eafcb7e4933ac6c73ca95.png"></a>
注意这里离线较远的点对数据的影响较大 可以选择过滤掉这些 y&gt;50以上的数据</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>xtrain<span style="color:#f92672">=</span>xtrain[ytrain<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">50</span>]
</span></span><span style="display:flex;"><span>ytrain<span style="color:#f92672">=</span>ytrain[ytrain<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">50</span>]</span></span></code></pre></div>
<p>得到图像
<a href="#R-image-3072193cd4dd8e20ca016e142c9f7b98" class="lightbox-link"><img alt="在这里插入图片描述" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/45c963e2ea7bf9a6e04d1bf63a57a9fa.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-3072193cd4dd8e20ca016e142c9f7b98"><img alt="在这里插入图片描述" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/machine_learning/basic/action_02_linear.md.images/45c963e2ea7bf9a6e04d1bf63a57a9fa.png"></a></p>
<h2 id="23-多元线性回归">2.3 多元线性回归</h2>
<p>上面的简单线性回归仅仅是对房间数量一个特征做了预测其实房价本身是由多个因素引起的
多元线性回归模型的一般形式为
Yi=β0+β1X1i+β2X2i+…+βkXki+μi i=1,2,…,n
多元线性回归就是求出这个i个系数  β0是截距
编程实现</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plot;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sklearn.linear_model <span style="color:#66d9ef">as</span> lm;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sklearn.datasets <span style="color:#66d9ef">as</span> ds;
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sklearn.model_selection <span style="color:#66d9ef">as</span> ms;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>bd<span style="color:#f92672">=</span>ds<span style="color:#f92672">.</span>load_boston();
</span></span><span style="display:flex;"><span><span style="color:#75715e">#获取波士顿房价的所有特征数据</span>
</span></span><span style="display:flex;"><span>data<span style="color:#f92672">=</span>bd<span style="color:#f92672">.</span>data;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#获取每行特征对应的房价</span>
</span></span><span style="display:flex;"><span>label<span style="color:#f92672">=</span>bd<span style="color:#f92672">.</span>target;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#将数据拆分成80%的训练数据  20%的测试数据</span>
</span></span><span style="display:flex;"><span>xtrain,xtest,ytrain,ytest<span style="color:#f92672">=</span>ms<span style="color:#f92672">.</span>train_test_split(data,label,test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>,random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>xtrain<span style="color:#f92672">=</span>xtrain[ytrain<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">50</span>]
</span></span><span style="display:flex;"><span>ytrain<span style="color:#f92672">=</span>ytrain[ytrain<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">50</span>]
</span></span><span style="display:flex;"><span>lr<span style="color:#f92672">=</span>lm<span style="color:#f92672">.</span>LinearRegression();
</span></span><span style="display:flex;"><span>lr<span style="color:#f92672">.</span>fit(xtrain,ytrain);
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>set_printoptions(suppress<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>) <span style="color:#75715e">#不使用科学计数法</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#系数也就是斜率</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;所有的系数:&#34;</span>);
</span></span><span style="display:flex;"><span>print(lr<span style="color:#f92672">.</span>coef_)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#截距</span>
</span></span><span style="display:flex;"><span>print(lr<span style="color:#f92672">.</span>intercept_)</span></span></code></pre></div>
<h3 id="231-关于系数的可解释性">2.3.1 关于系数的可解释性</h3>
<p>执行上面的结果得到系数是：</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[ -0.12246473   0.04796854  -0.05495153   0.3323236  -11.35521528
   3.0899128   -0.00873784  -1.19747097   0.24873896  -0.0129233
  -0.72951934   0.0096858   -0.41518496]</code></pre></div>
<p>对这些系数进行排序</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[ 4  7 10 12  0  2  9  6 11  1  8  3  5]</code></pre></div>
<p>第4个特征是  [NOX：一氧化氮浓度。] 是 -11 是负向关系也就是说 NOX越大 房价也就会越低
第5个特征是 [ RM：住宅平均房间数。 ] 是3.08 是正向关系也就是说平均房间数越大 房价也就会越高</p>

  <footer class="footline">
              <i class='fa-fw fas fa-calendar'></i> Sep 18, 2025
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/docs/index.html">
            <div class="logo-title">liaomin416100569博客</div>
          </a>
        </div>
        <search><form action="/docs/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/docs/index.html"><a class="padding" href="/docs/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="parent " data-nav-id="/docs/programming/index.html"><a class="padding" href="/docs/programming/index.html">编程开发</a><ul id="R-subsections-e3fc01b477dbaf64a8f5013a3dab5c5b" class="collapsible-menu">
            <li class="alwaysopen " data-nav-id="/docs/programming/languages/index.html"><a class="padding" href="/docs/programming/languages/index.html">编程语言</a><ul id="R-subsections-1bbde7fb0c312ba940b425df5a4caf67" class="collapsible-menu"></ul></li>
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/index.html"><a class="padding" href="/docs/programming/ai/index.html">人工智能</a><ul id="R-subsections-9d06be7bd8c736c09a65fb0b91b71d0e" class="collapsible-menu">
            <li class="alwaysopen " data-nav-id="/docs/programming/ai/tools_libraries/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/index.html">工具库</a><ul id="R-subsections-e43804740042696aa314af8cc1e28fa9" class="collapsible-menu"></ul></li>
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/machine_learning/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/index.html">机器学习</a><ul id="R-subsections-d3b98ca0beda96811b8c41829d886d7f" class="collapsible-menu">
            <li class="alwaysopen " data-nav-id="/docs/programming/ai/machine_learning/basic/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/basic/index.html">基础理论</a><ul id="R-subsections-2f18a18645b7652a148815c1a6786b18" class="collapsible-menu"></ul></li>
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/machine_learning/algorithms/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/algorithms/index.html">核心算法</a><ul id="R-subsections-921418d1d7190828278c689c88df6881" class="collapsible-menu">
            <li class="active " data-nav-id="/docs/programming/ai/machine_learning/algorithms/action_02_linear/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/algorithms/action_02_linear/index.html">机器学习实战教程（二）：线性回归</a></li></ul></li>
            <li class="" data-nav-id="/docs/programming/ai/machine_learning/tools/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/tools/index.html">实践工具</a></li>
            <li class="" data-nav-id="/docs/programming/ai/machine_learning/evaluation/index.html"><a class="padding" href="/docs/programming/ai/machine_learning/evaluation/index.html">模型评估</a></li></ul></li>
            <li class="alwaysopen " data-nav-id="/docs/programming/ai/deep_learning/index.html"><a class="padding" href="/docs/programming/ai/deep_learning/index.html">深度学习</a><ul id="R-subsections-8e4f2a2c63b9f66a19e3b2a7c957ccda" class="collapsible-menu"></ul></li></ul></li>
            <li class="alwaysopen " data-nav-id="/docs/programming/plugins/index.html"><a class="padding" href="/docs/programming/plugins/index.html">插件开发</a><ul id="R-subsections-de66f54cff99288ca68bfcb5bb0439ae" class="collapsible-menu"></ul></li></ul></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script src="/docs/js/clipboard/clipboard.min.js?1758334729" defer></script>
    <script src="/docs/js/perfect-scrollbar/perfect-scrollbar.min.js?1758334729" defer></script>
    <script src="/docs/js/theme.js?1758334729" defer></script>
  </body>
</html>
