<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>框架学习 :: liaomin416100569博客</title>
    <link>https://jiaozi789.github.io/docs/programming/ai/deep_learning/frameworks/index.html</link>
    <description></description>
    <generator>Hugo</generator>
    <language>zh</language>
    <lastBuildDate>Thu, 18 Sep 2025 16:55:17 +0800</lastBuildDate>
    <atom:link href="https://jiaozi789.github.io/docs/programming/ai/deep_learning/frameworks/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>深度学习01-tensorflow开发环境搭建</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/deep_learning/frameworks/dl_01_tensorflow/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/deep_learning/frameworks/dl_01_tensorflow/index.html</guid>
      <description>@[toc]&#xA;简介 TensorFlow是一种端到端开源机器学习平台，它提供了一个全面而灵活的生态系统，包含各种工具、库和社区资源，能够助力研究人员推动先进机器学习技术的发展。在TensorFlow机器学习框架下，开发者能够轻松地构建和部署由机器学习提供支持的应用。[2]&#xA;Keras是一个高层次神经网络 API，适用于快速构建原型、高级研究和生产。它作为TensorFlow的一个接口，可以兼容多种深度学习框架。Keras 的核心数据结构是 model，一种组织网络层的方式。最简单的模型是 Sequential 顺序模型，它由多个网络层线性堆叠。对于更复杂的结构，你应该使用 Keras 函数式 API，它允许构建任意的神经网络图。 Keras最开始是为研究人员开发的，其目的在于快速实验，具有相同的代码可以在CPU或GPU上无缝切换运行的特点，同时也具有用户友好的API，方便快速地开发深度学习模型的原型。 Keras使用类sklearn的api接口来调用tensorflow，从sklearn机器学习中切换过来，更加容易上手。 Tenforflow2.0后直接内置可keras。&#xA;运行硬件 TensorFlow支持在CPU和GPU上运行。GPU（图形处理单元）是一种专门用于加速计算的硬件，它可以大大提高深度学习模型的训练速度。相对而言，CPU（中央处理器）的每个核心具有更强大的处理能力，但它们的数量通常非常有限，因此在处理大数据时它们表现不佳。&#xA;TensorFlow GPU和CPU的主要区别在于如何使用硬件来处理计算任务，以及处理速度的差异。在CPU上，TensorFlow利用所有可用的CPU内核并将任务分配给它们，这可能需要几分钟或几小时来完成。在GPU上，TensorFlow使用CUDA（Compute Unified Device Architecture）技术来利用GPU进行并行计算并加速训练过程，因为GPU拥有数百到数千个小型核心，这比CPU的几十个核心要多得多。这使得TensorFlow能够在GPU上实现更快的训练速度和更高的吞吐量，尤其是在处理大规模的深度学习任务时。&#xA;另外需要注意的是，如果你的计算机没有安装专门的GPU，则无法使用TensorFlow GPU。在这种情况下，TensorFlow会使用CPU作为默认选项，但是训练过程会比在GPU上慢得多。因此，如果你需要进行大量的深度学习训练任务，建议使用具有至少一张GPU的计算机来加速训练。&#xA;总之，TensorFlow GPU和CPU之间的区别在于它们的硬件架构、并行计算能力以及处理速度等方面。当进行大规模的深度学习训练时，使用GPU可以显著提高训练速度和吞吐量，而对于较小的任务或者没有专门GPU的计算机，则应该使用CPU。&#xA;cuda和cuddn CUDA（Compute Unified Device Architecture）是一种由NVIDIA公司开发的并行计算平台和编程模型，它允许开发人员使用标准C/C++语言编写基于GPU的高性能应用程序。CUDA包括一个可编程的内核语言（CUDA C/C++），一个并行计算库（CUDA Toolkit），以及驱动程序和硬件架构，支持对NVIDIA GPU进行高性能并行计算。与CPU相比，GPU在并行处理任务时的性能要高得多，因此CUDA被广泛用于深度学习、科学计算和高性能计算等领域。[2]&#xA;cuDNN（CUDA Deep Neural Network library）是NVIDIA CUDA的一个加速库，它提供了一组高度优化的本地函数，用于加速深度神经网络模型的训练和推理。cuDNN主要用于卷积神经网络（CNNs）和递归神经网络（RNNs）等深度学习模型的优化，从而实现更快的训练和推理速度。cuDNN支持多种深度学习框架，包括TensorFlow，PyTorch和Caffe等。[1]&#xA;因此，CUDA是一种GPU计算平台和编程模型，cuDNN是其中一个加速库，专门用于加速深度学习模型的训练和推理。这两个技术结合起来，可以实现对GPU的高性能并行计算和深度学习模型的优化，从而提高深度学习任务的整体性能。&#xA;不同的tensorflow版本需要不同的cuda和cuddn版本，google官网可查看 https://tensorflow.google.cn/install/source_windows?hl=en 如果电脑有gpu建议安装tensorflow-gpu,如果电脑没有gpu安装性能较差的tensorflow&#xA;打开任务管理器-性能,查看你是否支持gpu 从这里我们可以看到我的cpu是英伟达(nvidia)的gtx1050 如果电脑已经安装显卡驱动，cuda肯定是自带的，我们可以使用nvidia-smi命令查看</description>
    </item>
    <item>
      <title>深度学习06-pytorch从入门到精通</title>
      <link>https://jiaozi789.github.io/docs/programming/ai/deep_learning/frameworks/dl_06_pytorch/index.html</link>
      <pubDate>Thu, 18 Sep 2025 16:55:17 +0800</pubDate>
      <guid>https://jiaozi789.github.io/docs/programming/ai/deep_learning/frameworks/dl_06_pytorch/index.html</guid>
      <description>概述 PyTorch是一个基于Python的开源机器学习框架，由Facebook的人工智能研究团队开发并维护。它提供了丰富的工具和接口，用于构建和训练深度神经网络模型。&#xA;PyTorch的主要特点和优势包括：&#xA;动态图：PyTorch使用动态图机制，即在运行时构建计算图。这使得模型的构建和调试更加直观和灵活，能够更好地处理复杂的计算流程和动态控制流。&#xA;简洁明了：PyTorch的API设计简洁明了，易于学习和使用。它提供了一系列高级接口，使得模型的构建、训练和评估变得更加简单和高效。&#xA;强大的GPU加速支持：PyTorch能够利用GPU进行张量运算和模型训练，从而加快计算速度。它提供了简单易用的接口，使得在GPU上进行加速变得更加方便。&#xA;灵活扩展：PyTorch支持自定义操作符和扩展，使得用户可以方便地实现和使用自己的模型组件和功能。&#xA;相比之下，TensorFlow是由Google开发的另一个流行的深度学习框架。与PyTorch相比，TensorFlow的主要特点和优势包括：&#xA;静态图：TensorFlow使用静态图机制，即在编译时构建计算图。这使得TensorFlow在模型运行时能够进行更多的优化和性能提升，适用于大规模的、计算密集型的任务。&#xA;跨平台支持：TensorFlow可以在多种硬件和操作系统上运行，并且具有广泛的部署支持。它提供了TensorFlow Serving、TensorFlow Lite和TensorFlow.js等工具，使得模型的部署和移植更加方便。&#xA;分布式训练支持：TensorFlow提供了分布式训练的功能，可以在多个设备和计算节点上进行模型训练，从而加快训练速度。&#xA;生态系统和社区：TensorFlow具有庞大的生态系统和活跃的社区，提供了丰富的资源和支持，包括模型库、教程和论坛等。&#xA;总的来说，PyTorch和TensorFlow都是优秀的深度学习框架，各有其特点和适用场景。PyTorch适合于快速原型开发、动态计算流程和小规模任务，而TensorFlow适合于大规模、计算密集型的任务和分布式训练。选择哪个框架取决于具体的需求和个人偏好。&#xA;对于初学接触神经网络，建议先学pytorch，它提供的api接近理论概念，有动态图，方便调试，适合做研究使用，，由于最近chargpt的大火，Hugging Face的transforms是使用PyTorch的。Hugging Face是一个提供自然语言处理（NLP）模型和工具的平台，他们的Transformers库主要基于PyTorch实现，他的入门pytorch必须要有基础。这个库提供了一系列用于数据预处理和后处理的函数，可以方便地对文本数据进行转换和处理。&#xA;环境准备 安装cuda和cudnn 一般pc电脑或者服务器都有nvida显卡，可以通过nvidia-smi命令查看。 其中python环境（3.8+版本），cuda和cudnn安装请参考：https://blog.csdn.net/liaomin416100569/article/details/130532993 安装后可以看到我的cuda version是11.2&#xA;安装pytorch 考虑到版本向下兼容，不一定非要下载cuda=11.2对应的那个版本的torch，或许低于这个版本就可以。所以我就选择下载cuda11.1的版本。 以下是pytorch对应的稳定版的网址下载链接，可以根据需要找到对应的torch版本下载。cu版本就是gpu版本，不带cu的是cpu版本，https://download.pytorch.org/whl/torch_stable.html，搜索cu111 直接选择&#xA;pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html 编写测试代码&#xA;import torch&#xD;print(torch.__version__)&#xD;#cuda是否可用，如果返回True，表示正常可用gpu&#xD;print(torch.cuda.is_available())&#xD;print(torch.cuda.device_count())&#xD;x1=torch.rand(5,3)&#xD;#把x1转换gpu0的tensor&#xD;x1=x1.cuda(0)&#xD;print(x1) 测试运行</description>
    </item>
  </channel>
</rss>