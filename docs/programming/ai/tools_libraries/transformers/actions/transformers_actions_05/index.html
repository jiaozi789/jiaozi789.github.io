<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/docs/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=docs/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.150.0">
    <meta name="generator" content="Relearn 8.0.1+b23cf6629eada0c2802f34ae4012e04343497862">
    <meta name="description" content="ç®€ä»‹ æ¨¡å‹é‡åŒ–ï¼ˆModel Quantizationï¼‰æ˜¯ä¸€ç§ä¼˜åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨å‡å°‘æœºå™¨å­¦ä¹ æ¨¡å‹çš„è®¡ç®—èµ„æºéœ€æ±‚å’Œå­˜å‚¨ç©ºé—´ï¼ŒåŒæ—¶åœ¨ç²¾åº¦æŸå¤±æœ€å°åŒ–çš„å‰æä¸‹æé«˜æ¨ç†æ•ˆç‡ã€‚é‡åŒ–é€šè¿‡å°†æ¨¡å‹æƒé‡å’Œæ¿€æ´»å‡½æ•°çš„æ•°å€¼ä»é«˜ç²¾åº¦ï¼ˆå¦‚ 32 ä½æµ®ç‚¹æ•°ï¼‰è½¬æ¢ä¸ºä½ç²¾åº¦ï¼ˆå¦‚ 8 ä½æ•´æ•°ï¼‰ï¼Œæ˜¾è‘—å‡å°‘äº†æ¨¡å‹å¤§å°å’Œè®¡ç®—å¤æ‚åº¦ã€‚
ä¸»è¦ç±»å‹ é™æ€é‡åŒ–ï¼ˆPost-Training Quantization, PTQï¼‰
åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆåè¿›è¡Œé‡åŒ–ã€‚ é€šè¿‡åˆ†æè®­ç»ƒæ•°æ®çš„åˆ†å¸ƒï¼Œå°†æƒé‡å’Œæ¿€æ´»å‡½æ•°æ˜ å°„åˆ°ä½ç²¾åº¦è¡¨ç¤ºã€‚ ä¸éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚ é€‚ç”¨äºå¯¹æ€§èƒ½å½±å“è¾ƒå°çš„åœºæ™¯ã€‚ åŠ¨æ€é‡åŒ–ï¼ˆDynamic Quantizationï¼‰
åœ¨æ¨ç†æ—¶åŠ¨æ€åœ°å°†æµ®ç‚¹æ•°è½¬æ¢ä¸ºä½ç²¾åº¦æ•´æ•°ã€‚ åœ¨è¿è¡Œè¿‡ç¨‹ä¸­å¯¹æ¿€æ´»å‡½æ•°è¿›è¡Œé‡åŒ–ã€‚ æ¯”é™æ€é‡åŒ–æ›´ç®€å•ï¼Œå› ä¸ºä¸éœ€è¦åˆ†æè®­ç»ƒæ•°æ®ã€‚ å¯¹æ¨ç†é€Ÿåº¦æœ‰æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯å¯¹æ¨¡å‹è¾“å…¥ä¾èµ–è¾ƒå°‘çš„å±‚ï¼ˆå¦‚å…¨è¿æ¥å±‚ï¼‰ã€‚ é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQuantization-Aware Training, QATï¼‰
åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡æ‹Ÿé‡åŒ–å½±å“ã€‚ æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è€ƒè™‘é‡åŒ–è¯¯å·®ï¼Œä»¥ä¾¿åœ¨é‡åŒ–åä¿æŒæ›´é«˜çš„ç²¾åº¦ã€‚ æ¯”é™æ€é‡åŒ–å’ŒåŠ¨æ€é‡åŒ–éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºï¼Œä½†ç²¾åº¦æŸå¤±æœ€å°ã€‚ é€‚ç”¨äºå¯¹ç²¾åº¦è¦æ±‚è¾ƒé«˜çš„åº”ç”¨ã€‚ è¿™é‡Œä¾‹å­å°±æ¼”ç¤ºä¸‹åŠ¨æ€é‡åŒ–ï¼Œbitsandbytesæœ¬èº«ä»¥ä¸Šä¸‰ç§éƒ½æ”¯æŒã€‚
é‡åŒ–çš„ä¼˜ç‚¹ å‡å°æ¨¡å‹å¤§å°ï¼šé€šè¿‡å°†æƒé‡å’Œæ¿€æ´»å‡½æ•°è¡¨ç¤ºä» 32 ä½æµ®ç‚¹æ•°è½¬æ¢ä¸º 8 ä½æ•´æ•°ï¼Œæ¨¡å‹å¤§å°å¯ä»¥æ˜¾è‘—å‡å°‘ã€‚ åŠ å¿«æ¨ç†é€Ÿåº¦ï¼šä½ç²¾åº¦è¿ç®—é€Ÿåº¦æ›´å¿«ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ¨ç†æ•ˆç‡ã€‚ é™ä½å†…å­˜å¸¦å®½éœ€æ±‚ï¼šä½ç²¾åº¦è¡¨ç¤ºå ç”¨æ›´å°‘çš„å†…å­˜ï¼Œå‡å°‘äº†å†…å­˜å¸¦å®½çš„éœ€æ±‚ã€‚ é‡åŒ–çš„ç¼ºç‚¹ ç²¾åº¦æŸå¤±ï¼šç”±äºæ•°å€¼è¡¨ç¤ºçš„ç²¾åº¦é™ä½ï¼Œæ¨¡å‹å¯èƒ½ä¼šç»å†ä¸€å®šç¨‹åº¦çš„ç²¾åº¦æŸå¤±ï¼Œå…·ä½“ç¨‹åº¦å–å†³äºæ¨¡å‹ç»“æ„å’Œæ•°æ®åˆ†å¸ƒã€‚ å¤æ‚æ€§å¢åŠ ï¼šåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œé‡åŒ–è¿‡ç¨‹å¯èƒ½ä¼šå¢åŠ æ¨¡å‹éƒ¨ç½²çš„å¤æ‚æ€§ï¼Œå°¤å…¶æ˜¯éœ€è¦è¿›è¡Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒæ—¶ã€‚ é‡åŒ–è¿‡ç¨‹ ä»¥ä¸‹è¿‡ç¨‹åªæ˜¯ä¸€ç§æœ€ç®€å•çš„æ€è·¯ï¼Œæ–¹ä¾¿ç†è§£ï¼Œå®é™…è¦æ¯”è¿™æ›´å¤æ‚ã€‚
é‡åŒ–è¿‡ç¨‹ ç¡®å®šå€¼åŸŸï¼š é¦–å…ˆï¼Œç¡®å®šè¦é‡åŒ–çš„æ•°æ®çš„å€¼åŸŸèŒƒå›´ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ç»„æ•°æ®çš„å€¼åŸŸä¸º $[min,max]$ã€‚
ç¡®å®šé‡åŒ–çº§åˆ«ï¼š ç¡®å®šé‡åŒ–çš„çº§åˆ«æˆ–åˆ†è¾¨ç‡ï¼Œè¿™å†³å®šäº†å°†å€¼åŸŸåˆ’åˆ†æˆå¤šå°‘ä¸ªåŒºé—´ã€‚åœ¨4ä½æ•´æ•°çš„æƒ…å†µä¸‹ï¼Œå…±æœ‰ $2^4=16$ ä¸ªå¯èƒ½çš„å€¼ã€‚
çº¿æ€§æ˜ å°„ï¼š å°†åŸå§‹æ•°æ®æ˜ å°„åˆ°4ä½æ•´æ•°çš„èŒƒå›´å†…ã€‚é€šå¸¸ä½¿ç”¨çº¿æ€§æ˜ å°„æ¥å®ç°ï¼Œè®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š $$\text{quantized_value} = \frac{\text{original_value} - \text{min}}{\text{max} - \text{min}} \times (\text{number of levels} - 1)$$
è¿™é‡Œçš„ number of levels æ˜¯16ï¼ˆå¯¹åº”4ä½æ•´æ•°çš„å€¼åŸŸèŒƒå›´ï¼‰ã€‚">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Transformerså®æˆ˜05-æ¨¡å‹é‡åŒ– :: liaomin416100569åšå®¢">
    <meta name="twitter:description" content="ç®€ä»‹ æ¨¡å‹é‡åŒ–ï¼ˆModel Quantizationï¼‰æ˜¯ä¸€ç§ä¼˜åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨å‡å°‘æœºå™¨å­¦ä¹ æ¨¡å‹çš„è®¡ç®—èµ„æºéœ€æ±‚å’Œå­˜å‚¨ç©ºé—´ï¼ŒåŒæ—¶åœ¨ç²¾åº¦æŸå¤±æœ€å°åŒ–çš„å‰æä¸‹æé«˜æ¨ç†æ•ˆç‡ã€‚é‡åŒ–é€šè¿‡å°†æ¨¡å‹æƒé‡å’Œæ¿€æ´»å‡½æ•°çš„æ•°å€¼ä»é«˜ç²¾åº¦ï¼ˆå¦‚ 32 ä½æµ®ç‚¹æ•°ï¼‰è½¬æ¢ä¸ºä½ç²¾åº¦ï¼ˆå¦‚ 8 ä½æ•´æ•°ï¼‰ï¼Œæ˜¾è‘—å‡å°‘äº†æ¨¡å‹å¤§å°å’Œè®¡ç®—å¤æ‚åº¦ã€‚
ä¸»è¦ç±»å‹ é™æ€é‡åŒ–ï¼ˆPost-Training Quantization, PTQï¼‰
åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆåè¿›è¡Œé‡åŒ–ã€‚ é€šè¿‡åˆ†æè®­ç»ƒæ•°æ®çš„åˆ†å¸ƒï¼Œå°†æƒé‡å’Œæ¿€æ´»å‡½æ•°æ˜ å°„åˆ°ä½ç²¾åº¦è¡¨ç¤ºã€‚ ä¸éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚ é€‚ç”¨äºå¯¹æ€§èƒ½å½±å“è¾ƒå°çš„åœºæ™¯ã€‚ åŠ¨æ€é‡åŒ–ï¼ˆDynamic Quantizationï¼‰
åœ¨æ¨ç†æ—¶åŠ¨æ€åœ°å°†æµ®ç‚¹æ•°è½¬æ¢ä¸ºä½ç²¾åº¦æ•´æ•°ã€‚ åœ¨è¿è¡Œè¿‡ç¨‹ä¸­å¯¹æ¿€æ´»å‡½æ•°è¿›è¡Œé‡åŒ–ã€‚ æ¯”é™æ€é‡åŒ–æ›´ç®€å•ï¼Œå› ä¸ºä¸éœ€è¦åˆ†æè®­ç»ƒæ•°æ®ã€‚ å¯¹æ¨ç†é€Ÿåº¦æœ‰æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯å¯¹æ¨¡å‹è¾“å…¥ä¾èµ–è¾ƒå°‘çš„å±‚ï¼ˆå¦‚å…¨è¿æ¥å±‚ï¼‰ã€‚ é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQuantization-Aware Training, QATï¼‰
åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡æ‹Ÿé‡åŒ–å½±å“ã€‚ æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è€ƒè™‘é‡åŒ–è¯¯å·®ï¼Œä»¥ä¾¿åœ¨é‡åŒ–åä¿æŒæ›´é«˜çš„ç²¾åº¦ã€‚ æ¯”é™æ€é‡åŒ–å’ŒåŠ¨æ€é‡åŒ–éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºï¼Œä½†ç²¾åº¦æŸå¤±æœ€å°ã€‚ é€‚ç”¨äºå¯¹ç²¾åº¦è¦æ±‚è¾ƒé«˜çš„åº”ç”¨ã€‚ è¿™é‡Œä¾‹å­å°±æ¼”ç¤ºä¸‹åŠ¨æ€é‡åŒ–ï¼Œbitsandbytesæœ¬èº«ä»¥ä¸Šä¸‰ç§éƒ½æ”¯æŒã€‚
é‡åŒ–çš„ä¼˜ç‚¹ å‡å°æ¨¡å‹å¤§å°ï¼šé€šè¿‡å°†æƒé‡å’Œæ¿€æ´»å‡½æ•°è¡¨ç¤ºä» 32 ä½æµ®ç‚¹æ•°è½¬æ¢ä¸º 8 ä½æ•´æ•°ï¼Œæ¨¡å‹å¤§å°å¯ä»¥æ˜¾è‘—å‡å°‘ã€‚ åŠ å¿«æ¨ç†é€Ÿåº¦ï¼šä½ç²¾åº¦è¿ç®—é€Ÿåº¦æ›´å¿«ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ¨ç†æ•ˆç‡ã€‚ é™ä½å†…å­˜å¸¦å®½éœ€æ±‚ï¼šä½ç²¾åº¦è¡¨ç¤ºå ç”¨æ›´å°‘çš„å†…å­˜ï¼Œå‡å°‘äº†å†…å­˜å¸¦å®½çš„éœ€æ±‚ã€‚ é‡åŒ–çš„ç¼ºç‚¹ ç²¾åº¦æŸå¤±ï¼šç”±äºæ•°å€¼è¡¨ç¤ºçš„ç²¾åº¦é™ä½ï¼Œæ¨¡å‹å¯èƒ½ä¼šç»å†ä¸€å®šç¨‹åº¦çš„ç²¾åº¦æŸå¤±ï¼Œå…·ä½“ç¨‹åº¦å–å†³äºæ¨¡å‹ç»“æ„å’Œæ•°æ®åˆ†å¸ƒã€‚ å¤æ‚æ€§å¢åŠ ï¼šåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œé‡åŒ–è¿‡ç¨‹å¯èƒ½ä¼šå¢åŠ æ¨¡å‹éƒ¨ç½²çš„å¤æ‚æ€§ï¼Œå°¤å…¶æ˜¯éœ€è¦è¿›è¡Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒæ—¶ã€‚ é‡åŒ–è¿‡ç¨‹ ä»¥ä¸‹è¿‡ç¨‹åªæ˜¯ä¸€ç§æœ€ç®€å•çš„æ€è·¯ï¼Œæ–¹ä¾¿ç†è§£ï¼Œå®é™…è¦æ¯”è¿™æ›´å¤æ‚ã€‚
é‡åŒ–è¿‡ç¨‹ ç¡®å®šå€¼åŸŸï¼š é¦–å…ˆï¼Œç¡®å®šè¦é‡åŒ–çš„æ•°æ®çš„å€¼åŸŸèŒƒå›´ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ç»„æ•°æ®çš„å€¼åŸŸä¸º $[min,max]$ã€‚
ç¡®å®šé‡åŒ–çº§åˆ«ï¼š ç¡®å®šé‡åŒ–çš„çº§åˆ«æˆ–åˆ†è¾¨ç‡ï¼Œè¿™å†³å®šäº†å°†å€¼åŸŸåˆ’åˆ†æˆå¤šå°‘ä¸ªåŒºé—´ã€‚åœ¨4ä½æ•´æ•°çš„æƒ…å†µä¸‹ï¼Œå…±æœ‰ $2^4=16$ ä¸ªå¯èƒ½çš„å€¼ã€‚
çº¿æ€§æ˜ å°„ï¼š å°†åŸå§‹æ•°æ®æ˜ å°„åˆ°4ä½æ•´æ•°çš„èŒƒå›´å†…ã€‚é€šå¸¸ä½¿ç”¨çº¿æ€§æ˜ å°„æ¥å®ç°ï¼Œè®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š $$\text{quantized_value} = \frac{\text{original_value} - \text{min}}{\text{max} - \text{min}} \times (\text{number of levels} - 1)$$
è¿™é‡Œçš„ number of levels æ˜¯16ï¼ˆå¯¹åº”4ä½æ•´æ•°çš„å€¼åŸŸèŒƒå›´ï¼‰ã€‚">
    <meta property="og:url" content="http://localhost:1313/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_05/index.html">
    <meta property="og:site_name" content="liaomin416100569åšå®¢">
    <meta property="og:title" content="Transformerså®æˆ˜05-æ¨¡å‹é‡åŒ– :: liaomin416100569åšå®¢">
    <meta property="og:description" content="ç®€ä»‹ æ¨¡å‹é‡åŒ–ï¼ˆModel Quantizationï¼‰æ˜¯ä¸€ç§ä¼˜åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨å‡å°‘æœºå™¨å­¦ä¹ æ¨¡å‹çš„è®¡ç®—èµ„æºéœ€æ±‚å’Œå­˜å‚¨ç©ºé—´ï¼ŒåŒæ—¶åœ¨ç²¾åº¦æŸå¤±æœ€å°åŒ–çš„å‰æä¸‹æé«˜æ¨ç†æ•ˆç‡ã€‚é‡åŒ–é€šè¿‡å°†æ¨¡å‹æƒé‡å’Œæ¿€æ´»å‡½æ•°çš„æ•°å€¼ä»é«˜ç²¾åº¦ï¼ˆå¦‚ 32 ä½æµ®ç‚¹æ•°ï¼‰è½¬æ¢ä¸ºä½ç²¾åº¦ï¼ˆå¦‚ 8 ä½æ•´æ•°ï¼‰ï¼Œæ˜¾è‘—å‡å°‘äº†æ¨¡å‹å¤§å°å’Œè®¡ç®—å¤æ‚åº¦ã€‚
ä¸»è¦ç±»å‹ é™æ€é‡åŒ–ï¼ˆPost-Training Quantization, PTQï¼‰
åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆåè¿›è¡Œé‡åŒ–ã€‚ é€šè¿‡åˆ†æè®­ç»ƒæ•°æ®çš„åˆ†å¸ƒï¼Œå°†æƒé‡å’Œæ¿€æ´»å‡½æ•°æ˜ å°„åˆ°ä½ç²¾åº¦è¡¨ç¤ºã€‚ ä¸éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚ é€‚ç”¨äºå¯¹æ€§èƒ½å½±å“è¾ƒå°çš„åœºæ™¯ã€‚ åŠ¨æ€é‡åŒ–ï¼ˆDynamic Quantizationï¼‰
åœ¨æ¨ç†æ—¶åŠ¨æ€åœ°å°†æµ®ç‚¹æ•°è½¬æ¢ä¸ºä½ç²¾åº¦æ•´æ•°ã€‚ åœ¨è¿è¡Œè¿‡ç¨‹ä¸­å¯¹æ¿€æ´»å‡½æ•°è¿›è¡Œé‡åŒ–ã€‚ æ¯”é™æ€é‡åŒ–æ›´ç®€å•ï¼Œå› ä¸ºä¸éœ€è¦åˆ†æè®­ç»ƒæ•°æ®ã€‚ å¯¹æ¨ç†é€Ÿåº¦æœ‰æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯å¯¹æ¨¡å‹è¾“å…¥ä¾èµ–è¾ƒå°‘çš„å±‚ï¼ˆå¦‚å…¨è¿æ¥å±‚ï¼‰ã€‚ é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQuantization-Aware Training, QATï¼‰
åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡æ‹Ÿé‡åŒ–å½±å“ã€‚ æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è€ƒè™‘é‡åŒ–è¯¯å·®ï¼Œä»¥ä¾¿åœ¨é‡åŒ–åä¿æŒæ›´é«˜çš„ç²¾åº¦ã€‚ æ¯”é™æ€é‡åŒ–å’ŒåŠ¨æ€é‡åŒ–éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºï¼Œä½†ç²¾åº¦æŸå¤±æœ€å°ã€‚ é€‚ç”¨äºå¯¹ç²¾åº¦è¦æ±‚è¾ƒé«˜çš„åº”ç”¨ã€‚ è¿™é‡Œä¾‹å­å°±æ¼”ç¤ºä¸‹åŠ¨æ€é‡åŒ–ï¼Œbitsandbytesæœ¬èº«ä»¥ä¸Šä¸‰ç§éƒ½æ”¯æŒã€‚
é‡åŒ–çš„ä¼˜ç‚¹ å‡å°æ¨¡å‹å¤§å°ï¼šé€šè¿‡å°†æƒé‡å’Œæ¿€æ´»å‡½æ•°è¡¨ç¤ºä» 32 ä½æµ®ç‚¹æ•°è½¬æ¢ä¸º 8 ä½æ•´æ•°ï¼Œæ¨¡å‹å¤§å°å¯ä»¥æ˜¾è‘—å‡å°‘ã€‚ åŠ å¿«æ¨ç†é€Ÿåº¦ï¼šä½ç²¾åº¦è¿ç®—é€Ÿåº¦æ›´å¿«ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ¨ç†æ•ˆç‡ã€‚ é™ä½å†…å­˜å¸¦å®½éœ€æ±‚ï¼šä½ç²¾åº¦è¡¨ç¤ºå ç”¨æ›´å°‘çš„å†…å­˜ï¼Œå‡å°‘äº†å†…å­˜å¸¦å®½çš„éœ€æ±‚ã€‚ é‡åŒ–çš„ç¼ºç‚¹ ç²¾åº¦æŸå¤±ï¼šç”±äºæ•°å€¼è¡¨ç¤ºçš„ç²¾åº¦é™ä½ï¼Œæ¨¡å‹å¯èƒ½ä¼šç»å†ä¸€å®šç¨‹åº¦çš„ç²¾åº¦æŸå¤±ï¼Œå…·ä½“ç¨‹åº¦å–å†³äºæ¨¡å‹ç»“æ„å’Œæ•°æ®åˆ†å¸ƒã€‚ å¤æ‚æ€§å¢åŠ ï¼šåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œé‡åŒ–è¿‡ç¨‹å¯èƒ½ä¼šå¢åŠ æ¨¡å‹éƒ¨ç½²çš„å¤æ‚æ€§ï¼Œå°¤å…¶æ˜¯éœ€è¦è¿›è¡Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒæ—¶ã€‚ é‡åŒ–è¿‡ç¨‹ ä»¥ä¸‹è¿‡ç¨‹åªæ˜¯ä¸€ç§æœ€ç®€å•çš„æ€è·¯ï¼Œæ–¹ä¾¿ç†è§£ï¼Œå®é™…è¦æ¯”è¿™æ›´å¤æ‚ã€‚
é‡åŒ–è¿‡ç¨‹ ç¡®å®šå€¼åŸŸï¼š é¦–å…ˆï¼Œç¡®å®šè¦é‡åŒ–çš„æ•°æ®çš„å€¼åŸŸèŒƒå›´ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ç»„æ•°æ®çš„å€¼åŸŸä¸º $[min,max]$ã€‚
ç¡®å®šé‡åŒ–çº§åˆ«ï¼š ç¡®å®šé‡åŒ–çš„çº§åˆ«æˆ–åˆ†è¾¨ç‡ï¼Œè¿™å†³å®šäº†å°†å€¼åŸŸåˆ’åˆ†æˆå¤šå°‘ä¸ªåŒºé—´ã€‚åœ¨4ä½æ•´æ•°çš„æƒ…å†µä¸‹ï¼Œå…±æœ‰ $2^4=16$ ä¸ªå¯èƒ½çš„å€¼ã€‚
çº¿æ€§æ˜ å°„ï¼š å°†åŸå§‹æ•°æ®æ˜ å°„åˆ°4ä½æ•´æ•°çš„èŒƒå›´å†…ã€‚é€šå¸¸ä½¿ç”¨çº¿æ€§æ˜ å°„æ¥å®ç°ï¼Œè®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š $$\text{quantized_value} = \frac{\text{original_value} - \text{min}}{\text{max} - \text{min}} \times (\text{number of levels} - 1)$$
è¿™é‡Œçš„ number of levels æ˜¯16ï¼ˆå¯¹åº”4ä½æ•´æ•°çš„å€¼åŸŸèŒƒå›´ï¼‰ã€‚">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="ç¼–ç¨‹å¼€å‘">
    <meta property="article:published_time" content="2025-09-18T16:55:17+08:00">
    <meta property="article:modified_time" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="name" content="Transformerså®æˆ˜05-æ¨¡å‹é‡åŒ– :: liaomin416100569åšå®¢">
    <meta itemprop="description" content="ç®€ä»‹ æ¨¡å‹é‡åŒ–ï¼ˆModel Quantizationï¼‰æ˜¯ä¸€ç§ä¼˜åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨å‡å°‘æœºå™¨å­¦ä¹ æ¨¡å‹çš„è®¡ç®—èµ„æºéœ€æ±‚å’Œå­˜å‚¨ç©ºé—´ï¼ŒåŒæ—¶åœ¨ç²¾åº¦æŸå¤±æœ€å°åŒ–çš„å‰æä¸‹æé«˜æ¨ç†æ•ˆç‡ã€‚é‡åŒ–é€šè¿‡å°†æ¨¡å‹æƒé‡å’Œæ¿€æ´»å‡½æ•°çš„æ•°å€¼ä»é«˜ç²¾åº¦ï¼ˆå¦‚ 32 ä½æµ®ç‚¹æ•°ï¼‰è½¬æ¢ä¸ºä½ç²¾åº¦ï¼ˆå¦‚ 8 ä½æ•´æ•°ï¼‰ï¼Œæ˜¾è‘—å‡å°‘äº†æ¨¡å‹å¤§å°å’Œè®¡ç®—å¤æ‚åº¦ã€‚
ä¸»è¦ç±»å‹ é™æ€é‡åŒ–ï¼ˆPost-Training Quantization, PTQï¼‰
åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆåè¿›è¡Œé‡åŒ–ã€‚ é€šè¿‡åˆ†æè®­ç»ƒæ•°æ®çš„åˆ†å¸ƒï¼Œå°†æƒé‡å’Œæ¿€æ´»å‡½æ•°æ˜ å°„åˆ°ä½ç²¾åº¦è¡¨ç¤ºã€‚ ä¸éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚ é€‚ç”¨äºå¯¹æ€§èƒ½å½±å“è¾ƒå°çš„åœºæ™¯ã€‚ åŠ¨æ€é‡åŒ–ï¼ˆDynamic Quantizationï¼‰
åœ¨æ¨ç†æ—¶åŠ¨æ€åœ°å°†æµ®ç‚¹æ•°è½¬æ¢ä¸ºä½ç²¾åº¦æ•´æ•°ã€‚ åœ¨è¿è¡Œè¿‡ç¨‹ä¸­å¯¹æ¿€æ´»å‡½æ•°è¿›è¡Œé‡åŒ–ã€‚ æ¯”é™æ€é‡åŒ–æ›´ç®€å•ï¼Œå› ä¸ºä¸éœ€è¦åˆ†æè®­ç»ƒæ•°æ®ã€‚ å¯¹æ¨ç†é€Ÿåº¦æœ‰æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯å¯¹æ¨¡å‹è¾“å…¥ä¾èµ–è¾ƒå°‘çš„å±‚ï¼ˆå¦‚å…¨è¿æ¥å±‚ï¼‰ã€‚ é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQuantization-Aware Training, QATï¼‰
åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡æ‹Ÿé‡åŒ–å½±å“ã€‚ æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è€ƒè™‘é‡åŒ–è¯¯å·®ï¼Œä»¥ä¾¿åœ¨é‡åŒ–åä¿æŒæ›´é«˜çš„ç²¾åº¦ã€‚ æ¯”é™æ€é‡åŒ–å’ŒåŠ¨æ€é‡åŒ–éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºï¼Œä½†ç²¾åº¦æŸå¤±æœ€å°ã€‚ é€‚ç”¨äºå¯¹ç²¾åº¦è¦æ±‚è¾ƒé«˜çš„åº”ç”¨ã€‚ è¿™é‡Œä¾‹å­å°±æ¼”ç¤ºä¸‹åŠ¨æ€é‡åŒ–ï¼Œbitsandbytesæœ¬èº«ä»¥ä¸Šä¸‰ç§éƒ½æ”¯æŒã€‚
é‡åŒ–çš„ä¼˜ç‚¹ å‡å°æ¨¡å‹å¤§å°ï¼šé€šè¿‡å°†æƒé‡å’Œæ¿€æ´»å‡½æ•°è¡¨ç¤ºä» 32 ä½æµ®ç‚¹æ•°è½¬æ¢ä¸º 8 ä½æ•´æ•°ï¼Œæ¨¡å‹å¤§å°å¯ä»¥æ˜¾è‘—å‡å°‘ã€‚ åŠ å¿«æ¨ç†é€Ÿåº¦ï¼šä½ç²¾åº¦è¿ç®—é€Ÿåº¦æ›´å¿«ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ¨ç†æ•ˆç‡ã€‚ é™ä½å†…å­˜å¸¦å®½éœ€æ±‚ï¼šä½ç²¾åº¦è¡¨ç¤ºå ç”¨æ›´å°‘çš„å†…å­˜ï¼Œå‡å°‘äº†å†…å­˜å¸¦å®½çš„éœ€æ±‚ã€‚ é‡åŒ–çš„ç¼ºç‚¹ ç²¾åº¦æŸå¤±ï¼šç”±äºæ•°å€¼è¡¨ç¤ºçš„ç²¾åº¦é™ä½ï¼Œæ¨¡å‹å¯èƒ½ä¼šç»å†ä¸€å®šç¨‹åº¦çš„ç²¾åº¦æŸå¤±ï¼Œå…·ä½“ç¨‹åº¦å–å†³äºæ¨¡å‹ç»“æ„å’Œæ•°æ®åˆ†å¸ƒã€‚ å¤æ‚æ€§å¢åŠ ï¼šåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œé‡åŒ–è¿‡ç¨‹å¯èƒ½ä¼šå¢åŠ æ¨¡å‹éƒ¨ç½²çš„å¤æ‚æ€§ï¼Œå°¤å…¶æ˜¯éœ€è¦è¿›è¡Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒæ—¶ã€‚ é‡åŒ–è¿‡ç¨‹ ä»¥ä¸‹è¿‡ç¨‹åªæ˜¯ä¸€ç§æœ€ç®€å•çš„æ€è·¯ï¼Œæ–¹ä¾¿ç†è§£ï¼Œå®é™…è¦æ¯”è¿™æ›´å¤æ‚ã€‚
é‡åŒ–è¿‡ç¨‹ ç¡®å®šå€¼åŸŸï¼š é¦–å…ˆï¼Œç¡®å®šè¦é‡åŒ–çš„æ•°æ®çš„å€¼åŸŸèŒƒå›´ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ç»„æ•°æ®çš„å€¼åŸŸä¸º $[min,max]$ã€‚
ç¡®å®šé‡åŒ–çº§åˆ«ï¼š ç¡®å®šé‡åŒ–çš„çº§åˆ«æˆ–åˆ†è¾¨ç‡ï¼Œè¿™å†³å®šäº†å°†å€¼åŸŸåˆ’åˆ†æˆå¤šå°‘ä¸ªåŒºé—´ã€‚åœ¨4ä½æ•´æ•°çš„æƒ…å†µä¸‹ï¼Œå…±æœ‰ $2^4=16$ ä¸ªå¯èƒ½çš„å€¼ã€‚
çº¿æ€§æ˜ å°„ï¼š å°†åŸå§‹æ•°æ®æ˜ å°„åˆ°4ä½æ•´æ•°çš„èŒƒå›´å†…ã€‚é€šå¸¸ä½¿ç”¨çº¿æ€§æ˜ å°„æ¥å®ç°ï¼Œè®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š $$\text{quantized_value} = \frac{\text{original_value} - \text{min}}{\text{max} - \text{min}} \times (\text{number of levels} - 1)$$
è¿™é‡Œçš„ number of levels æ˜¯16ï¼ˆå¯¹åº”4ä½æ•´æ•°çš„å€¼åŸŸèŒƒå›´ï¼‰ã€‚">
    <meta itemprop="datePublished" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="dateModified" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="wordCount" content="756">
    <title>Transformerså®æˆ˜05-æ¨¡å‹é‡åŒ– :: liaomin416100569åšå®¢</title>
    <link href="/docs/css/auto-complete/auto-complete.min.css?1758266232" rel="stylesheet">
    <script src="/docs/js/auto-complete/auto-complete.min.js?1758266232" defer></script>
    <script src="/docs/js/search-lunr.js?1758266232" defer></script>
    <script src="/docs/js/search.js?1758266232" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/docs/searchindex.en.js?1758266232";
    </script>
    <script src="/docs/js/lunr/lunr.min.js?1758266232" defer></script>
    <script src="/docs/js/lunr/lunr.stemmer.support.min.js?1758266232" defer></script>
    <script src="/docs/js/lunr/lunr.multi.min.js?1758266232" defer></script>
    <script src="/docs/js/lunr/lunr.en.min.js?1758266232" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="/docs/fonts/fontawesome/css/fontawesome-all.min.css?1758266232" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/docs/fonts/fontawesome/css/fontawesome-all.min.css?1758266232" rel="stylesheet"></noscript>
    <link href="/docs/css/perfect-scrollbar/perfect-scrollbar.min.css?1758266232" rel="stylesheet">
    <link href="/docs/css/theme.css?1758266232" rel="stylesheet">
    <link href="/docs/css/format-html.css?1758266232" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/programming\/ai\/tools_libraries\/transformers\/actions\/transformers_actions_05\/index.html';
      window.relearn.relBasePath='..\/..\/..\/..\/..\/..';
      window.relearn.relBaseUri='..\/..\/..\/..\/..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/docs';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
    <link href="/docs/css/custom.css?1758266232" rel="stylesheet">
  </head>
  <body class="mobile-support html" data-url="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_05/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li><a href="#ç®€ä»‹">ç®€ä»‹</a>
      <ul>
        <li><a href="#ä¸»è¦ç±»å‹">ä¸»è¦ç±»å‹</a></li>
        <li><a href="#é‡åŒ–çš„ä¼˜ç‚¹">é‡åŒ–çš„ä¼˜ç‚¹</a></li>
        <li><a href="#é‡åŒ–çš„ç¼ºç‚¹">é‡åŒ–çš„ç¼ºç‚¹</a></li>
        <li><a href="#é‡åŒ–è¿‡ç¨‹">é‡åŒ–è¿‡ç¨‹</a>
          <ul>
            <li><a href="#é‡åŒ–è¿‡ç¨‹-1">é‡åŒ–è¿‡ç¨‹</a></li>
            <li><a href="#åé‡åŒ–è¿‡ç¨‹">åé‡åŒ–è¿‡ç¨‹</a></li>
          </ul>
        </li>
        <li><a href="#ç²¾åº¦å’Œå‚æ•°">ç²¾åº¦å’Œå‚æ•°</a></li>
      </ul>
    </li>
    <li><a href="#é‡åŒ–å®ä¾‹">é‡åŒ–å®ä¾‹</a>
      <ul>
        <li><a href="#bitsandbytes">bitsandbytes</a>
          <ul>
            <li><a href="#å®‰è£…bitsandbytes">å®‰è£…bitsandbytes</a></li>
            <li><a href="#4bité‡åŒ–åŠ è½½">4bité‡åŒ–(åŠ è½½)</a></li>
            <li><a href="#8bité‡åŒ–åŠ è½½">8bité‡åŒ–(åŠ è½½)</a></li>
            <li><a href="#éªŒè¯æ•ˆæœ">éªŒè¯æ•ˆæœ</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/index.html"><span itemprop="name">liaomin416100569åšå®¢</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/index.html"><span itemprop="name">ç¼–ç¨‹å¼€å‘</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/index.html"><span itemprop="name">äººå·¥æ™ºèƒ½</span></a><meta itemprop="position" content="3">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/tools_libraries/index.html"><span itemprop="name">å·¥å…·åº“</span></a><meta itemprop="position" content="4">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/tools_libraries/transformers/index.html"><span itemprop="name">transformers</span></a><meta itemprop="position" content="5">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/tools_libraries/transformers/actions/index.html"><span itemprop="name">transformerså®æˆ˜</span></a><meta itemprop="position" content="6">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">Transformerså®æˆ˜05-æ¨¡å‹é‡åŒ–</span><meta itemprop="position" content="7"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_04/index.html" title="Transformerså®æˆ˜04-å¾®è°ƒgpt-2ç”Ÿæˆpythonä»£ç ã€‚ (ğŸ¡)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/docs/programming/plugins/index.html" title="æ’ä»¶å¼€å‘ (ğŸ¡’)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable programming" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="transformerså®æˆ˜05-æ¨¡å‹é‡åŒ–">Transformerså®æˆ˜05-æ¨¡å‹é‡åŒ–</h1>

<h1 id="ç®€ä»‹">ç®€ä»‹</h1>
<p>æ¨¡å‹é‡åŒ–ï¼ˆModel Quantizationï¼‰æ˜¯ä¸€ç§ä¼˜åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨å‡å°‘æœºå™¨å­¦ä¹ æ¨¡å‹çš„è®¡ç®—èµ„æºéœ€æ±‚å’Œå­˜å‚¨ç©ºé—´ï¼ŒåŒæ—¶åœ¨ç²¾åº¦æŸå¤±æœ€å°åŒ–çš„å‰æä¸‹æé«˜æ¨ç†æ•ˆç‡ã€‚é‡åŒ–é€šè¿‡å°†æ¨¡å‹æƒé‡å’Œæ¿€æ´»å‡½æ•°çš„æ•°å€¼ä»é«˜ç²¾åº¦ï¼ˆå¦‚ 32 ä½æµ®ç‚¹æ•°ï¼‰è½¬æ¢ä¸ºä½ç²¾åº¦ï¼ˆå¦‚ 8 ä½æ•´æ•°ï¼‰ï¼Œæ˜¾è‘—å‡å°‘äº†æ¨¡å‹å¤§å°å’Œè®¡ç®—å¤æ‚åº¦ã€‚</p>
<h2 id="ä¸»è¦ç±»å‹">ä¸»è¦ç±»å‹</h2>
<ol>
<li>
<p><strong>é™æ€é‡åŒ–ï¼ˆPost-Training Quantization, PTQï¼‰</strong></p>
<ul>
<li>åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆåè¿›è¡Œé‡åŒ–ã€‚</li>
<li>é€šè¿‡åˆ†æè®­ç»ƒæ•°æ®çš„åˆ†å¸ƒï¼Œå°†æƒé‡å’Œæ¿€æ´»å‡½æ•°æ˜ å°„åˆ°ä½ç²¾åº¦è¡¨ç¤ºã€‚</li>
<li>ä¸éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚</li>
<li>é€‚ç”¨äºå¯¹æ€§èƒ½å½±å“è¾ƒå°çš„åœºæ™¯ã€‚</li>
</ul>
</li>
<li>
<p><strong>åŠ¨æ€é‡åŒ–ï¼ˆDynamic Quantizationï¼‰</strong></p>
<ul>
<li>åœ¨æ¨ç†æ—¶åŠ¨æ€åœ°å°†æµ®ç‚¹æ•°è½¬æ¢ä¸ºä½ç²¾åº¦æ•´æ•°ã€‚</li>
<li>åœ¨è¿è¡Œè¿‡ç¨‹ä¸­å¯¹æ¿€æ´»å‡½æ•°è¿›è¡Œé‡åŒ–ã€‚</li>
<li>æ¯”é™æ€é‡åŒ–æ›´ç®€å•ï¼Œå› ä¸ºä¸éœ€è¦åˆ†æè®­ç»ƒæ•°æ®ã€‚</li>
<li>å¯¹æ¨ç†é€Ÿåº¦æœ‰æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯å¯¹æ¨¡å‹è¾“å…¥ä¾èµ–è¾ƒå°‘çš„å±‚ï¼ˆå¦‚å…¨è¿æ¥å±‚ï¼‰ã€‚</li>
</ul>
</li>
<li>
<p><strong>é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQuantization-Aware Training, QATï¼‰</strong></p>
<ul>
<li>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡æ‹Ÿé‡åŒ–å½±å“ã€‚</li>
<li>æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è€ƒè™‘é‡åŒ–è¯¯å·®ï¼Œä»¥ä¾¿åœ¨é‡åŒ–åä¿æŒæ›´é«˜çš„ç²¾åº¦ã€‚</li>
<li>æ¯”é™æ€é‡åŒ–å’ŒåŠ¨æ€é‡åŒ–éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºï¼Œä½†ç²¾åº¦æŸå¤±æœ€å°ã€‚</li>
<li>é€‚ç”¨äºå¯¹ç²¾åº¦è¦æ±‚è¾ƒé«˜çš„åº”ç”¨ã€‚</li>
</ul>
</li>
</ol>
<p>è¿™é‡Œä¾‹å­å°±æ¼”ç¤ºä¸‹åŠ¨æ€é‡åŒ–ï¼Œbitsandbytesæœ¬èº«ä»¥ä¸Šä¸‰ç§éƒ½æ”¯æŒã€‚</p>
<h2 id="é‡åŒ–çš„ä¼˜ç‚¹">é‡åŒ–çš„ä¼˜ç‚¹</h2>
<ul>
<li><strong>å‡å°æ¨¡å‹å¤§å°</strong>ï¼šé€šè¿‡å°†æƒé‡å’Œæ¿€æ´»å‡½æ•°è¡¨ç¤ºä» 32 ä½æµ®ç‚¹æ•°è½¬æ¢ä¸º 8 ä½æ•´æ•°ï¼Œæ¨¡å‹å¤§å°å¯ä»¥æ˜¾è‘—å‡å°‘ã€‚</li>
<li><strong>åŠ å¿«æ¨ç†é€Ÿåº¦</strong>ï¼šä½ç²¾åº¦è¿ç®—é€Ÿåº¦æ›´å¿«ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ¨ç†æ•ˆç‡ã€‚</li>
<li><strong>é™ä½å†…å­˜å¸¦å®½éœ€æ±‚</strong>ï¼šä½ç²¾åº¦è¡¨ç¤ºå ç”¨æ›´å°‘çš„å†…å­˜ï¼Œå‡å°‘äº†å†…å­˜å¸¦å®½çš„éœ€æ±‚ã€‚</li>
</ul>
<h2 id="é‡åŒ–çš„ç¼ºç‚¹">é‡åŒ–çš„ç¼ºç‚¹</h2>
<ul>
<li><strong>ç²¾åº¦æŸå¤±</strong>ï¼šç”±äºæ•°å€¼è¡¨ç¤ºçš„ç²¾åº¦é™ä½ï¼Œæ¨¡å‹å¯èƒ½ä¼šç»å†ä¸€å®šç¨‹åº¦çš„ç²¾åº¦æŸå¤±ï¼Œå…·ä½“ç¨‹åº¦å–å†³äºæ¨¡å‹ç»“æ„å’Œæ•°æ®åˆ†å¸ƒã€‚</li>
<li><strong>å¤æ‚æ€§å¢åŠ </strong>ï¼šåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œé‡åŒ–è¿‡ç¨‹å¯èƒ½ä¼šå¢åŠ æ¨¡å‹éƒ¨ç½²çš„å¤æ‚æ€§ï¼Œå°¤å…¶æ˜¯éœ€è¦è¿›è¡Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒæ—¶ã€‚</li>
</ul>
<h2 id="é‡åŒ–è¿‡ç¨‹">é‡åŒ–è¿‡ç¨‹</h2>
<p>ä»¥ä¸‹è¿‡ç¨‹åªæ˜¯ä¸€ç§æœ€ç®€å•çš„æ€è·¯ï¼Œæ–¹ä¾¿ç†è§£ï¼Œå®é™…è¦æ¯”è¿™æ›´å¤æ‚ã€‚</p>
<h3 id="é‡åŒ–è¿‡ç¨‹-1">é‡åŒ–è¿‡ç¨‹</h3>
<ol>
<li>
<p><strong>ç¡®å®šå€¼åŸŸï¼š</strong> é¦–å…ˆï¼Œç¡®å®šè¦é‡åŒ–çš„æ•°æ®çš„å€¼åŸŸèŒƒå›´ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ç»„æ•°æ®çš„å€¼åŸŸä¸º $[min,max]$ã€‚</p>
</li>
<li>
<p><strong>ç¡®å®šé‡åŒ–çº§åˆ«ï¼š</strong> ç¡®å®šé‡åŒ–çš„çº§åˆ«æˆ–åˆ†è¾¨ç‡ï¼Œè¿™å†³å®šäº†å°†å€¼åŸŸåˆ’åˆ†æˆå¤šå°‘ä¸ªåŒºé—´ã€‚åœ¨4ä½æ•´æ•°çš„æƒ…å†µä¸‹ï¼Œå…±æœ‰ $2^4=16$ ä¸ªå¯èƒ½çš„å€¼ã€‚</p>
</li>
<li>
<p><strong>çº¿æ€§æ˜ å°„ï¼š</strong> å°†åŸå§‹æ•°æ®æ˜ å°„åˆ°4ä½æ•´æ•°çš„èŒƒå›´å†…ã€‚é€šå¸¸ä½¿ç”¨çº¿æ€§æ˜ å°„æ¥å®ç°ï¼Œè®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š
$$\text{quantized_value} = \frac{\text{original_value} - \text{min}}{\text{max} - \text{min}} \times (\text{number of levels} - 1)$$</p>
</li>
<li>
<p>è¿™é‡Œçš„ number of levels æ˜¯16ï¼ˆå¯¹åº”4ä½æ•´æ•°çš„å€¼åŸŸèŒƒå›´ï¼‰ã€‚</p>
</li>
</ol>
<h3 id="åé‡åŒ–è¿‡ç¨‹">åé‡åŒ–è¿‡ç¨‹</h3>
<p>è§£ç åé‡åŒ–ï¼š åœ¨ä½¿ç”¨é‡åŒ–æ•°æ®è¿›è¡Œè®¡ç®—ä¹‹å‰ï¼Œéœ€è¦å°†å…¶è§£ç å›åŸå§‹çš„æ•°æ®è¡¨ç¤ºå½¢å¼ï¼ˆå¦‚32ä½æµ®ç‚¹æ•°æˆ–å…¶ä»–é«˜ç²¾åº¦è¡¨ç¤ºï¼‰ã€‚è§£ç å…¬å¼é€šå¸¸ä¸ºï¼š
$$\text{original_value} = \text{quantized_value} \times \frac{\text{max} - \text{min}}{\text{number of levels} - 1} + \text{min}$$
è¿™é‡Œçš„ quantized_valueæ˜¯æ˜¯é‡åŒ–åçš„4ä½æ•´æ•°å€¼,minå’Œmaxæ˜¯åŸå§‹æ•°æ®çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ã€‚</p>
<p>ä¸¤ä¸ªä¸åŒçš„åŸå§‹å€¼åœ¨é‡åŒ–åå¯èƒ½ç›¸åŒï¼Œè¢«è¿˜åŸä¸ºåŒä¸€ä¸ªå€¼ã€‚è¿™ç§æƒ…å†µè¡¨æ˜ç²¾åº¦æŸå¤±æ˜¯ä¸å¯é¿å…çš„ã€‚ä¸ºäº†å‡å°‘è¿™ç§ç²¾åº¦æŸå¤±å¸¦æ¥çš„å½±å“ï¼Œé€šå¸¸é‡‡å–ä»¥ä¸‹ç­–ç•¥ï¼š</p>
<ol>
<li>
<p><strong>å¢åŠ é‡åŒ–çº§åˆ«ï¼š</strong> å¢åŠ é‡åŒ–çº§åˆ«ï¼ˆå¦‚ä½¿ç”¨8ä½ã€16ä½é‡åŒ–ï¼‰ä»¥å‡å°‘ä¸åŒåŸå§‹å€¼è¢«é‡åŒ–ä¸ºåŒä¸€ä¸ªå€¼çš„æ¦‚ç‡ã€‚</p>
</li>
<li>
<p><strong>é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQuantization-aware trainingï¼‰ï¼š</strong> åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡æ‹Ÿé‡åŒ–è¯¯å·®ï¼Œä»¥æé«˜æ¨¡å‹åœ¨é‡åŒ–åçš„ç²¾åº¦è¡¨ç°ã€‚</p>
</li>
<li>
<p><strong>éçº¿æ€§é‡åŒ–ï¼š</strong> ä½¿ç”¨å¯¹æ•°é‡åŒ–æˆ–å…¶ä»–éçº¿æ€§é‡åŒ–æ–¹æ³•ï¼Œä½¿å¾—é‡åŒ–æ›´é€‚åº”æ•°æ®çš„åˆ†å¸ƒç‰¹æ€§ï¼Œä»è€Œå‡å°‘ç²¾åº¦æŸå¤±ã€‚</p>
</li>
<li>
<p><strong>ç²¾ç»†è°ƒèŠ‚é‡åŒ–å‚æ•°ï¼š</strong> é€šè¿‡ç²¾ç»†è°ƒæ•´é‡åŒ–çš„æœ€å°å€¼ã€æœ€å¤§å€¼å’Œæ¯”ä¾‹å› å­ï¼Œå°½é‡å‡å°‘é‡åŒ–è¯¯å·®å¯¹å…³é”®å€¼çš„å½±å“ã€‚</p>
</li>
</ol>
<h2 id="ç²¾åº¦å’Œå‚æ•°">ç²¾åº¦å’Œå‚æ•°</h2>
<p>æ¨¡å‹ä¸­æ¯ä¸ªå‚æ•°å¸¸è§çš„å­˜å‚¨ç±»å‹åŒ…æ‹¬ï¼š</p>
<ul>
<li><strong>FP32ï¼ˆ32-bit Floating Pointï¼‰</strong>: æ¯ä¸ªå‚æ•°å ç”¨ 4 å­—èŠ‚ï¼ˆ32 ä½ï¼‰ï¼Œå•ç²¾åº¦æµ®ç‚¹æ•°ï¼ˆ32ä½æµ®ç‚¹æ•°ï¼‰ï¼ŒèŒƒå›´å¤§çº¦ï¼š$[-3.4 \times 10^{38}, 3.4 \times 10^{38}]$ã€‚</li>
<li><strong>FP16ï¼ˆ16-bit Floating Pointï¼‰</strong>: æ¯ä¸ªå‚æ•°å ç”¨ 2 å­—èŠ‚ï¼ˆ16 ä½ï¼‰ï¼ŒåŠç²¾åº¦æµ®ç‚¹æ•°ä½¿ç”¨16ä½ï¼ˆ1ä½ç¬¦å·ã€5ä½æŒ‡æ•°ã€10ä½å°¾æ•°ï¼‰ï¼ŒFP16çš„æ•°å€¼èŒƒå›´å¤§çº¦æ˜¯ [âˆ’65504,65504]ï¼Œå¤§çº¦ 3 ä½æœ‰æ•ˆæ•°å­—ã€‚</li>
<li><strong>INT8ï¼ˆ8-bit Integerï¼‰</strong>: æ¯ä¸ªå‚æ•°å ç”¨ 1 å­—èŠ‚ï¼ˆ8 ä½ï¼‰ï¼Œå°†æ¨¡å‹çš„æƒé‡å’Œæ¿€æ´»å€¼é‡åŒ–ä¸º8ä½æ•´æ•°ï¼ˆèŒƒå›´é€šå¸¸æ˜¯0åˆ°255ï¼‰ï¼Œç›¸å¯¹äº32ä½æµ®ç‚¹æ•°ï¼Œç²¾åº¦çš„æŸå¤±è¾ƒå°ã€‚8-bité‡åŒ–æ¯”4-bitæä¾›æ›´å¥½çš„ç²¾åº¦ï¼Œå¹¶ä¸”é€šå¸¸å¯ä»¥æ›´æ¥è¿‘åŸå§‹æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li><strong>INT4ï¼ˆ4-bit Integerï¼‰</strong>: æ¯ä¸ªå‚æ•°å ç”¨4ä½ï¼Œå°†æ¨¡å‹çš„æƒé‡å’Œæ¿€æ´»å€¼é‡åŒ–ä¸º4ä½æ•´æ•°ï¼ˆèŒƒå›´é€šå¸¸æ˜¯-8åˆ°7æˆ–è€…0åˆ°15ï¼‰ï¼Œå› æ­¤ç›¸å¯¹äº32ä½æµ®ç‚¹æ•°ï¼Œå®ƒçš„ç²¾åº¦æ˜¾è‘—é™ä½ã€‚è¿™ç§é‡åŒ–å¯ä»¥æ˜¾è‘—å‡å°æ¨¡å‹çš„å¤§å°å’Œè®¡ç®—éœ€æ±‚ï¼Œä½†å¯èƒ½ä¼šæŸå¤±ä¸€å®šçš„æ¨¡å‹ç²¾åº¦ã€‚</li>
</ul>
<p>å¦‚ä½•è·å–æŸä¸ªæ¨¡å‹çš„ç²¾åº¦äº†</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>import torch
from transformers import AutoModel, BertTokenizer
model_name=&#34;bert-base-chinese&#34; #bert-base-uncased
model=AutoModel.from_pretrained(model_name)
#è·å–æ¨¡å‹å‚æ•°çš„ç²¾åº¦
&#34;&#34;&#34;
    FP32ï¼ˆ32-bit Floating Pointï¼‰: æ¯ä¸ªå‚æ•°å ç”¨ 4 å­—èŠ‚ï¼ˆ32 ä½ï¼‰ã€‚
    FP16ï¼ˆ16-bit Floating Pointï¼‰: æ¯ä¸ªå‚æ•°å ç”¨ 2 å­—èŠ‚ï¼ˆ16 ä½ï¼‰ã€‚
    INT8ï¼ˆ8-bit Integerï¼‰: æ¯ä¸ªå‚æ•°å ç”¨ 1 å­—èŠ‚ï¼ˆ8 ä½ï¼‰ã€‚
&#34;&#34;&#34;
dtype=list(model.parameters())[0].dtype
print(&#34;ç²¾åº¦:&#34;,dtype)
total_params = sum(p.numel() for p in model.parameters())
dtype_to_bytes = {
    torch.float32: 4,  # FP32: 4å­—èŠ‚
    torch.float16: 2,  # FP16: 2å­—èŠ‚
    torch.int8: 1,     # INT8: 1å­—èŠ‚
    torch.int32: 4,    # INT32: 4å­—èŠ‚
    torch.int64: 8,    # INT64: 8å­—èŠ‚
    torch.float64: 8,  # FP64 (double): 8å­—èŠ‚
}
model_size = total_params * dtype_to_bytes[dtype]
print(f&#39;Model size: {model_size / (1024**2):.2f} MB&#39;)</code></pre></div>
<p>è¾“å‡º</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>ç²¾åº¦: torch.float32
Model size: 390.12 MB</code></pre></div>
<h1 id="é‡åŒ–å®ä¾‹">é‡åŒ–å®ä¾‹</h1>
<h2 id="bitsandbytes">bitsandbytes</h2>
<p>bitsandbytes é€šè¿‡ PyTorch çš„ k ä½é‡åŒ–æŠ€æœ¯ä½¿å¤§å‹è¯­è¨€æ¨¡å‹çš„è®¿é—®å˜å¾—å¯è¡Œã€‚bitsandbytes æä¾›äº†ä¸‰ä¸ªä¸»è¦åŠŸèƒ½ä»¥æ˜¾è‘—é™ä½æ¨ç†å’Œè®­ç»ƒæ—¶çš„å†…å­˜æ¶ˆè€—ï¼š</p>
<ul>
<li>8 ä½ä¼˜åŒ–å™¨é‡‡ç”¨åŒºå—å¼é‡åŒ–æŠ€æœ¯ï¼Œåœ¨æå°çš„å†…å­˜æˆæœ¬ä¸‹ç»´æŒ 32 ä½çš„è¡¨ç°ã€‚</li>
<li>LLM.Int() æˆ– 8 ä½é‡åŒ–ä½¿å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†åªéœ€ä¸€åŠçš„å†…å­˜éœ€æ±‚ï¼Œå¹¶ä¸”ä¸ä¼šæœ‰ä»»ä½•æ€§èƒ½ä¸‹é™ã€‚è¯¥æ–¹æ³•åŸºäºå‘é‡å¼çš„é‡åŒ–æŠ€æœ¯å°†å¤§éƒ¨åˆ†ç‰¹æ€§é‡åŒ–åˆ° 8 ä½ï¼Œå¹¶ä¸”ç”¨ 16 ä½çŸ©é˜µä¹˜æ³•å•ç‹¬å¤„ç†å¼‚å¸¸å€¼ã€‚</li>
<li>QLoRA æˆ– 4 ä½é‡åŒ–ä½¿å¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒæˆä¸ºå¯èƒ½ï¼Œå®ƒç»“åˆäº†å‡ ç§èŠ‚çœå†…å­˜çš„æŠ€æœ¯ï¼ŒåŒæ—¶åˆä¸ç‰ºç‰²æ€§èƒ½ã€‚è¯¥æ–¹æ³•å°†æ¨¡å‹é‡åŒ–è‡³ 4 ä½ï¼Œå¹¶æ’å…¥ä¸€ç»„å¯è®­ç»ƒçš„ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰æƒé‡æ¥å…è®¸è®­ç»ƒã€‚</li>
</ul>
<h3 id="å®‰è£…bitsandbytes">å®‰è£…bitsandbytes</h3>
<p>bitsandbytes ä»…æ”¯æŒ CUDA ç‰ˆæœ¬ 11.0 - 12.5 çš„ CUDA GPUã€‚</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>!pip install -U bitsandbytes
!pip install transformers
!pip install accelerate</code></pre></div>
<h3 id="4bité‡åŒ–åŠ è½½">4bité‡åŒ–(åŠ è½½)</h3>
<p>åŠ è½½å¹¶é‡åŒ–ä¸€ä¸ªæ¨¡å‹åˆ°4ä½ï¼Œå¹¶ä½¿ç”¨bfloat16æ•°æ®ç±»å‹è¿›è¡Œè®¡ç®—ï¼š</p>
<blockquote>
<p>æ‚¨ä½¿ç”¨ bnb_4bit_compute_dtype=torch.bfloat16ï¼Œè¿™æ„å‘³ç€è®¡ç®—è¿‡ç¨‹ä¸­ä¼šåé‡åŒ–ä½¿ç”¨ bfloat16 æ•°æ®ç±»å‹ï¼Œè€Œå­˜å‚¨æ—¶åˆ™å¯èƒ½ä½¿ç”¨4ä½è¡¨ç¤ºã€‚è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆæ‚¨çœ‹åˆ°çš„ dtype ä»ç„¶æ˜¯ fp16 æˆ–è€… bfloat16ã€‚</p></blockquote>
<p>BigScience æ˜¯ä¸€ä¸ªå…¨çƒæ€§çš„å¼€æºAIç ”ç©¶åˆä½œé¡¹ç›®ï¼Œæ—¨åœ¨æ¨åŠ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•ã€‚bloom-1b7 æ˜¯ BigScience é¡¹ç›®ä¸‹çš„ä¸€éƒ¨åˆ†ï¼Œå…·ä½“æ¥è¯´ï¼Œæ˜¯ä¸€ä¸ªåŒ…å«çº¦17äº¿å‚æ•°çš„è¯­è¨€æ¨¡å‹ã€‚</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>import torch
from transformers import AutoModelForCausalLM, BitsAndBytesConfig
model_name=&#34;bigscience/bloom-1b7&#34; 
quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map=&#34;auto&#34;,
)
model_4bit = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map=&#34;auto&#34;,
    quantization_config=quantization_config,
)
dtype=list(model.parameters())[0].dtype
print(&#34;åŸå§‹ç²¾åº¦:&#34;,dtype)
dest_dtype=list(model_4bit.parameters())[0].dtype
print(&#34;é‡åŒ–ç²¾åº¦:&#34;,dest_dtype)

# æ£€æŸ¥æ¨¡å‹çš„é‡åŒ–é…ç½®
print(&#34;é‡åŒ–é…ç½®:&#34;, model_4bit.config.quantization_config)

def print_model_info(model):
    total_params = 0
    for name, param in model.named_parameters():
        total_params += param.numel()
    #print(f&#34;Total parameters: {total_params / 1e6}M&#34;)
    return total_params

total_model_size=print_model_info(model)
total_model_4bit_size=print_model_info(model_4bit)
print(&#34;æ¨¡å‹å‚æ•°ä¸ªæ•°ï¼š&#34;,total_model_size)
print(&#34;é‡åŒ–åçš„æ¨¡å‹å‚æ•°ä¸ªæ•°ï¼š&#34;,total_model_4bit_size)

dtype_to_bytes = {
    torch.float32: 4,  # FP32: 4å­—èŠ‚
    torch.float16: 2,  # FP16: 2å­—èŠ‚
    torch.int8: 1,     # INT8: 1å­—èŠ‚
    torch.int32: 4,    # INT32: 4å­—èŠ‚
    torch.int64: 8,    # INT64: 8å­—èŠ‚
    torch.float64: 8,  # FP64 (double): 8å­—èŠ‚
}
model_size = total_model_size * dtype_to_bytes[dtype]
model_size = total_model_size * dtype_to_bytes[dtype]
print(f&#39;origin Model size: {model_size / (1024**2):.2f} MB&#39;)
model_size = total_model_4bit_size * dtype_to_bytes[dest_dtype]
print(f&#39;quan Model size: {model_size / (1024**2):.2f} MB&#39;)

model_4bit.save_pretrained(&#34;/tmp/p&#34;)
model.save_pretrained(&#34;/tmp/o&#34;)</code></pre></div>
<p>è¾“å‡ºï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>åŸå§‹ç²¾åº¦: torch.float32
é‡åŒ–ç²¾åº¦: torch.float16
é‡åŒ–é…ç½®: BitsAndBytesConfig {
  &#34;_load_in_4bit&#34;: true,
  &#34;_load_in_8bit&#34;: false,
  &#34;bnb_4bit_compute_dtype&#34;: &#34;bfloat16&#34;,
  &#34;bnb_4bit_quant_storage&#34;: &#34;uint8&#34;,
  &#34;bnb_4bit_quant_type&#34;: &#34;fp4&#34;,
  &#34;bnb_4bit_use_double_quant&#34;: false,
  &#34;llm_int8_enable_fp32_cpu_offload&#34;: false,
  &#34;llm_int8_has_fp16_weight&#34;: false,
  &#34;llm_int8_skip_modules&#34;: null,
  &#34;llm_int8_threshold&#34;: 6.0,
  &#34;load_in_4bit&#34;: true,
  &#34;load_in_8bit&#34;: false,
  &#34;quant_method&#34;: &#34;bitsandbytes&#34;
}

æ¨¡å‹å‚æ•°ä¿¡æ¯ï¼š 1722408960
é‡åŒ–åçš„æ¨¡å‹å‚æ•°ä¿¡æ¯ï¼š 1118429184
origin Model size: 6570.47 MB
quan Model size: 2133.23 MB</code></pre></div>
<p>æ€»çš„å‚æ•°ä¸ªæ•°å‡å°‘ã€‚è¿™é€šå¸¸æ˜¯ç”±äºé‡åŒ–è¿‡ç¨‹ä¸­è¿›è¡Œäº†ä¼˜åŒ–æˆ–è€…å‚æ•°å‹ç¼©çš„æ“ä½œã€‚
é‡åŒ–åœ¨æ·±åº¦å­¦ä¹ ä¸­é€šå¸¸æ˜¯æŒ‡å°†æ¨¡å‹ä¸­çš„æµ®ç‚¹æ•°å‚æ•°è½¬æ¢ä¸ºæ›´ä½ç²¾åº¦çš„æ•´æ•°æˆ–å®šç‚¹æ•°è¡¨ç¤ºï¼Œä»¥èŠ‚çœå†…å­˜å’Œæé«˜è®¡ç®—æ•ˆç‡ã€‚</p>
<p>ä¸ºå•¥é‡åŒ–æ¨¡å‹çš„dtypeæ˜¯fp16äº†è€Œä¸æ˜¯int4ï¼Œä»¥ä¸‹æ˜¯å¯¹é‡åŒ–æ¨¡å‹åŠ è½½è¿‡ç¨‹ä¸­ <code>dtype</code> é—®é¢˜çš„ä¸€äº›è§£é‡Šï¼š</p>
<ol>
<li>
<p><strong>å‚æ•°å­˜å‚¨ä¸è®¡ç®—ç±»å‹çš„åŒºåˆ«</strong>ï¼š</p>
<ul>
<li>å­˜å‚¨æ—¶ï¼Œæ¨¡å‹å‚æ•°å¯èƒ½è¢«å‹ç¼©æˆ–é‡åŒ–ä¸ºè¾ƒä½ä½å®½çš„æ•´æ•°ç±»å‹ï¼ˆå¦‚4ä½æ•´æ•°ï¼‰ã€‚</li>
<li>åŠ è½½æ—¶ï¼Œä¸ºäº†æ–¹ä¾¿åç»­è®¡ç®—ï¼Œè¿™äº›å‚æ•°å¯èƒ½ä¼šè¢«è§£ç ä¸ºè¾ƒé«˜ç²¾åº¦çš„æµ®ç‚¹ç±»å‹ï¼ˆå¦‚ <code>fp16</code> æˆ– <code>bfloat16</code>ï¼‰ã€‚</li>
</ul>
</li>
<li>
<p><strong>é‡åŒ–è¿‡ç¨‹çš„å…·ä½“å®ç°</strong>ï¼š</p>
<ul>
<li>è®¸å¤šé‡åŒ–åº“åœ¨åŠ è½½æ¨¡å‹æ—¶ï¼Œä¼šå°†ä½ä½å®½çš„é‡åŒ–å‚æ•°è§£ç ä¸ºæµ®ç‚¹ç±»å‹ï¼Œä»¥ä¾¿åœ¨è®¡ç®—æ—¶å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™äº›å‚æ•°ã€‚</li>
<li>è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå³ä½¿æ‚¨ä½¿ç”¨äº† <code>load_in_4bit=True</code>ï¼Œåœ¨åŠ è½½åæ£€æŸ¥å‚æ•°çš„ <code>dtype</code> æ—¶ä»ç„¶çœ‹åˆ°çš„æ˜¯ <code>fp16</code>ã€‚</li>
</ul>
</li>
</ol>
<p>é€šè¿‡æŸ¥çœ‹æ¨¡å‹ä¿å­˜çš„å°±å¯ä»¥ç¡®å®šäº†
æŸ¥çœ‹é‡åŒ–çš„æ¨¡å‹ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>!ls /tmp/p -al --block-size=M | grep model</code></pre></div>
<p>è¾“å‡º:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>-rw-r--r-- 1 root root 1630M Aug  6 08:04 model.safetensors</code></pre></div>
<p>å¯ä»¥çœ‹åˆ°æˆ‘ä»¬ä¹‹å‰åœ¨å†…å­˜ä¸­æ‰“å°çš„æ˜¯2133.23ï¼ˆå†…å­˜ä¸­è®¡ç®—è¿˜æ˜¯ä¼šè¢«åé‡åŒ–åˆ°bnb_4bit_compute_dtypeæŒ‡å®šç±»å‹ï¼Œä½†æ˜¯å‚æ•°éƒ½æ˜¯å‹ç¼©åå»æ‰äº†ä¸€äº›å‚æ•°ï¼‰ ï¼Œå­˜å‚¨åå˜æˆäº†1630Mï¼Œæ¯”ä¹‹å‰è®¡ç®—çš„å°‘ä¸€äº›ï¼Œè¯´æ˜å­˜å‚¨ä½¿ç”¨äº†4bitã€‚
åœ¨çœ‹ä¸‹æ²¡æœ‰é‡åŒ–çš„æ¨¡å‹ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>!ls /tmp/o -al --block-size=M | grep model</code></pre></div>
<p>è¾“å‡ºäº†ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>-rw-r--r-- 1 root root 4714M Aug  6 08:05 model-00001-of-00002.safetensors
-rw-r--r-- 1 root root 1857M Aug  6 08:05 model-00002-of-00002.safetensors
-rw-r--r-- 1 root root    1M Aug  6 08:05 model.safetensors.index.json</code></pre></div>
<p>å¯ä»¥çœ‹åˆ°æˆ‘ä»¬ä¹‹å‰åœ¨å†…å­˜ä¸­æ‰“å°çš„æ˜¯6570.47 MB ï¼Œå­˜å‚¨åæ²¡å˜ï¼Œåˆ†æ–‡ä»¶å­˜å‚¨äº†4714M+1857M ã€‚</p>
<h3 id="8bité‡åŒ–åŠ è½½">8bité‡åŒ–(åŠ è½½)</h3>
<p>ä»£ç å’Œ4bitç›¸ä¼¼ï¼Œè°ƒæ•´ä¸‹é…ç½®å³å¯</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>quantization_config = BitsAndBytesConfig(load_in_8bit=True)</code></pre></div>
<p>åŒ4bitä»£ç ï¼Œè¾“å‡º</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>åŸå§‹ç²¾åº¦: torch.float32
é‡åŒ–ç²¾åº¦: torch.float16
é‡åŒ–é…ç½®: BitsAndBytesConfig {
  &#34;_load_in_4bit&#34;: false,
  &#34;_load_in_8bit&#34;: true,
  &#34;bnb_4bit_compute_dtype&#34;: &#34;float32&#34;,
  &#34;bnb_4bit_quant_storage&#34;: &#34;uint8&#34;,
  &#34;bnb_4bit_quant_type&#34;: &#34;fp4&#34;,
  &#34;bnb_4bit_use_double_quant&#34;: false,
  &#34;llm_int8_enable_fp32_cpu_offload&#34;: false,
  &#34;llm_int8_has_fp16_weight&#34;: false,
  &#34;llm_int8_skip_modules&#34;: null,
  &#34;llm_int8_threshold&#34;: 6.0,
  &#34;load_in_4bit&#34;: false,
  &#34;load_in_8bit&#34;: true,
  &#34;quant_method&#34;: &#34;bitsandbytes&#34;
}

æ¨¡å‹å‚æ•°ä¿¡æ¯ï¼š 1722408960
é‡åŒ–åçš„æ¨¡å‹å‚æ•°ä¿¡æ¯ï¼š 1722408960
origin Model size: 6570.47 MB
quan Model size: 3285.23 MB</code></pre></div>
<p>å¯ä»¥çœ‹åˆ°8bitä¸éœ€è¦æŒ‡å®šå†…å­˜è®¡ç®—çš„ç±»å‹ï¼Œé‡åŒ–å†…å­˜è®¡ç®—ç²¾åº¦é»˜è®¤å°±æ˜¯fp16ã€‚
æŸ¥çœ‹æ¨¡å‹ä¿å­˜å¤§å°</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>!ls /tmp/p -al --block-size=M | grep model
#----------------------------------------------------------------------------------------------------
!ls /tmp/o -al --block-size=M | grep model</code></pre></div>
<p>è¾“å‡º</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>-rw-r--r-- 1 root root 2135M Aug  6 08:30 model.safetensors
#----------------------------------------------------------------------------------------------------
-rw-r--r-- 1 root root 4714M Aug  6 08:30 model-00001-of-00002.safetensors
-rw-r--r-- 1 root root 1857M Aug  6 08:31 model-00002-of-00002.safetensors
-rw-r--r-- 1 root root    1M Aug  6 08:31 model.safetensors.index.json</code></pre></div>
<h3 id="éªŒè¯æ•ˆæœ">éªŒè¯æ•ˆæœ</h3>
<p>è¿™é‡Œç”¨ä¹‹å‰çš„4bitæ¨¡å‹æ¥å’ŒåŸå§‹æ¨¡å‹æ¯”è¾ƒ</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>import time

def benchmark_model(model, input_text, tokenizer):
    inputs = tokenizer(input_text, return_tensors=&#34;pt&#34;).to(model.device)
    start_time = time.time()
    with torch.no_grad():
        outputs = model.generate(**inputs)
    # è§£ç å¹¶æ‰“å°ç”Ÿæˆçš„æ–‡æœ¬
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    print(&#34;Generated text:&#34;, generated_text)
    end_time = time.time()
    inference_time = end_time - start_time
    print(f&#34;Inference time: {inference_time:.2f} seconds&#34;)

from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(model_name)
input_text = &#34;Hello, how are you?&#34;
print(&#34;æœªé‡åŒ–æ¨¡å‹æ€§èƒ½æµ‹è¯•ï¼š&#34;)
benchmark_model(model, input_text, tokenizer)
print(&#34;é‡åŒ–æ¨¡å‹æ€§èƒ½æµ‹è¯•ï¼š&#34;)
benchmark_model(model_4bit, input_text, tokenizer)</code></pre></div>
<p>è¾“å‡º</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>æœªé‡åŒ–æ¨¡å‹æ€§èƒ½æµ‹è¯•ï¼š
Generated text: Hello, how are you? I hope you are doing well. I am a newbie in this
Inference time: 0.31 seconds
é‡åŒ–æ¨¡å‹æ€§èƒ½æµ‹è¯•ï¼š
Generated text: Hello, how are you?&#34;
&#34;I&#39;m fine,&#34; I said.
&#34;I&#39;m just a
Inference time: 0.62 seconds</code></pre></div>
<p>è¿™é‡Œçœ‹åˆ°é‡åŒ–çš„æ¨¡å‹åè€Œæ¨ç†éœ€è¦æ›´å¤šçš„æ—¶é—´ï¼Œé‡åŒ–æ¨¡å‹åœ¨ç†è®ºä¸Šåº”è¯¥æé«˜æ¨ç†é€Ÿåº¦å’Œå‡å°‘å†…å­˜å ç”¨,è¿™é‡Œä½¿ç”¨float16gpuæ˜¾å­˜å ç”¨è‚¯å®šå°‘äº†ä¸€åŠä»¥ä¸Šï¼Œä½†æ˜¯æ¨ç†é€Ÿåº¦æ¯”è¾ƒæ…¢ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½ä¼šå› ä¸ºå¤šä¸ªå› ç´ å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚</p>

  <footer class="footline">
              <i class='fa-fw fas fa-calendar'></i> Sep 18, 2025
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/docs/index.html">
            <div class="logo-title">liaomin416100569åšå®¢</div>
          </a>
        </div>
        <search><form action="/docs/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/docs/index.html"><a class="padding" href="/docs/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="parent " data-nav-id="/docs/programming/index.html"><a class="padding" href="/docs/programming/index.html">ç¼–ç¨‹å¼€å‘</a><ul id="R-subsections-e3fc01b477dbaf64a8f5013a3dab5c5b" class="collapsible-menu">
            <li class="alwaysopen " data-nav-id="/docs/programming/languages/index.html"><a class="padding" href="/docs/programming/languages/index.html">ç¼–ç¨‹è¯­è¨€</a><ul id="R-subsections-1bbde7fb0c312ba940b425df5a4caf67" class="collapsible-menu"></ul></li>
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/index.html"><a class="padding" href="/docs/programming/ai/index.html">äººå·¥æ™ºèƒ½</a><ul id="R-subsections-9d06be7bd8c736c09a65fb0b91b71d0e" class="collapsible-menu">
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/tools_libraries/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/index.html">å·¥å…·åº“</a><ul id="R-subsections-e43804740042696aa314af8cc1e28fa9" class="collapsible-menu">
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/tools_libraries/transformers/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/index.html">transformers</a><ul id="R-subsections-c93b786975796f9b9f81f28585ce698d" class="collapsible-menu">
            <li class="alwaysopen " data-nav-id="/docs/programming/ai/tools_libraries/transformers/basic/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/basic/index.html">transformersæ¨¡å‹è¯¦è§£</a><ul id="R-subsections-1e672efdff9aa37295341bdd1b243398" class="collapsible-menu"></ul></li>
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/tools_libraries/transformers/actions/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/actions/index.html">transformerså®æˆ˜</a><ul id="R-subsections-7dfd1a2fc9789505d186535459f93268" class="collapsible-menu">
            <li class="" data-nav-id="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_01/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_01/index.html">Transformerså®æˆ˜01-å¼€ç®±å³ç”¨çš„ pipelines</a></li>
            <li class="" data-nav-id="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_02/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_02/index.html">Transformerså®æˆ˜02-BERTé¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ</a></li>
            <li class="" data-nav-id="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_03/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_03/index.html">Transformerså®æˆ˜03-PEFTåº“ä½¿ç”¨LORAæ–¹æ³•å¾®è°ƒVITå›¾åƒåˆ†ç±»ã€‚</a></li>
            <li class="" data-nav-id="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_04/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_04/index.html">Transformerså®æˆ˜04-å¾®è°ƒgpt-2ç”Ÿæˆpythonä»£ç ã€‚</a></li>
            <li class="active " data-nav-id="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_05/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/actions/transformers_actions_05/index.html">Transformerså®æˆ˜05-æ¨¡å‹é‡åŒ–</a></li></ul></li></ul></li></ul></li></ul></li>
            <li class="alwaysopen " data-nav-id="/docs/programming/plugins/index.html"><a class="padding" href="/docs/programming/plugins/index.html">æ’ä»¶å¼€å‘</a><ul id="R-subsections-de66f54cff99288ca68bfcb5bb0439ae" class="collapsible-menu"></ul></li></ul></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script src="/docs/js/clipboard/clipboard.min.js?1758266232" defer></script>
    <script src="/docs/js/perfect-scrollbar/perfect-scrollbar.min.js?1758266232" defer></script>
    <script src="/docs/js/theme.js?1758266232" defer></script>
  </body>
</html>
