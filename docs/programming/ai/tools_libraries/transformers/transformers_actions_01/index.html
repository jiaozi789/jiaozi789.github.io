<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/docs/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=docs/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.150.0">
    <meta name="generator" content="Relearn 8.0.1+b23cf6629eada0c2802f34ae4012e04343497862">
    <meta name="description" content="ç®€ä»‹ Hugging Face Hugging Faceæ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å…¬å¸ï¼Œå®ƒè‡´åŠ›äºå¼€å‘å’Œæ¨å¹¿è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ç›¸å…³çš„æŠ€æœ¯å’Œå·¥å…·ã€‚è¯¥å…¬å¸ä»¥å…¶å¼€æºé¡¹ç›®å’Œç¤¾åŒºè€Œé—»åï¼Œå…¶æœ€çŸ¥åçš„é¡¹ç›®ä¹‹ä¸€æ˜¯Transformersåº“ï¼Œå®ƒæä¾›äº†ä¸€ç³»åˆ—é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬BERTã€GPTå’ŒRoBERTaç­‰ã€‚è¿™äº›æ¨¡å‹å·²ç»åœ¨å„ç§NLPä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œå¹¶æˆä¸ºäº†è®¸å¤šç ”ç©¶å’Œå·¥ä¸šåº”ç”¨çš„åŸºç¡€ã€‚
é™¤äº†æä¾›é¢„è®­ç»ƒçš„æ¨¡å‹ä¹‹å¤–ï¼ŒHugging Faceè¿˜å¼€å‘äº†ä¸€ç³»åˆ—å·¥å…·å’Œå¹³å°ï¼Œä½¿å¾—ä½¿ç”¨å’Œéƒ¨ç½²è¿™äº›æ¨¡å‹å˜å¾—æ›´åŠ ç®€å•ã€‚å…¶ä¸­åŒ…æ‹¬ï¼š
Transformersåº“ï¼šæä¾›äº†å„ç§é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹çš„æ¥å£å’Œå·¥å…·ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥è½»æ¾åœ°ä½¿ç”¨è¿™äº›æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€è¯­è¨€ç”Ÿæˆç­‰ä»»åŠ¡ã€‚
Datasetsåº“ï¼šåŒ…å«äº†å„ç§NLPæ•°æ®é›†çš„æ¥å£å’Œå·¥å…·ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨è¿™äº›æ•°æ®é›†è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ã€‚
Traineråº“ï¼šæä¾›äº†ä¸€ä¸ªè®­ç»ƒå’Œå¾®è°ƒæ¨¡å‹çš„æ¡†æ¶ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šçš„ä»»åŠ¡å’Œåº”ç”¨åœºæ™¯ã€‚
Model Hubï¼šä¸€ä¸ªæ¨¡å‹åˆ†äº«å’Œå‘å¸ƒå¹³å°ï¼Œå¼€å‘è€…å¯ä»¥åœ¨è¿™é‡Œåˆ†äº«è‡ªå·±è®­ç»ƒçš„æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥æ‰¾åˆ°å…¶ä»–äººåˆ†äº«çš„æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥ç›´æ¥åœ¨è‡ªå·±çš„é¡¹ç›®ä¸­ä½¿ç”¨è¿™äº›æ¨¡å‹ã€‚
datasetsæ•°æ®é›†å¤„ç†ï¼Œtransformersé¢„è®­ç»ƒå¾®è°ƒç­‰ç›¸å…³æ•™ç¨‹è¯·å‚è€ƒå®˜ç½‘hugging faceå®˜æ–¹æ–‡æ¡£ã€‚
Transformers Transformers æ˜¯ç”± Hugging Face å¼€å‘çš„ä¸€ä¸ª NLP åŒ…ï¼Œæ”¯æŒåŠ è½½ç›®å‰ç»å¤§éƒ¨åˆ†çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚éšç€ BERTã€GPT ç­‰å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å…´èµ·ï¼Œè¶Šæ¥è¶Šå¤šçš„å…¬å¸å’Œç ”ç©¶è€…é‡‡ç”¨ Transformers åº“æ¥æ„å»º NLP åº”ç”¨ï¼Œå®˜ç½‘åœ°å€ã€‚ å®ƒæä¾›äº†å„ç§é¢„è®­ç»ƒçš„ Transformer æ¨¡å‹ï¼ŒåŒ…æ‹¬ BERTã€GPTã€RoBERTaã€DistilBERT ç­‰ã€‚è¿™äº›æ¨¡å‹åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾—äº† state-of-the-art çš„æ€§èƒ½ï¼Œå¹¶ä¸” Transformers åº“æä¾›äº†ç®€å•æ˜“ç”¨çš„æ¥å£ï¼Œä½¿å¾—ä½¿ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹å˜å¾—éå¸¸ä¾¿æ·ã€‚
å®‰è£… å®˜ç½‘å®‰è£…æ•™ç¨‹å‚è€ƒï¼šhttps://huggingface.co/docs/transformers/installation
æ‚¨å¯ä»¥é€šè¿‡ pip å®‰è£… Transformers åº“ã€‚åœ¨ç»ˆç«¯æˆ–å‘½ä»¤è¡Œç•Œé¢ä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼ˆæˆ‘è¿™é‡Œä½¿ç”¨pytorchï¼Œå¦‚æœéœ€è¦tensorflowçš„ç‰ˆæœ¬å‚è€ƒå®˜ç½‘ï¼‰ï¼š
pip install &#39;transformers[torch]&#39;
è¿™å°†ä¼šè‡ªåŠ¨ä» PyPIï¼ˆPython Package Indexï¼‰ä¸‹è½½å¹¶å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ Transformers åº“åŠå…¶ä¾èµ–é¡¹ã€‚
å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ Anaconda ç¯å¢ƒï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ conda å®‰è£…ï¼š
conda install -c huggingface transformers
è¿™å°†ä¼šä» Anaconda ä»“åº“ä¸­ä¸‹è½½å¹¶å®‰è£… Transformers åº“åŠå…¶ä¾èµ–é¡¹ã€‚">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Transformerså®æˆ˜01-å¼€ç®±å³ç”¨çš„ pipelines :: liaomin416100569åšå®¢">
    <meta name="twitter:description" content="ç®€ä»‹ Hugging Face Hugging Faceæ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å…¬å¸ï¼Œå®ƒè‡´åŠ›äºå¼€å‘å’Œæ¨å¹¿è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ç›¸å…³çš„æŠ€æœ¯å’Œå·¥å…·ã€‚è¯¥å…¬å¸ä»¥å…¶å¼€æºé¡¹ç›®å’Œç¤¾åŒºè€Œé—»åï¼Œå…¶æœ€çŸ¥åçš„é¡¹ç›®ä¹‹ä¸€æ˜¯Transformersåº“ï¼Œå®ƒæä¾›äº†ä¸€ç³»åˆ—é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬BERTã€GPTå’ŒRoBERTaç­‰ã€‚è¿™äº›æ¨¡å‹å·²ç»åœ¨å„ç§NLPä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œå¹¶æˆä¸ºäº†è®¸å¤šç ”ç©¶å’Œå·¥ä¸šåº”ç”¨çš„åŸºç¡€ã€‚
é™¤äº†æä¾›é¢„è®­ç»ƒçš„æ¨¡å‹ä¹‹å¤–ï¼ŒHugging Faceè¿˜å¼€å‘äº†ä¸€ç³»åˆ—å·¥å…·å’Œå¹³å°ï¼Œä½¿å¾—ä½¿ç”¨å’Œéƒ¨ç½²è¿™äº›æ¨¡å‹å˜å¾—æ›´åŠ ç®€å•ã€‚å…¶ä¸­åŒ…æ‹¬ï¼š
Transformersåº“ï¼šæä¾›äº†å„ç§é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹çš„æ¥å£å’Œå·¥å…·ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥è½»æ¾åœ°ä½¿ç”¨è¿™äº›æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€è¯­è¨€ç”Ÿæˆç­‰ä»»åŠ¡ã€‚
Datasetsåº“ï¼šåŒ…å«äº†å„ç§NLPæ•°æ®é›†çš„æ¥å£å’Œå·¥å…·ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨è¿™äº›æ•°æ®é›†è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ã€‚
Traineråº“ï¼šæä¾›äº†ä¸€ä¸ªè®­ç»ƒå’Œå¾®è°ƒæ¨¡å‹çš„æ¡†æ¶ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šçš„ä»»åŠ¡å’Œåº”ç”¨åœºæ™¯ã€‚
Model Hubï¼šä¸€ä¸ªæ¨¡å‹åˆ†äº«å’Œå‘å¸ƒå¹³å°ï¼Œå¼€å‘è€…å¯ä»¥åœ¨è¿™é‡Œåˆ†äº«è‡ªå·±è®­ç»ƒçš„æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥æ‰¾åˆ°å…¶ä»–äººåˆ†äº«çš„æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥ç›´æ¥åœ¨è‡ªå·±çš„é¡¹ç›®ä¸­ä½¿ç”¨è¿™äº›æ¨¡å‹ã€‚
datasetsæ•°æ®é›†å¤„ç†ï¼Œtransformersé¢„è®­ç»ƒå¾®è°ƒç­‰ç›¸å…³æ•™ç¨‹è¯·å‚è€ƒå®˜ç½‘hugging faceå®˜æ–¹æ–‡æ¡£ã€‚
Transformers Transformers æ˜¯ç”± Hugging Face å¼€å‘çš„ä¸€ä¸ª NLP åŒ…ï¼Œæ”¯æŒåŠ è½½ç›®å‰ç»å¤§éƒ¨åˆ†çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚éšç€ BERTã€GPT ç­‰å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å…´èµ·ï¼Œè¶Šæ¥è¶Šå¤šçš„å…¬å¸å’Œç ”ç©¶è€…é‡‡ç”¨ Transformers åº“æ¥æ„å»º NLP åº”ç”¨ï¼Œå®˜ç½‘åœ°å€ã€‚ å®ƒæä¾›äº†å„ç§é¢„è®­ç»ƒçš„ Transformer æ¨¡å‹ï¼ŒåŒ…æ‹¬ BERTã€GPTã€RoBERTaã€DistilBERT ç­‰ã€‚è¿™äº›æ¨¡å‹åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾—äº† state-of-the-art çš„æ€§èƒ½ï¼Œå¹¶ä¸” Transformers åº“æä¾›äº†ç®€å•æ˜“ç”¨çš„æ¥å£ï¼Œä½¿å¾—ä½¿ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹å˜å¾—éå¸¸ä¾¿æ·ã€‚
å®‰è£… å®˜ç½‘å®‰è£…æ•™ç¨‹å‚è€ƒï¼šhttps://huggingface.co/docs/transformers/installation
æ‚¨å¯ä»¥é€šè¿‡ pip å®‰è£… Transformers åº“ã€‚åœ¨ç»ˆç«¯æˆ–å‘½ä»¤è¡Œç•Œé¢ä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼ˆæˆ‘è¿™é‡Œä½¿ç”¨pytorchï¼Œå¦‚æœéœ€è¦tensorflowçš„ç‰ˆæœ¬å‚è€ƒå®˜ç½‘ï¼‰ï¼š
pip install &#39;transformers[torch]&#39;
è¿™å°†ä¼šè‡ªåŠ¨ä» PyPIï¼ˆPython Package Indexï¼‰ä¸‹è½½å¹¶å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ Transformers åº“åŠå…¶ä¾èµ–é¡¹ã€‚
å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ Anaconda ç¯å¢ƒï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ conda å®‰è£…ï¼š
conda install -c huggingface transformers
è¿™å°†ä¼šä» Anaconda ä»“åº“ä¸­ä¸‹è½½å¹¶å®‰è£… Transformers åº“åŠå…¶ä¾èµ–é¡¹ã€‚">
    <meta property="og:url" content="http://localhost:1313/docs/programming/ai/tools_libraries/transformers/transformers_actions_01/index.html">
    <meta property="og:site_name" content="liaomin416100569åšå®¢">
    <meta property="og:title" content="Transformerså®æˆ˜01-å¼€ç®±å³ç”¨çš„ pipelines :: liaomin416100569åšå®¢">
    <meta property="og:description" content="ç®€ä»‹ Hugging Face Hugging Faceæ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å…¬å¸ï¼Œå®ƒè‡´åŠ›äºå¼€å‘å’Œæ¨å¹¿è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ç›¸å…³çš„æŠ€æœ¯å’Œå·¥å…·ã€‚è¯¥å…¬å¸ä»¥å…¶å¼€æºé¡¹ç›®å’Œç¤¾åŒºè€Œé—»åï¼Œå…¶æœ€çŸ¥åçš„é¡¹ç›®ä¹‹ä¸€æ˜¯Transformersåº“ï¼Œå®ƒæä¾›äº†ä¸€ç³»åˆ—é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬BERTã€GPTå’ŒRoBERTaç­‰ã€‚è¿™äº›æ¨¡å‹å·²ç»åœ¨å„ç§NLPä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œå¹¶æˆä¸ºäº†è®¸å¤šç ”ç©¶å’Œå·¥ä¸šåº”ç”¨çš„åŸºç¡€ã€‚
é™¤äº†æä¾›é¢„è®­ç»ƒçš„æ¨¡å‹ä¹‹å¤–ï¼ŒHugging Faceè¿˜å¼€å‘äº†ä¸€ç³»åˆ—å·¥å…·å’Œå¹³å°ï¼Œä½¿å¾—ä½¿ç”¨å’Œéƒ¨ç½²è¿™äº›æ¨¡å‹å˜å¾—æ›´åŠ ç®€å•ã€‚å…¶ä¸­åŒ…æ‹¬ï¼š
Transformersåº“ï¼šæä¾›äº†å„ç§é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹çš„æ¥å£å’Œå·¥å…·ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥è½»æ¾åœ°ä½¿ç”¨è¿™äº›æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€è¯­è¨€ç”Ÿæˆç­‰ä»»åŠ¡ã€‚
Datasetsåº“ï¼šåŒ…å«äº†å„ç§NLPæ•°æ®é›†çš„æ¥å£å’Œå·¥å…·ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨è¿™äº›æ•°æ®é›†è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ã€‚
Traineråº“ï¼šæä¾›äº†ä¸€ä¸ªè®­ç»ƒå’Œå¾®è°ƒæ¨¡å‹çš„æ¡†æ¶ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šçš„ä»»åŠ¡å’Œåº”ç”¨åœºæ™¯ã€‚
Model Hubï¼šä¸€ä¸ªæ¨¡å‹åˆ†äº«å’Œå‘å¸ƒå¹³å°ï¼Œå¼€å‘è€…å¯ä»¥åœ¨è¿™é‡Œåˆ†äº«è‡ªå·±è®­ç»ƒçš„æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥æ‰¾åˆ°å…¶ä»–äººåˆ†äº«çš„æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥ç›´æ¥åœ¨è‡ªå·±çš„é¡¹ç›®ä¸­ä½¿ç”¨è¿™äº›æ¨¡å‹ã€‚
datasetsæ•°æ®é›†å¤„ç†ï¼Œtransformersé¢„è®­ç»ƒå¾®è°ƒç­‰ç›¸å…³æ•™ç¨‹è¯·å‚è€ƒå®˜ç½‘hugging faceå®˜æ–¹æ–‡æ¡£ã€‚
Transformers Transformers æ˜¯ç”± Hugging Face å¼€å‘çš„ä¸€ä¸ª NLP åŒ…ï¼Œæ”¯æŒåŠ è½½ç›®å‰ç»å¤§éƒ¨åˆ†çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚éšç€ BERTã€GPT ç­‰å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å…´èµ·ï¼Œè¶Šæ¥è¶Šå¤šçš„å…¬å¸å’Œç ”ç©¶è€…é‡‡ç”¨ Transformers åº“æ¥æ„å»º NLP åº”ç”¨ï¼Œå®˜ç½‘åœ°å€ã€‚ å®ƒæä¾›äº†å„ç§é¢„è®­ç»ƒçš„ Transformer æ¨¡å‹ï¼ŒåŒ…æ‹¬ BERTã€GPTã€RoBERTaã€DistilBERT ç­‰ã€‚è¿™äº›æ¨¡å‹åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾—äº† state-of-the-art çš„æ€§èƒ½ï¼Œå¹¶ä¸” Transformers åº“æä¾›äº†ç®€å•æ˜“ç”¨çš„æ¥å£ï¼Œä½¿å¾—ä½¿ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹å˜å¾—éå¸¸ä¾¿æ·ã€‚
å®‰è£… å®˜ç½‘å®‰è£…æ•™ç¨‹å‚è€ƒï¼šhttps://huggingface.co/docs/transformers/installation
æ‚¨å¯ä»¥é€šè¿‡ pip å®‰è£… Transformers åº“ã€‚åœ¨ç»ˆç«¯æˆ–å‘½ä»¤è¡Œç•Œé¢ä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼ˆæˆ‘è¿™é‡Œä½¿ç”¨pytorchï¼Œå¦‚æœéœ€è¦tensorflowçš„ç‰ˆæœ¬å‚è€ƒå®˜ç½‘ï¼‰ï¼š
pip install &#39;transformers[torch]&#39;
è¿™å°†ä¼šè‡ªåŠ¨ä» PyPIï¼ˆPython Package Indexï¼‰ä¸‹è½½å¹¶å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ Transformers åº“åŠå…¶ä¾èµ–é¡¹ã€‚
å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ Anaconda ç¯å¢ƒï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ conda å®‰è£…ï¼š
conda install -c huggingface transformers
è¿™å°†ä¼šä» Anaconda ä»“åº“ä¸­ä¸‹è½½å¹¶å®‰è£… Transformers åº“åŠå…¶ä¾èµ–é¡¹ã€‚">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="ç¼–ç¨‹å¼€å‘">
    <meta property="article:published_time" content="2025-09-18T16:55:17+08:00">
    <meta property="article:modified_time" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="name" content="Transformerså®æˆ˜01-å¼€ç®±å³ç”¨çš„ pipelines :: liaomin416100569åšå®¢">
    <meta itemprop="description" content="ç®€ä»‹ Hugging Face Hugging Faceæ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å…¬å¸ï¼Œå®ƒè‡´åŠ›äºå¼€å‘å’Œæ¨å¹¿è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ç›¸å…³çš„æŠ€æœ¯å’Œå·¥å…·ã€‚è¯¥å…¬å¸ä»¥å…¶å¼€æºé¡¹ç›®å’Œç¤¾åŒºè€Œé—»åï¼Œå…¶æœ€çŸ¥åçš„é¡¹ç›®ä¹‹ä¸€æ˜¯Transformersåº“ï¼Œå®ƒæä¾›äº†ä¸€ç³»åˆ—é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬BERTã€GPTå’ŒRoBERTaç­‰ã€‚è¿™äº›æ¨¡å‹å·²ç»åœ¨å„ç§NLPä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œå¹¶æˆä¸ºäº†è®¸å¤šç ”ç©¶å’Œå·¥ä¸šåº”ç”¨çš„åŸºç¡€ã€‚
é™¤äº†æä¾›é¢„è®­ç»ƒçš„æ¨¡å‹ä¹‹å¤–ï¼ŒHugging Faceè¿˜å¼€å‘äº†ä¸€ç³»åˆ—å·¥å…·å’Œå¹³å°ï¼Œä½¿å¾—ä½¿ç”¨å’Œéƒ¨ç½²è¿™äº›æ¨¡å‹å˜å¾—æ›´åŠ ç®€å•ã€‚å…¶ä¸­åŒ…æ‹¬ï¼š
Transformersåº“ï¼šæä¾›äº†å„ç§é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹çš„æ¥å£å’Œå·¥å…·ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥è½»æ¾åœ°ä½¿ç”¨è¿™äº›æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€è¯­è¨€ç”Ÿæˆç­‰ä»»åŠ¡ã€‚
Datasetsåº“ï¼šåŒ…å«äº†å„ç§NLPæ•°æ®é›†çš„æ¥å£å’Œå·¥å…·ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨è¿™äº›æ•°æ®é›†è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ã€‚
Traineråº“ï¼šæä¾›äº†ä¸€ä¸ªè®­ç»ƒå’Œå¾®è°ƒæ¨¡å‹çš„æ¡†æ¶ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šçš„ä»»åŠ¡å’Œåº”ç”¨åœºæ™¯ã€‚
Model Hubï¼šä¸€ä¸ªæ¨¡å‹åˆ†äº«å’Œå‘å¸ƒå¹³å°ï¼Œå¼€å‘è€…å¯ä»¥åœ¨è¿™é‡Œåˆ†äº«è‡ªå·±è®­ç»ƒçš„æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥æ‰¾åˆ°å…¶ä»–äººåˆ†äº«çš„æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥ç›´æ¥åœ¨è‡ªå·±çš„é¡¹ç›®ä¸­ä½¿ç”¨è¿™äº›æ¨¡å‹ã€‚
datasetsæ•°æ®é›†å¤„ç†ï¼Œtransformersé¢„è®­ç»ƒå¾®è°ƒç­‰ç›¸å…³æ•™ç¨‹è¯·å‚è€ƒå®˜ç½‘hugging faceå®˜æ–¹æ–‡æ¡£ã€‚
Transformers Transformers æ˜¯ç”± Hugging Face å¼€å‘çš„ä¸€ä¸ª NLP åŒ…ï¼Œæ”¯æŒåŠ è½½ç›®å‰ç»å¤§éƒ¨åˆ†çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚éšç€ BERTã€GPT ç­‰å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å…´èµ·ï¼Œè¶Šæ¥è¶Šå¤šçš„å…¬å¸å’Œç ”ç©¶è€…é‡‡ç”¨ Transformers åº“æ¥æ„å»º NLP åº”ç”¨ï¼Œå®˜ç½‘åœ°å€ã€‚ å®ƒæä¾›äº†å„ç§é¢„è®­ç»ƒçš„ Transformer æ¨¡å‹ï¼ŒåŒ…æ‹¬ BERTã€GPTã€RoBERTaã€DistilBERT ç­‰ã€‚è¿™äº›æ¨¡å‹åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾—äº† state-of-the-art çš„æ€§èƒ½ï¼Œå¹¶ä¸” Transformers åº“æä¾›äº†ç®€å•æ˜“ç”¨çš„æ¥å£ï¼Œä½¿å¾—ä½¿ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹å˜å¾—éå¸¸ä¾¿æ·ã€‚
å®‰è£… å®˜ç½‘å®‰è£…æ•™ç¨‹å‚è€ƒï¼šhttps://huggingface.co/docs/transformers/installation
æ‚¨å¯ä»¥é€šè¿‡ pip å®‰è£… Transformers åº“ã€‚åœ¨ç»ˆç«¯æˆ–å‘½ä»¤è¡Œç•Œé¢ä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼ˆæˆ‘è¿™é‡Œä½¿ç”¨pytorchï¼Œå¦‚æœéœ€è¦tensorflowçš„ç‰ˆæœ¬å‚è€ƒå®˜ç½‘ï¼‰ï¼š
pip install &#39;transformers[torch]&#39;
è¿™å°†ä¼šè‡ªåŠ¨ä» PyPIï¼ˆPython Package Indexï¼‰ä¸‹è½½å¹¶å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ Transformers åº“åŠå…¶ä¾èµ–é¡¹ã€‚
å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ Anaconda ç¯å¢ƒï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ conda å®‰è£…ï¼š
conda install -c huggingface transformers
è¿™å°†ä¼šä» Anaconda ä»“åº“ä¸­ä¸‹è½½å¹¶å®‰è£… Transformers åº“åŠå…¶ä¾èµ–é¡¹ã€‚">
    <meta itemprop="datePublished" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="dateModified" content="2025-09-18T16:55:17+08:00">
    <meta itemprop="wordCount" content="1622">
    <title>Transformerså®æˆ˜01-å¼€ç®±å³ç”¨çš„ pipelines :: liaomin416100569åšå®¢</title>
    <link href="/docs/css/auto-complete/auto-complete.min.css?1758265020" rel="stylesheet">
    <script src="/docs/js/auto-complete/auto-complete.min.js?1758265020" defer></script>
    <script src="/docs/js/search-lunr.js?1758265020" defer></script>
    <script src="/docs/js/search.js?1758265020" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/docs/searchindex.en.js?1758265020";
    </script>
    <script src="/docs/js/lunr/lunr.min.js?1758265020" defer></script>
    <script src="/docs/js/lunr/lunr.stemmer.support.min.js?1758265020" defer></script>
    <script src="/docs/js/lunr/lunr.multi.min.js?1758265020" defer></script>
    <script src="/docs/js/lunr/lunr.en.min.js?1758265020" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="/docs/fonts/fontawesome/css/fontawesome-all.min.css?1758265020" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/docs/fonts/fontawesome/css/fontawesome-all.min.css?1758265020" rel="stylesheet"></noscript>
    <link href="/docs/css/perfect-scrollbar/perfect-scrollbar.min.css?1758265020" rel="stylesheet">
    <link href="/docs/css/theme.css?1758265020" rel="stylesheet">
    <link href="/docs/css/format-html.css?1758265020" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/programming\/ai\/tools_libraries\/transformers\/transformers_actions_01\/index.html';
      window.relearn.relBasePath='..\/..\/..\/..\/..';
      window.relearn.relBaseUri='..\/..\/..\/..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/docs';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
    <link href="/docs/css/custom.css?1758265020" rel="stylesheet">
  </head>
  <body class="mobile-support html" data-url="/docs/programming/ai/tools_libraries/transformers/transformers_actions_01/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li><a href="#ç®€ä»‹">ç®€ä»‹</a>
      <ul>
        <li><a href="#hugging-face">Hugging Face</a></li>
        <li><a href="#transformers">Transformers</a></li>
      </ul>
    </li>
    <li><a href="#å®‰è£…">å®‰è£…</a></li>
    <li><a href="#æ¨¡å‹">æ¨¡å‹</a>
      <ul>
        <li><a href="#æ–‡ä»¶ç»“æ„">æ–‡ä»¶ç»“æ„</a></li>
      </ul>
    </li>
    <li><a href="#pipelines">pipelines</a>
      <ul>
        <li><a href="#å›¾ç‰‡è½¬æ–‡æœ¬">å›¾ç‰‡è½¬æ–‡æœ¬</a></li>
        <li><a href="#æ–‡æœ¬ç”Ÿæˆ">æ–‡æœ¬ç”Ÿæˆ</a></li>
        <li><a href="#æƒ…æ„Ÿåˆ†æ">æƒ…æ„Ÿåˆ†æ</a></li>
        <li><a href="#é›¶è®­ç»ƒæ ·æœ¬åˆ†ç±»">é›¶è®­ç»ƒæ ·æœ¬åˆ†ç±»</a></li>
        <li><a href="#é®ç›–è¯å¡«å……">é®ç›–è¯å¡«å……</a></li>
        <li><a href="#å‘½åå®ä½“è¯†åˆ«">å‘½åå®ä½“è¯†åˆ«</a></li>
        <li><a href="#è‡ªåŠ¨é—®ç­”">è‡ªåŠ¨é—®ç­”</a></li>
        <li><a href="#è‡ªåŠ¨æ‘˜è¦">è‡ªåŠ¨æ‘˜è¦</a></li>
      </ul>
    </li>
    <li><a href="#pipeline-èƒŒååšäº†ä»€ä¹ˆ">pipeline èƒŒååšäº†ä»€ä¹ˆï¼Ÿ</a>
      <ul>
        <li><a href="#ä½¿ç”¨åˆ†è¯å™¨è¿›è¡Œé¢„å¤„ç†">ä½¿ç”¨åˆ†è¯å™¨è¿›è¡Œé¢„å¤„ç†</a></li>
        <li><a href="#å°†é¢„å¤„ç†å¥½çš„è¾“å…¥é€å…¥æ¨¡å‹">å°†é¢„å¤„ç†å¥½çš„è¾“å…¥é€å…¥æ¨¡å‹</a>
          <ul>
            <li><a href="#transformersåº“ç»“æ„">Transformersåº“ç»“æ„</a></li>
            <li><a href="#æ¨¡å—è¾“å‡º">æ¨¡å—è¾“å‡º</a></li>
          </ul>
        </li>
        <li><a href="#å¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œåå¤„ç†">å¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œåå¤„ç†</a></li>
      </ul>
    </li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/index.html"><span itemprop="name">liaomin416100569åšå®¢</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/index.html"><span itemprop="name">ç¼–ç¨‹å¼€å‘</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/tools_libraries/index.html"><span itemprop="name">å·¥å…·åº“</span></a><meta itemprop="position" content="3">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/docs/programming/ai/tools_libraries/transformers/index.html"><span itemprop="name">transformers</span></a><meta itemprop="position" content="4">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">Transformerså®æˆ˜01-å¼€ç®±å³ç”¨çš„ pipelines</span><meta itemprop="position" content="5"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/docs/programming/ai/tools_libraries/transformers/actions/index.html" title="transformerså®æˆ˜ (ğŸ¡)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/docs/programming/ai/tools_libraries/transformers/transformers_actions_02/index.html" title="Transformerså®æˆ˜02-BERTé¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ (ğŸ¡’)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable programming" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="transformerså®æˆ˜01-å¼€ç®±å³ç”¨çš„-pipelines">Transformerså®æˆ˜01-å¼€ç®±å³ç”¨çš„ pipelines</h1>

<h1 id="ç®€ä»‹">ç®€ä»‹</h1>
<h2 id="hugging-face">Hugging Face</h2>
<p>Hugging Faceæ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å…¬å¸ï¼Œå®ƒè‡´åŠ›äºå¼€å‘å’Œæ¨å¹¿è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ç›¸å…³çš„æŠ€æœ¯å’Œå·¥å…·ã€‚è¯¥å…¬å¸ä»¥å…¶å¼€æºé¡¹ç›®å’Œç¤¾åŒºè€Œé—»åï¼Œå…¶æœ€çŸ¥åçš„é¡¹ç›®ä¹‹ä¸€æ˜¯Transformersåº“ï¼Œå®ƒæä¾›äº†ä¸€ç³»åˆ—é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬BERTã€GPTå’ŒRoBERTaç­‰ã€‚è¿™äº›æ¨¡å‹å·²ç»åœ¨å„ç§NLPä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œå¹¶æˆä¸ºäº†è®¸å¤šç ”ç©¶å’Œå·¥ä¸šåº”ç”¨çš„åŸºç¡€ã€‚</p>
<p>é™¤äº†æä¾›é¢„è®­ç»ƒçš„æ¨¡å‹ä¹‹å¤–ï¼ŒHugging Faceè¿˜å¼€å‘äº†ä¸€ç³»åˆ—å·¥å…·å’Œå¹³å°ï¼Œä½¿å¾—ä½¿ç”¨å’Œéƒ¨ç½²è¿™äº›æ¨¡å‹å˜å¾—æ›´åŠ ç®€å•ã€‚å…¶ä¸­åŒ…æ‹¬ï¼š</p>
<ol>
<li>
<p><strong>Transformersåº“</strong>ï¼šæä¾›äº†å„ç§é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹çš„æ¥å£å’Œå·¥å…·ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥è½»æ¾åœ°ä½¿ç”¨è¿™äº›æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€è¯­è¨€ç”Ÿæˆç­‰ä»»åŠ¡ã€‚</p>
</li>
<li>
<p><strong>Datasetsåº“</strong>ï¼šåŒ…å«äº†å„ç§NLPæ•°æ®é›†çš„æ¥å£å’Œå·¥å…·ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨è¿™äº›æ•°æ®é›†è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ã€‚</p>
</li>
<li>
<p><strong>Traineråº“</strong>ï¼šæä¾›äº†ä¸€ä¸ªè®­ç»ƒå’Œå¾®è°ƒæ¨¡å‹çš„æ¡†æ¶ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šçš„ä»»åŠ¡å’Œåº”ç”¨åœºæ™¯ã€‚</p>
</li>
<li>
<p><strong>Model Hub</strong>ï¼šä¸€ä¸ªæ¨¡å‹åˆ†äº«å’Œå‘å¸ƒå¹³å°ï¼Œå¼€å‘è€…å¯ä»¥åœ¨è¿™é‡Œåˆ†äº«è‡ªå·±è®­ç»ƒçš„æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥æ‰¾åˆ°å…¶ä»–äººåˆ†äº«çš„æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥ç›´æ¥åœ¨è‡ªå·±çš„é¡¹ç›®ä¸­ä½¿ç”¨è¿™äº›æ¨¡å‹ã€‚</p>
</li>
</ol>
<p>datasetsæ•°æ®é›†å¤„ç†ï¼Œtransformersé¢„è®­ç»ƒå¾®è°ƒç­‰ç›¸å…³æ•™ç¨‹è¯·å‚è€ƒå®˜ç½‘hugging face<a href="https://huggingface.co/docs" rel="external" target="_blank">å®˜æ–¹æ–‡æ¡£</a>ã€‚</p>
<h2 id="transformers">Transformers</h2>
<p>Transformers æ˜¯ç”± Hugging Face å¼€å‘çš„ä¸€ä¸ª NLP åŒ…ï¼Œæ”¯æŒåŠ è½½ç›®å‰ç»å¤§éƒ¨åˆ†çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚éšç€ BERTã€GPT ç­‰å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å…´èµ·ï¼Œè¶Šæ¥è¶Šå¤šçš„å…¬å¸å’Œç ”ç©¶è€…é‡‡ç”¨ Transformers åº“æ¥æ„å»º NLP åº”ç”¨ï¼Œ<a href="https://huggingface.co/docs/transformers/index" rel="external" target="_blank">å®˜ç½‘åœ°å€</a>ã€‚
å®ƒæä¾›äº†å„ç§é¢„è®­ç»ƒçš„ Transformer æ¨¡å‹ï¼ŒåŒ…æ‹¬ BERTã€GPTã€RoBERTaã€DistilBERT ç­‰ã€‚è¿™äº›æ¨¡å‹åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå–å¾—äº† state-of-the-art çš„æ€§èƒ½ï¼Œå¹¶ä¸” Transformers åº“æä¾›äº†ç®€å•æ˜“ç”¨çš„æ¥å£ï¼Œä½¿å¾—ä½¿ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹å˜å¾—éå¸¸ä¾¿æ·ã€‚</p>
<h1 id="å®‰è£…">å®‰è£…</h1>
<p>å®˜ç½‘å®‰è£…æ•™ç¨‹å‚è€ƒï¼šhttps://huggingface.co/docs/transformers/installation</p>
<p>æ‚¨å¯ä»¥é€šè¿‡ pip å®‰è£… Transformers åº“ã€‚åœ¨ç»ˆç«¯æˆ–å‘½ä»¤è¡Œç•Œé¢ä¸­æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼ˆæˆ‘è¿™é‡Œä½¿ç”¨pytorchï¼Œå¦‚æœéœ€è¦tensorflowçš„ç‰ˆæœ¬å‚è€ƒå®˜ç½‘ï¼‰ï¼š</p>
<p><code>pip install 'transformers[torch]'</code></p>
<p>è¿™å°†ä¼šè‡ªåŠ¨ä» PyPIï¼ˆPython Package Indexï¼‰ä¸‹è½½å¹¶å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ Transformers åº“åŠå…¶ä¾èµ–é¡¹ã€‚</p>
<p>å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ Anaconda ç¯å¢ƒï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ conda å®‰è£…ï¼š</p>
<p><code>conda install -c huggingface transformers</code></p>
<p>è¿™å°†ä¼šä» Anaconda ä»“åº“ä¸­ä¸‹è½½å¹¶å®‰è£… Transformers åº“åŠå…¶ä¾èµ–é¡¹ã€‚</p>
<p>å®‰è£…å®Œæˆåï¼Œæ‚¨å°±å¯ä»¥åœ¨ Python ç¯å¢ƒä¸­ä½¿ç”¨ Transformers åº“äº†ã€‚æ‚¨å¯ä»¥ç¼–å†™ä»£ç æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ã€æ‰§è¡Œå„ç§ NLP ä»»åŠ¡ï¼Œæˆ–è€…ä½¿ç”¨ Transformers æä¾›çš„é«˜çº§ APIï¼Œå¦‚ pipelines æ¥å¿«é€Ÿå®Œæˆä»»åŠ¡ã€‚</p>
<h1 id="æ¨¡å‹">æ¨¡å‹</h1>
<p>è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ¨¡å‹æ˜¯æŒ‡ç”¨äºå¤„ç†å’Œç†è§£è‡ªç„¶è¯­è¨€æ–‡æœ¬çš„è®¡ç®—æœºæ¨¡å‹ã€‚è¿™äº›æ¨¡å‹çš„è®¾è®¡å’Œè®­ç»ƒæ—¨åœ¨ä½¿è®¡ç®—æœºèƒ½å¤Ÿè‡ªåŠ¨å¤„ç†å’Œåˆ†æè¯­è¨€æ•°æ®ï¼Œä»¥æ‰§è¡Œå„ç§è¯­è¨€ç›¸å…³çš„ä»»åŠ¡ã€‚ä»¥ä¸‹æ˜¯å‡ ç§å¸¸è§çš„NLPæ¨¡å‹ç±»å‹åŠå…¶åŠŸèƒ½ï¼š</p>
<ol>
<li>
<p><strong>åŸºäºè§„åˆ™çš„æ¨¡å‹</strong>ï¼šè¿™äº›æ¨¡å‹ä½¿ç”¨æ‰‹å·¥åˆ¶å®šçš„è§„åˆ™å’Œè§„åˆ™é›†æ¥å¤„ç†æ–‡æœ¬ï¼Œä¾‹å¦‚è¯­æ³•åˆ†ææˆ–å…³é”®è¯æå–ã€‚è¿™ç§æ–¹æ³•çš„å±€é™æ€§åœ¨äºéœ€è¦å¤§é‡çš„äººå·¥å·¥ä½œå’Œéš¾ä»¥å¤„ç†çš„å¤æ‚æ€§ã€‚</p>
</li>
<li>
<p><strong>åŸºäºç»Ÿè®¡çš„æ¨¡å‹</strong>ï¼šè¿™äº›æ¨¡å‹åˆ©ç”¨ç»Ÿè®¡å­¦ä¹ æŠ€æœ¯ä»å¤§é‡æ–‡æœ¬æ•°æ®ä¸­å­¦ä¹ è¯­è¨€æ¨¡å¼å’Œè§„å¾‹ã€‚ä¾‹å¦‚ï¼Œn-gramè¯­è¨€æ¨¡å‹å¯ä»¥é¢„æµ‹ç»™å®šå•è¯åºåˆ—çš„ä¸‹ä¸€ä¸ªå•è¯ï¼Œè€Œéšé©¬å°”å¯å¤«æ¨¡å‹åˆ™ç”¨äºè¯æ€§æ ‡æ³¨å’Œè¯­éŸ³è¯†åˆ«ã€‚</p>
</li>
<li>
<p><strong>ç¥ç»ç½‘ç»œæ¨¡å‹</strong>ï¼šéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼Œç¥ç»ç½‘ç»œåœ¨NLPä¸­çš„åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›ã€‚è¿™äº›æ¨¡å‹ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œç»“æ„æ¥å­¦ä¹ å¤æ‚çš„è¯­è¨€ç‰¹å¾å’Œæ¨¡å¼ã€‚ä¾‹å¦‚ï¼Œé€’å½’ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ã€é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰å’Œå˜å‹å™¨ï¼ˆTransformerï¼‰ç­‰æ¨¡å‹å·²ç»åœ¨æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆã€æƒ…æ„Ÿåˆ†æç­‰ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆå°±ã€‚</p>
</li>
<li>
<p><strong>é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹</strong>ï¼šè¿™äº›æ¨¡å‹é€šè¿‡åœ¨å¤§è§„æ¨¡æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œè‡ªç›‘ç£å­¦ä¹ æ¥é¢„å…ˆè®­ç»ƒï¼Œä¾‹å¦‚BERTï¼ˆBidirectional Encoder Representations from Transformersï¼‰ã€GPTï¼ˆGenerative Pre-trained Transformerï¼‰ç­‰ã€‚é¢„è®­ç»ƒæ¨¡å‹åœ¨å„ç§NLPä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶é€šè¿‡å¾®è°ƒé€‚åº”ç‰¹å®šçš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
</li>
</ol>
<p>NLPæ¨¡å‹çš„é€‰æ‹©å–å†³äºä»»åŠ¡çš„æ€§è´¨å’Œå¤æ‚åº¦ï¼Œä»¥åŠå¯ç”¨çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºã€‚éšç€æŠ€æœ¯çš„è¿›æ­¥å’Œç ”ç©¶çš„æ·±å…¥ï¼ŒNLPæ¨¡å‹ä¸æ–­æ¼”è¿›å’Œæ”¹è¿›ï¼Œä¸ºè¯­è¨€å¤„ç†é¢†åŸŸå¸¦æ¥äº†è®¸å¤šåˆ›æ–°å’Œæ–°çš„åº”ç”¨å¯èƒ½æ€§ã€‚</p>
<h2 id="æ–‡ä»¶ç»“æ„">æ–‡ä»¶ç»“æ„</h2>
<p><a href="#R-image-e3503abfe3c03166a686ddfa78df33fd" class="lightbox-link"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/cb01bc2b8c0ac0a386ef1f6692400079.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-e3503abfe3c03166a686ddfa78df33fd"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/cb01bc2b8c0ac0a386ef1f6692400079.png"></a>
è®­ç»ƒæ¨¡å‹é€šå¸¸å…·æœ‰ä»¥ä¸‹å¸¸è§çš„ç›®å½•æ–‡ä»¶ç»“æ„å’Œæ–‡ä»¶ï¼š</p>
<ol>
<li>
<p><strong>vocab.json</strong>: è¿™æ˜¯ä¸€ä¸ªåŒ…å«è¯æ±‡è¡¨çš„æ–‡ä»¶ï¼Œå®ƒå°†æ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨çš„è¯æ±‡æ˜ å°„åˆ°æ•´æ•°ç´¢å¼•ã€‚è¿™å¯¹äºå°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„è¾“å…¥æ ¼å¼ï¼ˆå¦‚æ•´æ•°ç´¢å¼•æˆ–è€…è¯åµŒå…¥ï¼‰éå¸¸é‡è¦ã€‚</p>
</li>
<li>
<p><strong>tokenizer_config.json</strong>: è¿™ä¸ªæ–‡ä»¶åŒ…å«æœ‰å…³æ¨¡å‹ä½¿ç”¨çš„åˆ†è¯å™¨ï¼ˆtokenizerï¼‰çš„é…ç½®ä¿¡æ¯ï¼Œä¾‹å¦‚åˆ†è¯å™¨çš„ç±»å‹ã€å‚æ•°è®¾ç½®ç­‰ã€‚åˆ†è¯å™¨ç”¨äºå°†æ–‡æœ¬åˆ’åˆ†ä¸ºè¯è¯­æˆ–å­è¯çš„åºåˆ—ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„è¾“å…¥æ ¼å¼ã€‚</p>
</li>
<li>
<p><strong>tokenizer.json</strong>: å¦‚æœæ¨¡å‹ä½¿ç”¨äº†ç‰¹å®šçš„åˆ†è¯å™¨ï¼Œæ­¤æ–‡ä»¶å¯èƒ½åŒ…å«åˆ†è¯å™¨çš„å…·ä½“å®ç°å’Œé…ç½®ä¿¡æ¯ã€‚è¿™å¯¹äºåŠ è½½å’Œä½¿ç”¨æ¨¡å‹çš„æ—¶å€™ç¡®ä¿åˆ†è¯å™¨èƒ½æ­£ç¡®åœ°å·¥ä½œéå¸¸é‡è¦ã€‚</p>
</li>
<li>
<p><strong>config.json</strong>: è¿™ä¸ªæ–‡ä»¶åŒ…å«äº†æ¨¡å‹æœ¬èº«çš„é…ç½®ä¿¡æ¯ï¼Œä¾‹å¦‚æ¨¡å‹çš„ç±»å‹ï¼ˆå¦‚BERTã€GPTï¼‰ã€å±‚æ•°ã€éšè—å•å…ƒæ•°ç­‰è¶…å‚æ•°è®¾ç½®ã€‚è¿™äº›ä¿¡æ¯å¯¹äºæ„å»ºå’Œåˆå§‹åŒ–æ¨¡å‹æä¸ºå…³é”®ã€‚</p>
</li>
<li>
<p><strong>pytorch_model.bin</strong> æˆ– <strong>tensorflow_model.h5</strong>ï¼šè¿™æ˜¯åŒ…å«é¢„è®­ç»ƒæ¨¡å‹æƒé‡çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œå…¶æ ¼å¼å–å†³äºæ‰€ä½¿ç”¨çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚è¿™äº›æƒé‡æ˜¯æ¨¡å‹å­¦ä¹ åˆ°çš„å‚æ•°ï¼Œç”¨äºå®é™…çš„é¢„æµ‹å’Œæ¨ç†ä»»åŠ¡ã€‚</p>
</li>
<li>
<p><strong>special_tokens_map.json</strong>: å¦‚æœæ¨¡å‹åŒ…å«äº†ç‰¹æ®Šæ ‡è®°ï¼ˆå¦‚å¡«å……æ ‡è®°ã€èµ·å§‹æ ‡è®°ç­‰ï¼‰ï¼Œæ­¤æ–‡ä»¶å°†åŒ…å«è¿™äº›ç‰¹æ®Šæ ‡è®°çš„å®šä¹‰åŠå…¶åœ¨æ¨¡å‹ä¸­çš„ä½¿ç”¨æ–¹å¼ã€‚</p>
</li>
<li>
<p><strong>merges.txt</strong>ï¼ˆå¯¹äºBERTç­‰å­è¯çº§åˆ«çš„æ¨¡å‹ï¼‰ï¼šè¿™ä¸ªæ–‡ä»¶åŒ…å«å°†è¯æ±‡åˆ’åˆ†ä¸ºå­è¯æˆ–è€…å­—ç¬¦çš„è§„åˆ™æˆ–è€…åˆå¹¶æ“ä½œï¼Œè¿™å¯¹äºåˆ†è¯å™¨çš„å·¥ä½œéå¸¸å…³é”®ã€‚</p>
</li>
<li>
<p><strong>README.md</strong> æˆ–è€… <strong>model_card.md</strong>ï¼šè¿™äº›æ–‡ä»¶é€šå¸¸åŒ…å«äº†å…³äºæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ï¼Œå¦‚ä½œè€…ã€è®¸å¯è¯ã€è®­ç»ƒæ•°æ®é›†ã€æ€§èƒ½è¯„ä¼°ç­‰ï¼Œå¯¹äºäº†è§£å’Œä½¿ç”¨æ¨¡å‹éå¸¸æœ‰å¸®åŠ©ã€‚</p>
</li>
</ol>
<p>æ¯ä¸ªæ¨¡å‹çš„å…·ä½“ç»“æ„å’Œæ–‡ä»¶å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒï¼Œä½†ä¸Šè¿°æ–‡ä»¶æ˜¯æ„æˆå¤§å¤šæ•°é¢„è®­ç»ƒæ¨¡å‹çš„åŸºæœ¬è¦ç´ ã€‚é€šè¿‡ç†è§£å’Œæ“ä½œè¿™äº›æ–‡ä»¶ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£å’Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚</p>
<h1 id="pipelines">pipelines</h1>
<p>åœ¨ Hugging Face Transformers ä¸­ï¼Œpipelines æ˜¯ä¸€ç§æ–¹ä¾¿çš„é«˜çº§ APIï¼Œç”¨äºæ‰§è¡Œå„ç§è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€é—®ç­”ç­‰ã€‚ä½¿ç”¨ pipelinesï¼Œæ‚¨æ— éœ€ç¼–å†™å¤§é‡çš„ä»£ç æ¥åŠ è½½æ¨¡å‹ã€é¢„å¤„ç†è¾“å…¥æ•°æ®ã€æ‰§è¡Œæ¨ç†ç­‰æ“ä½œï¼Œè€Œæ˜¯å¯ä»¥é€šè¿‡ç®€å•çš„å‡½æ•°è°ƒç”¨æ¥å®Œæˆè¿™äº›ä»»åŠ¡ã€‚</p>
<p>ransformers åº“å°†ç›®å‰çš„ NLP ä»»åŠ¡å½’çº³ä¸ºå‡ ä¸‹å‡ ç±»ï¼š</p>
<ul>
<li><strong>æ–‡æœ¬åˆ†ç±»</strong>ï¼šä¾‹å¦‚æƒ…æ„Ÿåˆ†æã€å¥å­å¯¹å…³ç³»åˆ¤æ–­ç­‰ï¼›</li>
<li><strong>å¯¹æ–‡æœ¬ä¸­çš„è¯è¯­è¿›è¡Œåˆ†ç±»</strong>ï¼šä¾‹å¦‚è¯æ€§æ ‡æ³¨ (POS)ã€å‘½åå®ä½“è¯†åˆ« (NER) ç­‰ï¼›</li>
<li><strong>æ–‡æœ¬ç”Ÿæˆ</strong>ï¼šä¾‹å¦‚å¡«å……é¢„è®¾çš„æ¨¡æ¿ (prompt)ã€é¢„æµ‹æ–‡æœ¬ä¸­è¢«é®æ©æ‰ (masked) çš„è¯è¯­ï¼›</li>
<li><strong>ä»æ–‡æœ¬ä¸­æŠ½å–ç­”æ¡ˆ</strong>ï¼šä¾‹å¦‚æ ¹æ®ç»™å®šçš„é—®é¢˜ä»ä¸€æ®µæ–‡æœ¬ä¸­æŠ½å–å‡ºå¯¹åº”çš„ç­”æ¡ˆï¼›</li>
<li><strong>æ ¹æ®è¾“å…¥æ–‡æœ¬ç”Ÿæˆæ–°çš„å¥å­</strong>ï¼šä¾‹å¦‚æ–‡æœ¬ç¿»è¯‘ã€è‡ªåŠ¨æ‘˜è¦ç­‰ã€‚</li>
</ul>
<p>Transformers åº“æœ€åŸºç¡€çš„å¯¹è±¡å°±æ˜¯ <code>pipeline()</code> å‡½æ•°ï¼Œå®ƒå°è£…äº†é¢„è®­ç»ƒæ¨¡å‹å’Œå¯¹åº”çš„å‰å¤„ç†å’Œåå¤„ç†ç¯èŠ‚ã€‚æˆ‘ä»¬åªéœ€è¾“å…¥æ–‡æœ¬ï¼Œå°±èƒ½å¾—åˆ°é¢„æœŸçš„ç­”æ¡ˆã€‚ç›®å‰å¸¸ç”¨çš„ <a href="https://huggingface.co/docs/transformers/main_classes/pipelines" rel="external" target="_blank">pipelines</a> æœ‰ï¼š</p>
<ol>
<li><strong>audio-classification</strong>ï¼ˆéŸ³é¢‘åˆ†ç±»ï¼‰ï¼šç”¨äºå¯¹éŸ³é¢‘è¿›è¡Œåˆ†ç±»ï¼Œè¯†åˆ«éŸ³é¢‘ä¸­çš„ç±»åˆ«æˆ–å±æ€§ã€‚</li>
<li><strong>automatic-speech-recognition</strong>ï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰ï¼šç”¨äºå°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ï¼Œå®ç°è¯­éŸ³è¯†åˆ«çš„åŠŸèƒ½ã€‚</li>
<li><strong>conversational</strong>ï¼ˆä¼šè¯å¼å¤„ç†ï¼‰ï¼šç”¨äºæ„å»ºå’Œå¤„ç†å¯¹è¯ç³»ç»Ÿï¼Œå®ç°å¯¹è¯å¼äº¤äº’çš„åŠŸèƒ½ã€‚</li>
<li><strong>depth-estimation</strong>ï¼ˆæ·±åº¦ä¼°è®¡ï¼‰ï¼šç”¨äºä»å•å¼ å›¾ç‰‡æˆ–è§†é¢‘ä¸­ä¼°è®¡åœºæ™¯çš„æ·±åº¦ä¿¡æ¯ã€‚</li>
<li><strong>document-question-answering</strong>ï¼ˆæ–‡æ¡£é—®ç­”ï¼‰ï¼šç”¨äºä»æ–‡æ¡£ä¸­å›ç­”é—®é¢˜ï¼Œå¸®åŠ©ç”¨æˆ·è·å–æ–‡æ¡£å†…å®¹ä¸­çš„ç›¸å…³ä¿¡æ¯ã€‚</li>
<li><strong>feature-extraction</strong>ï¼ˆç‰¹å¾æå–ï¼‰ï¼šç”¨äºä»æ–‡æœ¬ã€å›¾ç‰‡ç­‰æ•°æ®ä¸­æå–ç‰¹å¾ï¼Œç”¨äºåç»­çš„ä»»åŠ¡æˆ–åˆ†æã€‚</li>
<li><strong>fill-mask</strong>ï¼ˆå¡«ç©ºï¼‰ï¼šç”¨äºç»™å®šå¸¦æœ‰ç©ºç™½çš„å¥å­ï¼Œé¢„æµ‹å¹¶å¡«è¡¥ç©ºç™½å¤„çš„å•è¯æˆ–çŸ­è¯­ã€‚</li>
<li><strong>image-classification</strong>ï¼ˆå›¾ç‰‡åˆ†ç±»ï¼‰ï¼šç”¨äºå¯¹å›¾ç‰‡è¿›è¡Œåˆ†ç±»ï¼Œè¯†åˆ«å›¾ç‰‡ä¸­çš„ç±»åˆ«æˆ–å±æ€§ã€‚</li>
<li><strong>image-feature-extraction</strong>ï¼ˆå›¾ç‰‡ç‰¹å¾æå–ï¼‰ï¼šç”¨äºä»å›¾ç‰‡ä¸­æå–ç‰¹å¾ï¼Œç”¨äºåç»­çš„ä»»åŠ¡æˆ–åˆ†æã€‚</li>
<li><strong>image-segmentation</strong>ï¼ˆå›¾ç‰‡åˆ†å‰²ï¼‰ï¼šç”¨äºå°†å›¾ç‰‡åˆ†å‰²æˆä¸åŒçš„åŒºåŸŸæˆ–å¯¹è±¡ï¼Œè¿›è¡Œå›¾åƒåˆ†å‰²ä»»åŠ¡ã€‚</li>
<li><strong>image-to-image</strong>ï¼ˆå›¾ç‰‡åˆ°å›¾ç‰‡ï¼‰ï¼šç”¨äºæ‰§è¡Œå›¾ç‰‡åˆ°å›¾ç‰‡çš„è½¬æ¢ï¼Œå¦‚å›¾åƒé£æ ¼è½¬æ¢ã€å›¾åƒå»å™ªç­‰ã€‚</li>
<li><strong>image-to-text</strong>ï¼ˆå›¾ç‰‡åˆ°æ–‡æœ¬ï¼‰ï¼šç”¨äºä»å›¾ç‰‡ä¸­æå–æ–‡æœ¬ä¿¡æ¯ï¼Œå®ç°å›¾ç‰‡ä¸­çš„æ–‡å­—è¯†åˆ«åŠŸèƒ½ã€‚</li>
<li><strong>mask-generation</strong>ï¼ˆé®ç½©ç”Ÿæˆï¼‰ï¼šç”¨äºç”Ÿæˆå›¾ç‰‡ä¸­çš„é®ç½©æˆ–æ©ç ï¼Œç”¨äºå›¾åƒå¤„ç†æˆ–åˆ†å‰²ä»»åŠ¡ã€‚</li>
<li><strong>object-detection</strong>ï¼ˆç›®æ ‡æ£€æµ‹ï¼‰ï¼šç”¨äºä»å›¾ç‰‡æˆ–è§†é¢‘ä¸­æ£€æµ‹å’Œè¯†åˆ«å‡ºå›¾åƒä¸­çš„ç›®æ ‡å¯¹è±¡ã€‚</li>
<li><strong>question-answering</strong>ï¼ˆé—®ç­”ï¼‰ï¼šç”¨äºå›ç­”ç»™å®šé—®é¢˜çš„æ¨¡å‹ï¼Œä»æ–‡æœ¬ä¸­æ‰¾å‡ºåŒ…å«ç­”æ¡ˆçš„éƒ¨åˆ†ã€‚</li>
<li><strong>summarization</strong>ï¼ˆæ‘˜è¦ç”Ÿæˆï¼‰ï¼šç”¨äºç”Ÿæˆæ–‡æœ¬çš„æ‘˜è¦æˆ–æ€»ç»“ï¼Œå°†æ–‡æœ¬å†…å®¹å‹ç¼©ä¸ºç®€çŸ­çš„å½¢å¼ã€‚</li>
<li><strong>table-question-answering</strong>ï¼ˆè¡¨æ ¼é—®ç­”ï¼‰ï¼šç”¨äºä»è¡¨æ ¼æ•°æ®ä¸­å›ç­”é—®é¢˜ï¼Œå¸®åŠ©ç”¨æˆ·ä»è¡¨æ ¼ä¸­è·å–ä¿¡æ¯ã€‚</li>
<li><strong>text2text-generation</strong>ï¼ˆæ–‡æœ¬åˆ°æ–‡æœ¬ç”Ÿæˆï¼‰ï¼šç”¨äºç”Ÿæˆæ–‡æœ¬çš„æ¨¡å‹ï¼Œå¯ä»¥æ‰§è¡Œæ–‡æœ¬åˆ°æ–‡æœ¬çš„è½¬æ¢æˆ–ç”Ÿæˆä»»åŠ¡ã€‚</li>
<li><strong>text-classification</strong>ï¼ˆæ–‡æœ¬åˆ†ç±»ï¼‰ï¼š(åˆ«å&quot;sentiment-analysis&quot; å¯ç”¨ï¼Œæƒ…æ„Ÿåˆ†æ)ç”¨äºå°†æ–‡æœ¬è¿›è¡Œåˆ†ç±»ï¼Œè¯†åˆ«æ–‡æœ¬ä¸­çš„ç±»åˆ«æˆ–å±æ€§ã€‚</li>
<li><strong>text-generation</strong>ï¼ˆæ–‡æœ¬ç”Ÿæˆï¼‰ï¼šç”¨äºç”Ÿæˆæ–‡æœ¬çš„æ¨¡å‹ï¼Œå¯ä»¥ç”Ÿæˆè¿ç»­çš„æ–‡æœ¬åºåˆ—ã€‚</li>
<li><strong>text-to-audio</strong>ï¼ˆæ–‡æœ¬åˆ°éŸ³é¢‘ï¼‰ï¼šç”¨äºå°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³ï¼Œå®ç°æ–‡æœ¬åˆ°è¯­éŸ³çš„åŠŸèƒ½ã€‚</li>
<li><strong>token-classification</strong>ï¼ˆæ ‡è®°åˆ†ç±»ï¼‰ï¼šåˆ«å&quot;ner&quot; å¯ç”¨ï¼Œå‘½åå®ä½“è¯†åˆ«ï¼Œç”¨äºå°†æ–‡æœ¬ä¸­çš„æ¯ä¸ªæ ‡è®°æˆ–å•è¯è¿›è¡Œåˆ†ç±»ï¼Œè¯†åˆ«æ¯ä¸ªæ ‡è®°çš„ç±»åˆ«æˆ–å±æ€§ã€‚</li>
<li><strong>translation</strong>ï¼ˆç¿»è¯‘ï¼‰ï¼šç”¨äºæ‰§è¡Œæ–‡æœ¬çš„ç¿»è¯‘ä»»åŠ¡ï¼Œå°†æ–‡æœ¬ä»ä¸€ç§è¯­è¨€ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€ã€‚</li>
<li><strong>video-classification</strong>ï¼ˆè§†é¢‘åˆ†ç±»ï¼‰ï¼šç”¨äºå¯¹è§†é¢‘è¿›è¡Œåˆ†ç±»ï¼Œè¯†åˆ«è§†é¢‘ä¸­çš„ç±»åˆ«æˆ–å±æ€§ã€‚</li>
<li><strong>visual-question-answering</strong>ï¼ˆè§†è§‰é—®ç­”ï¼‰ï¼šç”¨äºä»å›¾ç‰‡æˆ–è§†é¢‘ä¸­å›ç­”é—®é¢˜ï¼Œç»“åˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯è¿›è¡Œé—®ç­”ã€‚</li>
<li><strong>zero-shot-classification</strong>ï¼ˆé›¶æ ·æœ¬åˆ†ç±»ï¼‰ï¼šç”¨äºæ‰§è¡Œé›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œå³åœ¨æ²¡æœ‰è§è¿‡è¯¥ç±»åˆ«çš„æƒ…å†µä¸‹å¯¹æ–°æ ·æœ¬è¿›è¡Œåˆ†ç±»ã€‚</li>
<li><strong>zero-shot-image-classification</strong>ï¼ˆé›¶æ ·æœ¬å›¾ç‰‡åˆ†ç±»ï¼‰ï¼šç”¨äºæ‰§è¡Œé›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œå³åœ¨æ²¡æœ‰è§è¿‡è¯¥ç±»åˆ«çš„æƒ…å†µä¸‹å¯¹æ–°å›¾ç‰‡è¿›è¡Œåˆ†ç±»ã€‚</li>
<li><strong>zero-shot-audio-classification</strong>ï¼ˆé›¶æ ·æœ¬éŸ³é¢‘åˆ†ç±»ï¼‰ï¼šç”¨äºæ‰§è¡Œé›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œå³åœ¨æ²¡æœ‰è§è¿‡è¯¥ç±»åˆ«çš„æƒ…å†µä¸‹å¯¹æ–°éŸ³é¢‘è¿›è¡Œåˆ†ç±»ã€‚</li>
<li><strong>zero-shot-object-detection</strong>ï¼ˆé›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹ï¼‰ï¼šç”¨äºæ‰§è¡Œé›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼Œå³åœ¨æ²¡æœ‰è§è¿‡è¯¥ç±»åˆ«çš„æƒ…å†µä¸‹å¯¹æ–°å›¾ç‰‡ä¸­çš„ç›®æ ‡å¯¹è±¡è¿›è¡Œæ£€æµ‹ã€‚</li>
</ol>
<p>å¦‚æœéœ€è¦äº†è§£æ›´å¤šçš„taskç±»å‹æ›´æ–°ï¼Œå‚è€ƒ<a href="https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/pipelines" rel="external" target="_blank">å®˜ç½‘pipeline</a>ï¼š
ä¸‹é¢æˆ‘ä»¬ä»¥å¸¸è§çš„å‡ ä¸ª NLP ä»»åŠ¡ä¸ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•è°ƒç”¨è¿™äº› pipeline æ¨¡å‹ã€‚</p>
<h2 id="å›¾ç‰‡è½¬æ–‡æœ¬">å›¾ç‰‡è½¬æ–‡æœ¬</h2>
<p>æ•™ç¨‹å‚è€ƒè‡ªå®˜ç½‘ï¼šhttps://huggingface.co/docs/transformers/v4.40.2/en/main_classes/pipelines#transformers.ImageToTextPipeline
<a href="#R-image-5490e7684a004236b8174694680665a6" class="lightbox-link"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/43243b59a8fc0d9921d012e1d256d51f.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-5490e7684a004236b8174694680665a6"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/43243b59a8fc0d9921d012e1d256d51f.png"></a></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import pipeline
itt=pipeline(&#34;image-to-text&#34;,model=&#34;ydshieh/vit-gpt2-coco-en&#34;) #modelä¸æŒ‡å®šä¼šä½¿ç”¨é»˜è®¤æ¨¡å‹ã€‚
rtn=itt(&#34;https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png&#34;)
print(rtn)</code></pre></div>
<p>å¯ä»¥çœ‹åˆ°è¾“å‡ºæ˜¯éœ€è¦å…ˆä¸‹è½½æ¨¡å‹ï¼ˆä¸‹è½½ä¸€æ¬¡ï¼Œè‡ªåŠ¨ç¼“å­˜ï¼‰ï¼Œä¸‹è½½åœ¨C:\Users\admin.cache\huggingface\hubç›®å½•ä¸‹ã€‚</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>:\python\evn311\Lib\site-packages\huggingface_hub\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\admin\.cache\huggingface\hub\models--ydshieh--vit-gpt2-coco-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)</code></pre></div>
<p>æœ€åè¾“å‡ºï¼š[{&lsquo;generated_text&rsquo;: &rsquo;two birds are standing next to each other &lsquo;}]</p>
<p>å¦‚æœå¸Œæœ›ä½¿ç”¨å…¶ä»–çš„image-to-textæ¨¡å‹å¯ä»¥åœ¨å®˜ç½‘æœç´¢
<a href="https://huggingface.co/models?pipeline_tag=image-to-text&sort=trending" rel="external" target="_blank">https://huggingface.co/models?pipeline_tag=image-to-text&sort=trending</a>
<a href="#R-image-103360c4daaf637c39130799ea91ade5" class="lightbox-link"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/0af97dd5cd118a9c950b925c53ac28b9.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-103360c4daaf637c39130799ea91ade5"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/0af97dd5cd118a9c950b925c53ac28b9.png"></a>
æ¯”å¦‚é€‰æ‹©image-to-textå³ä¾§æ–‡æœ¬æ¡†è¾“å…¥chineseï¼Œçœ‹ä¸‹æ˜¯ä¸æ˜¯æœ‰ä¸­æ–‡æè¿°çš„
<a href="#R-image-4644ef7a14713ec0ffb2a8de6840ec89" class="lightbox-link"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/f99868b1909dd9c7de04e569b0d941e1.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-4644ef7a14713ec0ffb2a8de6840ec89"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/f99868b1909dd9c7de04e569b0d941e1.png"></a>
ä½¿ç”¨è¿™ä¸ªæ¨¡å‹æ¥æµ‹è¯•ä¸‹</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>image_path=&#34;https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png&#34;
from transformers import pipeline
itt=pipeline(&#34;image-to-text&#34;,model=&#34;IDEA-CCNL/Taiyi-BLIP-750M-Chinese&#34;)
rtn=itt(image_path)
print(rtn)</code></pre></div>
<p>è¾“å‡ºï¼ˆæ•ˆæœæ²¡æœ‰è‹±æ–‡çš„æ¨¡å‹å¥½ï¼Œæ˜æ˜æ˜¯ä¸¤åªé¹¦é¹‰å•Šï¼Œä¸è¿‡è¯†åˆ«å‡ºäº†é¹¦é¹‰ï¼Œè‹±æ–‡çš„åªæ˜¯ä¸¤åªé¸Ÿï¼‰
[{&lsquo;generated_text&rsquo;: &lsquo;ä¸€ åª é¹¦ é¹‰ çš„ é»‘ ç™½ ç…§ ç‰‡ ã€‚&rsquo;}]</p>
<h2 id="æ–‡æœ¬ç”Ÿæˆ">æ–‡æœ¬ç”Ÿæˆ</h2>
<p>æˆ‘ä»¬é¦–å…ˆæ ¹æ®ä»»åŠ¡éœ€è¦æ„å»ºä¸€ä¸ªæ¨¡æ¿ (prompt)ï¼Œç„¶åå°†å…¶é€å…¥åˆ°æ¨¡å‹ä¸­æ¥ç”Ÿæˆåç»­æ–‡æœ¬ã€‚æ³¨æ„ï¼Œç”±äºæ–‡æœ¬ç”Ÿæˆå…·æœ‰éšæœºæ€§ï¼Œå› æ­¤æ¯æ¬¡è¿è¡Œéƒ½ä¼šå¾—åˆ°ä¸åŒçš„ç»“æœã€‚</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>#%%
from transformers import pipeline
generator = pipeline(&#34;text-generation&#34;,model=&#34;openai-community/gpt2&#34;)
print(generator(&#34;I can&#39;t believe you did such a &#34;))</code></pre></div>
<p>è¾“å‡ºï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[{&#39;generated_text&#39;: &#39;I can\&#39;t believe you did such a _____t!&#34;\n\n&#34;You know I\&#39;m kind of an asshole to you, I mean?&#34;\n\n&#34;Just because I had one thing to do doesn\&#39;t mean I hate you. I know you&#39;}]</code></pre></div>
<p>åœ¨huggerfaceä¸Šæœç´¢ä¸€ä¸ªå¤è¯—è¯ç”Ÿæˆçš„æ¨¡å‹ï¼Œ
å·¦ä¾§é€‰æ‹©tag Text Generation ï¼Œæœç´¢poemï¼Œé€‰æ‹©æœ€å¤šäººå–œæ¬¢ã€‚
<a href="#R-image-6181102015d70af23ebc9f6bf94bbae6" class="lightbox-link"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/8dfa39301693265aea3f46b80d5a3641.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-6181102015d70af23ebc9f6bf94bbae6"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/8dfa39301693265aea3f46b80d5a3641.png"></a></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import pipeline
generator = pipeline(&#34;text-generation&#34;,model=&#34;uer/gpt2-chinese-poem&#34;)
print(generator(&#34;[CLS] ç¦» ç¦» åŸ ä¸Š è‰ ï¼Œ&#34;))</code></pre></div>
<p>è¾“å‡º</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[{&#39;generated_text&#39;: &#39;[CLS] ç¦» ç¦» åŸ ä¸Š è‰ ï¼Œ æ¿¯ æ¿¯ åŸ ä¸Š æ¡‘ ã€‚ æ˜¥ é£ å¹ ç½— è¡£ ï¼Œ è¡Œ äºº æ³ª æˆ è¡Œ ã€‚ ç¦» äºº ä¸ å¯ ç•™ ï¼Œ å†µ ä¹ƒ éš” æ²³ æ¢ ã€‚ å½“ å’Œ éœ² é¤ ï¼Œ å‹¿ å¤ æ€¨ ç§‹ å‡‰ ã€‚ æ„¿ è¨€ å´‡ ä»¤ å¾· ï¼Œ ä»¥ é… å› å­ å…‰ ã€‚ æ¯‹ æ€€ è¿œ å¿ƒ ï¼Œ çš“ æœˆ é‰´ æˆ‘ ä¼¤ ã€‚ è« æ€¨ ä¸œ é£ ï¼Œ é£˜ ç„¶ å…¥ è¥¿ æ¥¼ ã€‚ ä¸¾ æ‰‹ å€š é˜‘ å¹² ï¼Œ ä¸¾ é…’ ç›¸ åŠ é…¬ ã€‚ è‰¯ æ—¶ ç„‰ å¯ å† ï¼Œ é€ æ°´ ä½• æ‚  æ‚  ã€‚ æˆ‘ é‡‘ çŸ³ äº¤ ï¼Œ æ²‰ é‚ˆ ç„‰ èƒ½ æ±‚&#39;}]</code></pre></div>
<h2 id="æƒ…æ„Ÿåˆ†æ">æƒ…æ„Ÿåˆ†æ</h2>
<p>å€ŸåŠ©æƒ…æ„Ÿåˆ†æ pipelineï¼Œæˆ‘ä»¬åªéœ€è¦è¾“å…¥æ–‡æœ¬ï¼Œå°±å¯ä»¥å¾—åˆ°å…¶æƒ…æ„Ÿæ ‡ç­¾ï¼ˆç§¯æ/æ¶ˆæï¼‰ä»¥åŠå¯¹åº”çš„æ¦‚ç‡ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import pipeline

classifier = pipeline(&#34;sentiment-analysis&#34;)
result = classifier(&#34;I&#39;ve been waiting for a HuggingFace course my whole life.&#34;)
print(result)
results = classifier(
  [&#34;I&#39;ve been waiting for a HuggingFace course my whole life.&#34;, &#34;I hate this so much!&#34;]
)
print(results)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)

[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9598048329353333}]
[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9598048329353333}, {&#39;label&#39;: &#39;NEGATIVE&#39;, &#39;score&#39;: 0.9994558691978455}]</code></pre></div>
<p>pipeline æ¨¡å‹ä¼šè‡ªåŠ¨å®Œæˆä»¥ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š</p>
<ol>
<li>å°†æ–‡æœ¬é¢„å¤„ç†ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ ¼å¼ï¼›</li>
<li>å°†é¢„å¤„ç†å¥½çš„æ–‡æœ¬é€å…¥æ¨¡å‹ï¼›</li>
<li>å¯¹æ¨¡å‹çš„é¢„æµ‹å€¼è¿›è¡Œåå¤„ç†ï¼Œè¾“å‡ºäººç±»å¯ä»¥ç†è§£çš„æ ¼å¼ã€‚</li>
</ol>
<p>pipeline ä¼šè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„é¢„è®­ç»ƒæ¨¡å‹æ¥å®Œæˆä»»åŠ¡ã€‚ä¾‹å¦‚å¯¹äºæƒ…æ„Ÿåˆ†æï¼Œé»˜è®¤å°±ä¼šé€‰æ‹©å¾®è°ƒå¥½çš„è‹±æ–‡æƒ…æ„Ÿæ¨¡å‹ <em>distilbert-base-uncased-finetuned-sst-2-english</em>ã€‚</p>
<blockquote>
<p>Transformers åº“ä¼šåœ¨åˆ›å»ºå¯¹è±¡æ—¶ä¸‹è½½å¹¶ä¸”ç¼“å­˜æ¨¡å‹ï¼Œåªæœ‰åœ¨é¦–æ¬¡åŠ è½½æ¨¡å‹æ—¶æ‰ä¼šä¸‹è½½ï¼Œåç»­ä¼šç›´æ¥è°ƒç”¨ç¼“å­˜å¥½çš„æ¨¡å‹ã€‚</p></blockquote>
<h2 id="é›¶è®­ç»ƒæ ·æœ¬åˆ†ç±»">é›¶è®­ç»ƒæ ·æœ¬åˆ†ç±»</h2>
<p>é›¶è®­ç»ƒæ ·æœ¬åˆ†ç±» pipeline å…è®¸æˆ‘ä»¬åœ¨ä¸æä¾›ä»»ä½•æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹è‡ªå®šä¹‰åˆ†ç±»æ ‡ç­¾ã€‚</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import pipeline

classifier = pipeline(&#34;zero-shot-classification&#34;)
result = classifier(
&#34;This is a course about the Transformers library&#34;,
candidate_labels=[&#34;education&#34;, &#34;politics&#34;, &#34;business&#34;],
)
print(result)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)

{&#39;sequence&#39;: &#39;This is a course about the Transformers library&#39;, 
 &#39;labels&#39;: [&#39;education&#39;, &#39;business&#39;, &#39;politics&#39;], 
 &#39;scores&#39;: [0.8445973992347717, 0.11197526752948761, 0.043427325785160065]}</code></pre></div>
<p>å¯ä»¥çœ‹åˆ°ï¼Œpipeline è‡ªåŠ¨é€‰æ‹©äº†é¢„è®­ç»ƒå¥½çš„ <em>facebook/bart-large-mnli</em> æ¨¡å‹æ¥å®Œæˆä»»åŠ¡ã€‚</p>
<h2 id="é®ç›–è¯å¡«å……">é®ç›–è¯å¡«å……</h2>
<p>ç»™å®šä¸€æ®µéƒ¨åˆ†è¯è¯­è¢«é®ç›–æ‰ (masked) çš„æ–‡æœ¬ï¼Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ¥é¢„æµ‹èƒ½å¤Ÿå¡«å……è¿™äº›ä½ç½®çš„è¯è¯­ã€‚</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import pipeline

unmasker = pipeline(&#34;fill-mask&#34;)
results = unmasker(&#34;This course will teach you all about &lt;mask&gt; models.&#34;, top_k=2)
print(results)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)

[{&#39;sequence&#39;: &#39;This course will teach you all about mathematical models.&#39;, 
  &#39;score&#39;: 0.19619858264923096, 
  &#39;token&#39;: 30412, 
  &#39;token_str&#39;: &#39; mathematical&#39;}, 
 {&#39;sequence&#39;: &#39;This course will teach you all about computational models.&#39;, 
  &#39;score&#39;: 0.04052719101309776, 
  &#39;token&#39;: 38163, 
  &#39;token_str&#39;: &#39; computational&#39;}]</code></pre></div>
<p>å¯ä»¥çœ‹åˆ°ï¼Œpipeline è‡ªåŠ¨é€‰æ‹©äº†é¢„è®­ç»ƒå¥½çš„ <em>distilroberta-base</em> æ¨¡å‹æ¥å®Œæˆä»»åŠ¡ã€‚</p>
<h2 id="å‘½åå®ä½“è¯†åˆ«">å‘½åå®ä½“è¯†åˆ«</h2>
<p>å‘½åå®ä½“è¯†åˆ« (NER) pipeline è´Ÿè´£ä»æ–‡æœ¬ä¸­æŠ½å–å‡ºæŒ‡å®šç±»å‹çš„å®ä½“ï¼Œä¾‹å¦‚äººç‰©ã€åœ°ç‚¹ã€ç»„ç»‡ç­‰ç­‰ã€‚</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import pipeline

ner = pipeline(&#34;ner&#34;, grouped_entities=True)
results = ner(&#34;My name is Sylvain and I work at Hugging Face in Brooklyn.&#34;)
print(results)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)

[{&#39;entity_group&#39;: &#39;PER&#39;, &#39;score&#39;: 0.9981694, &#39;word&#39;: &#39;Sylvain&#39;, &#39;start&#39;: 11, &#39;end&#39;: 18}, 
 {&#39;entity_group&#39;: &#39;ORG&#39;, &#39;score&#39;: 0.97960186, &#39;word&#39;: &#39;Hugging Face&#39;, &#39;start&#39;: 33, &#39;end&#39;: 45}, 
 {&#39;entity_group&#39;: &#39;LOC&#39;, &#39;score&#39;: 0.99321055, &#39;word&#39;: &#39;Brooklyn&#39;, &#39;start&#39;: 49, &#39;end&#39;: 57}]</code></pre></div>
<p>å¯ä»¥çœ‹åˆ°ï¼Œæ¨¡å‹æ­£ç¡®åœ°è¯†åˆ«å‡ºäº† Sylvain æ˜¯ä¸€ä¸ªäººç‰©ï¼ŒHugging Face æ˜¯ä¸€ä¸ªç»„ç»‡ï¼ŒBrooklyn æ˜¯ä¸€ä¸ªåœ°åã€‚</p>
<blockquote>
<p>è¿™é‡Œé€šè¿‡è®¾ç½®å‚æ•° <code>grouped_entities=True</code>ï¼Œä½¿å¾— pipeline è‡ªåŠ¨åˆå¹¶å±äºåŒä¸€ä¸ªå®ä½“çš„å¤šä¸ªå­è¯ (token)ï¼Œä¾‹å¦‚è¿™é‡Œå°†â€œHuggingâ€å’Œâ€œFaceâ€åˆå¹¶ä¸ºä¸€ä¸ªç»„ç»‡å®ä½“ï¼Œå®é™…ä¸Š Sylvain ä¹Ÿè¿›è¡Œäº†å­è¯åˆå¹¶ï¼Œå› ä¸ºåˆ†è¯å™¨ä¼šå°† Sylvain åˆ‡åˆ†ä¸º <code>S</code>ã€<code>##yl</code> ã€<code>##va</code> å’Œ <code>##in</code> å››ä¸ª tokenã€‚</p></blockquote>
<h2 id="è‡ªåŠ¨é—®ç­”">è‡ªåŠ¨é—®ç­”</h2>
<p>è‡ªåŠ¨é—®ç­” pipeline å¯ä»¥æ ¹æ®ç»™å®šçš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œä¾‹å¦‚ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import pipeline

question_answerer = pipeline(&#34;question-answering&#34;)
answer = question_answerer(
    question=&#34;Where do I work?&#34;,
    context=&#34;My name is Sylvain and I work at Hugging Face in Brooklyn&#34;,
)
print(answer)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)

{&#39;score&#39;: 0.6949771046638489, &#39;start&#39;: 33, &#39;end&#39;: 45, &#39;answer&#39;: &#39;Hugging Face&#39;}</code></pre></div>
<p>å¯ä»¥çœ‹åˆ°ï¼Œpipeline è‡ªåŠ¨é€‰æ‹©äº†åœ¨ SQuAD æ•°æ®é›†ä¸Šè®­ç»ƒå¥½çš„ <em>distilbert-base</em> æ¨¡å‹æ¥å®Œæˆä»»åŠ¡ã€‚è¿™é‡Œçš„è‡ªåŠ¨é—®ç­” pipeline å®é™…ä¸Šæ˜¯ä¸€ä¸ªæŠ½å–å¼é—®ç­”æ¨¡å‹ï¼Œå³ä»ç»™å®šçš„ä¸Šä¸‹æ–‡ä¸­æŠ½å–ç­”æ¡ˆï¼Œè€Œä¸æ˜¯ç”Ÿæˆç­”æ¡ˆã€‚</p>
<blockquote>
<p>æ ¹æ®å½¢å¼çš„ä¸åŒï¼Œè‡ªåŠ¨é—®ç­” (QA) ç³»ç»Ÿå¯ä»¥åˆ†ä¸ºä¸‰ç§ï¼š</p>
<ul>
<li>**æŠ½å–å¼ QA (extractive QA)ï¼š**å‡è®¾ç­”æ¡ˆå°±åŒ…å«åœ¨æ–‡æ¡£ä¸­ï¼Œå› æ­¤ç›´æ¥ä»æ–‡æ¡£ä¸­æŠ½å–ç­”æ¡ˆï¼›</li>
<li>**å¤šé€‰ QA (multiple-choice QA)ï¼š**ä»å¤šä¸ªç»™å®šçš„é€‰é¡¹ä¸­é€‰æ‹©ç­”æ¡ˆï¼Œç›¸å½“äºåšé˜…è¯»ç†è§£é¢˜ï¼›</li>
<li>**æ— çº¦æŸ QA (free-form QA)ï¼š**ç›´æ¥ç”Ÿæˆç­”æ¡ˆæ–‡æœ¬ï¼Œå¹¶ä¸”å¯¹ç­”æ¡ˆæ–‡æœ¬æ ¼å¼æ²¡æœ‰ä»»ä½•é™åˆ¶ã€‚</li>
</ul></blockquote>
<h2 id="è‡ªåŠ¨æ‘˜è¦">è‡ªåŠ¨æ‘˜è¦</h2>
<p>è‡ªåŠ¨æ‘˜è¦ pipeline æ—¨åœ¨å°†é•¿æ–‡æœ¬å‹ç¼©æˆçŸ­æ–‡æœ¬ï¼Œå¹¶ä¸”è¿˜è¦å°½å¯èƒ½ä¿ç•™åŸæ–‡çš„ä¸»è¦ä¿¡æ¯ï¼Œä¾‹å¦‚ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import pipeline

summarizer = pipeline(&#34;summarization&#34;)
results = summarizer(
    &#34;&#34;&#34;
    America has changed dramatically during recent years. Not only has the number of 
    graduates in traditional engineering disciplines such as mechanical, civil, 
    electrical, chemical, and aeronautical engineering declined, but in most of 
    the premier American universities engineering curricula now concentrate on 
    and encourage largely the study of engineering science. As a result, there 
    are declining offerings in engineering subjects dealing with infrastructure, 
    the environment, and related issues, and greater concentration on high 
    technology subjects, largely supporting increasingly complex scientific 
    developments. While the latter is important, it should not be at the expense 
    of more traditional engineering.

    Rapidly developing economies such as China and India, as well as other 
    industrial countries in Europe and Asia, continue to encourage and advance 
    the teaching of engineering. Both China and India, respectively, graduate 
    six and eight times as many traditional engineers as does the United States. 
    Other industrial countries at minimum maintain their output, while America 
    suffers an increasingly serious decline in the number of engineering graduates 
    and a lack of well-educated engineers.
    &#34;&#34;&#34;
)
print(results)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)

[{&#39;summary_text&#39;: &#39; America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil, electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India, as well as other industrial countries in Europe and Asia, continue to encourage and advance engineering .&#39;}]</code></pre></div>
<p>å¯ä»¥çœ‹åˆ°ï¼Œpipeline è‡ªåŠ¨é€‰æ‹©äº†é¢„è®­ç»ƒå¥½çš„ <em>distilbart-cnn-12-6</em> æ¨¡å‹æ¥å®Œæˆä»»åŠ¡ã€‚ä¸æ–‡æœ¬ç”Ÿæˆç±»ä¼¼ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ <code>max_length</code> æˆ– <code>min_length</code> å‚æ•°æ¥æ§åˆ¶è¿”å›æ‘˜è¦çš„é•¿åº¦ã€‚</p>
<h1 id="pipeline-èƒŒååšäº†ä»€ä¹ˆ">pipeline èƒŒååšäº†ä»€ä¹ˆï¼Ÿ</h1>
<p>è¿™äº›ç®€å•æ˜“ç”¨çš„ pipeline æ¨¡å‹å®é™…ä¸Šå°è£…äº†è®¸å¤šæ“ä½œï¼Œä¸‹é¢æˆ‘ä»¬å°±æ¥äº†è§£ä¸€ä¸‹å®ƒä»¬èƒŒåç©¶ç«Ÿåšäº†å•¥ã€‚ä»¥ç¬¬ä¸€ä¸ªæƒ…æ„Ÿåˆ†æ pipeline ä¸ºä¾‹ï¼Œæˆ‘ä»¬è¿è¡Œä¸‹é¢çš„ä»£ç </p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import pipeline

classifier = pipeline(&#34;sentiment-analysis&#34;)
result = classifier(&#34;This course is amazing!&#34;)
print(result)</code></pre></div>
<p>å°±ä¼šå¾—åˆ°ç»“æœï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9998824596405029}]</code></pre></div>
<p>å®é™…ä¸Šå®ƒçš„èƒŒåç»è¿‡äº†ä¸‰ä¸ªæ­¥éª¤ï¼š</p>
<ol>
<li>é¢„å¤„ç† (preprocessing)ï¼Œå°†åŸå§‹æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥æ¥å—çš„è¾“å…¥æ ¼å¼ï¼›</li>
<li>å°†å¤„ç†å¥½çš„è¾“å…¥é€å…¥æ¨¡å‹ï¼›</li>
<li>å¯¹æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œåå¤„ç† (postprocessing)ï¼Œå°†å…¶è½¬æ¢ä¸ºäººç±»æ–¹ä¾¿é˜…è¯»çš„æ ¼å¼ã€‚
<a href="#R-image-387b11d4a8f2f8b021e2318b6e2e0bc7" class="lightbox-link"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/e992d68b8636797327a618cd9236a749.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-387b11d4a8f2f8b021e2318b6e2e0bc7"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/e992d68b8636797327a618cd9236a749.png"></a></li>
</ol>
<h2 id="ä½¿ç”¨åˆ†è¯å™¨è¿›è¡Œé¢„å¤„ç†">ä½¿ç”¨åˆ†è¯å™¨è¿›è¡Œé¢„å¤„ç†</h2>
<p>å› ä¸ºç¥ç»ç½‘ç»œæ¨¡å‹æ— æ³•ç›´æ¥å¤„ç†æ–‡æœ¬ï¼Œå› æ­¤é¦–å…ˆéœ€è¦é€šè¿‡<strong>é¢„å¤„ç†</strong>ç¯èŠ‚å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ•°å­—ã€‚å…·ä½“åœ°ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨æ¯ä¸ªæ¨¡å‹å¯¹åº”çš„åˆ†è¯å™¨ (tokenizer) æ¥è¿›è¡Œï¼š</p>
<ol>
<li>å°†è¾“å…¥åˆ‡åˆ†ä¸ºè¯è¯­ã€å­è¯æˆ–è€…ç¬¦å·ï¼ˆä¾‹å¦‚æ ‡ç‚¹ç¬¦å·ï¼‰ï¼Œç»Ÿç§°ä¸º <strong>tokens</strong>ï¼›</li>
<li>æ ¹æ®æ¨¡å‹çš„è¯è¡¨å°†æ¯ä¸ª token æ˜ å°„åˆ°å¯¹åº”çš„ token ç¼–å·ï¼ˆå°±æ˜¯ä¸€ä¸ªæ•°å­—ï¼‰ï¼›</li>
<li>æ ¹æ®æ¨¡å‹çš„éœ€è¦ï¼Œæ·»åŠ ä¸€äº›é¢å¤–çš„è¾“å…¥ã€‚</li>
</ol>
<p>æˆ‘ä»¬å¯¹è¾“å…¥æ–‡æœ¬çš„é¢„å¤„ç†éœ€è¦ä¸æ¨¡å‹è‡ªèº«é¢„è®­ç»ƒæ—¶çš„æ“ä½œå®Œå…¨ä¸€è‡´ï¼Œåªæœ‰è¿™æ ·æ¨¡å‹æ‰å¯ä»¥æ­£å¸¸åœ°å·¥ä½œã€‚æ³¨æ„ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½æœ‰ç‰¹å®šçš„é¢„å¤„ç†æ“ä½œï¼Œå¦‚æœå¯¹è¦ä½¿ç”¨çš„æ¨¡å‹ä¸ç†Ÿæ‚‰ï¼Œå¯ä»¥é€šè¿‡ <a href="https://huggingface.co/models" rel="external" target="_blank">Model Hub</a> æŸ¥è¯¢ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ <code>AutoTokenizer</code> ç±»å’Œå®ƒçš„ <code>from_pretrained()</code> å‡½æ•°ï¼Œå®ƒå¯ä»¥è‡ªåŠ¨æ ¹æ®æ¨¡å‹ checkpoint åç§°æ¥è·å–å¯¹åº”çš„åˆ†è¯å™¨ã€‚</p>
<p>æƒ…æ„Ÿåˆ†æ pipeline çš„é»˜è®¤ checkpoint æ˜¯ <a href="https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english" rel="external" target="_blank">distilbert-base-uncased-finetuned-sst-2-english</a>ï¼Œä¸‹é¢æˆ‘ä»¬æ‰‹å·¥ä¸‹è½½å¹¶è°ƒç”¨å…¶åˆ†è¯å™¨ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import AutoTokenizer

checkpoint = &#34;distilbert-base-uncased-finetuned-sst-2-english&#34;
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

raw_inputs = [
    &#34;I&#39;ve been waiting for a HuggingFace course my whole life.&#34;,
    &#34;I hate this so much!&#34;,
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=&#34;pt&#34;)
print(inputs)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>{
    &#39;input_ids&#39;: tensor([
        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],
        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,
             0,     0,     0,     0,     0,     0]
    ]), 
    &#39;attention_mask&#39;: tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]
    ])
}</code></pre></div>
<p>å¯ä»¥çœ‹åˆ°ï¼Œè¾“å‡ºä¸­åŒ…å«ä¸¤ä¸ªé”® <code>input_ids</code> å’Œ <code>attention_mask</code>ï¼Œå…¶ä¸­ <code>input_ids</code> å¯¹åº”åˆ†è¯ä¹‹åçš„ tokens æ˜ å°„åˆ°çš„æ•°å­—ç¼–å·åˆ—è¡¨ï¼Œè€Œ <code>attention_mask</code> åˆ™æ˜¯ç”¨æ¥æ ‡è®°å“ªäº› tokens æ˜¯è¢«å¡«å……çš„ï¼ˆè¿™é‡Œâ€œ1â€è¡¨ç¤ºæ˜¯åŸæ–‡ï¼Œâ€œ0â€è¡¨ç¤ºæ˜¯å¡«å……å­—ç¬¦ï¼‰ã€‚</p>
<blockquote>
<p>å…ˆä¸è¦å…³æ³¨ <code>padding</code>ã€<code>truncation</code> è¿™äº›å‚æ•°ï¼Œä»¥åŠ <code>attention_mask</code> é¡¹ï¼Œåé¢æˆ‘ä»¬ä¼šè¯¦ç»†ä»‹ç»:)ã€‚</p></blockquote>
<h2 id="å°†é¢„å¤„ç†å¥½çš„è¾“å…¥é€å…¥æ¨¡å‹">å°†é¢„å¤„ç†å¥½çš„è¾“å…¥é€å…¥æ¨¡å‹</h2>
<p>é¢„è®­ç»ƒæ¨¡å‹çš„ä¸‹è½½æ–¹å¼å’Œåˆ†è¯å™¨ (tokenizer) ç±»ä¼¼ï¼ŒTransformers åŒ…æä¾›äº†ä¸€ä¸ª <code>AutoModel</code> ç±»å’Œå¯¹åº”çš„ <code>from_pretrained()</code> å‡½æ•°ã€‚ä¸‹é¢æˆ‘ä»¬æ‰‹å·¥ä¸‹è½½è¿™ä¸ª distilbert-base æ¨¡å‹ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import AutoModel

checkpoint = &#34;distilbert-base-uncased-finetuned-sst-2-english&#34;
model = AutoModel.from_pretrained(checkpoint)</code></pre></div>
<p>é¢„è®­ç»ƒæ¨¡å‹çš„æœ¬ä½“åªåŒ…å«åŸºç¡€çš„ Transformer æ¨¡å—ï¼Œå¯¹äºç»™å®šçš„è¾“å…¥ï¼Œå®ƒä¼šè¾“å‡ºä¸€äº›ç¥ç»å…ƒçš„å€¼ï¼Œç§°ä¸º hidden states æˆ–è€…ç‰¹å¾ (features)ã€‚å¯¹äº NLP æ¨¡å‹æ¥è¯´ï¼Œå¯ä»¥ç†è§£ä¸ºæ˜¯æ–‡æœ¬çš„é«˜ç»´è¯­ä¹‰è¡¨ç¤ºã€‚è¿™äº› hidden states é€šå¸¸ä¼šè¢«è¾“å…¥åˆ°å…¶ä»–çš„æ¨¡å‹éƒ¨åˆ†ï¼ˆç§°ä¸º headï¼‰ï¼Œä»¥å®Œæˆç‰¹å®šçš„ä»»åŠ¡ï¼Œä¾‹å¦‚é€å…¥åˆ°åˆ†ç±»å¤´ä¸­å®Œæˆæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€‚</p>
<blockquote>
<p>å…¶å®å‰é¢æˆ‘ä»¬ä¸¾ä¾‹çš„æ‰€æœ‰ pipelines éƒ½å…·æœ‰ç±»ä¼¼çš„æ¨¡å‹ç»“æ„ï¼Œåªæ˜¯æ¨¡å‹çš„æœ€åä¸€éƒ¨åˆ†ä¼šä½¿ç”¨ä¸åŒçš„ head ä»¥å®Œæˆå¯¹åº”çš„ä»»åŠ¡ã€‚
<a href="#R-image-6fb70f2240a0b743db0c6df3bc3aa2af" class="lightbox-link"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox figure-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/06666f31d707e8ca43c2b24b7263dfc8.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-6fb70f2240a0b743db0c6df3bc3aa2af"><img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" class="lazy lightbox lightbox-image" loading="lazy" src="/docs/images/content/programming/ai/tools_libraries/transformers/transformers_actions_01.md.images/06666f31d707e8ca43c2b24b7263dfc8.png"></a></p></blockquote>
<h3 id="transformersåº“ç»“æ„">Transformersåº“ç»“æ„</h3>
<p>Transformers åº“å°è£…äº†å¾ˆå¤šä¸åŒçš„ç»“æ„ï¼Œå¸¸è§çš„æœ‰ï¼š</p>
<ul>
<li><code>*Model</code> ï¼ˆè¿”å› hidden statesï¼‰</li>
<li><code>*ForCausalLM</code> ï¼ˆç”¨äºæ¡ä»¶è¯­è¨€æ¨¡å‹ï¼‰ï¼Œæ˜¯ä¸€ç§ç”¨äºå› æœè¯­è¨€æ¨¡å‹çš„Transformeræ¥å£ç±»å‹ã€‚åœ¨Transformeræ¶æ„ä¸­,ForCausalLMæ˜¯ä¸€ä¸ªç‰¹æ®Šçš„æ¨¡å‹å¤´,å®ƒè¢«è®¾è®¡ç”¨äºç”Ÿæˆæ–‡æœ¬,å³ä»å‰ä¸€ä¸ªè¯é¢„æµ‹ä¸‹ä¸€ä¸ªè¯,è¿™ç±»æ¨¡å‹ä¸»è¦ç”¨äºä»¥ä¸‹ä»»åŠ¡ï¼š1.æ ¹æ®å·²æœ‰æ–‡æœ¬ç”Ÿæˆåç»­æ–‡æœ¬ï¼Œä¾‹å¦‚è‡ªåŠ¨å†™ä½œã€å¯¹è¯ç”Ÿæˆç­‰,2.è¯­è¨€å»ºæ¨¡ï¼šé¢„æµ‹ç»™å®šæ–‡æœ¬åºåˆ—ä¸­ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡ã€‚</li>
<li><code>*ForSeq2SeqLM</code>ä»£è¡¨ç”¨äºåºåˆ—åˆ°åºåˆ—ï¼ˆSequence-to-Sequenceï¼‰ä»»åŠ¡çš„è¯­è¨€æ¨¡å‹ã€‚è¿™ç±»æ¨¡å‹é€šå¸¸ç”¨äºä»¥ä¸‹ä»»åŠ¡ï¼š1.æœºå™¨ç¿»è¯‘ï¼šå°†ä¸€ç§è¯­è¨€çš„å¥å­ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€,2.æ–‡æœ¬æ‘˜è¦ï¼šå°†é•¿æ–‡æœ¬ç”Ÿæˆç®€çŸ­çš„æ‘˜è¦,3.é—®ç­”ç³»ç»Ÿï¼šä»ä¸Šä¸‹æ–‡ä¸­ç”Ÿæˆå›ç­”ã€‚ã€‚</li>
<li><code>*ForMaskedLM</code> ï¼ˆç”¨äºé®ç›–è¯­è¨€æ¨¡å‹ï¼‰ï¼Œåœ¨MLMä»»åŠ¡ä¸­,è¾“å…¥åºåˆ—ä¸­çš„æŸäº›è¯ä¼šè¢«éšæœºmaskæ‰,æ¨¡å‹çš„ç›®æ ‡æ˜¯é¢„æµ‹è¿™äº›è¢«maskçš„è¯ã€‚</li>
<li><code>*ForMultipleChoice</code> ï¼ˆç”¨äºå¤šé€‰ä»»åŠ¡ï¼‰</li>
<li><code>*ForQuestionAnswering</code> ï¼ˆç”¨äºè‡ªåŠ¨é—®ç­”ä»»åŠ¡ï¼‰</li>
<li><code>*ForSequenceClassification</code> ï¼ˆç”¨äºæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼‰ï¼Œç±»ä¼¼apiå¦‚ï¼šå›¾åƒåˆ†ç±»ï¼š*ForImageClassificationï¼Œè¾“å‡ºç»´åº¦å¯¹åº”äºæ•´ä¸ªåºåˆ—çš„ç±»åˆ«é¢„æµ‹,å³æ•´ä¸ªè¾“å…¥åºåˆ—åªæœ‰ä¸€ä¸ªç±»åˆ«è¾“å‡ºã€‚</li>
<li><code>*ForTokenClassification</code> ï¼ˆç”¨äº token åˆ†ç±»ä»»åŠ¡ï¼Œä¾‹å¦‚ NERï¼‰ï¼Œè¾“å‡ºç»´åº¦å¯¹åº”äºæ¯ä¸ªtokençš„ç±»åˆ«é¢„æµ‹,å³æ¯ä¸ªè¾“å…¥tokenéƒ½æœ‰ä¸€ä¸ªç±»åˆ«è¾“å‡ºã€‚</li>
</ul>
<h3 id="æ¨¡å—è¾“å‡º">æ¨¡å—è¾“å‡º</h3>
<p>Transformer æ¨¡å—çš„è¾“å‡ºæ˜¯ä¸€ä¸ªç»´åº¦ä¸º (Batch size, Sequence length, Hidden size) çš„ä¸‰ç»´å¼ é‡ï¼Œå…¶ä¸­ Batch size è¡¨ç¤ºæ¯æ¬¡è¾“å…¥çš„æ ·æœ¬ï¼ˆæ–‡æœ¬åºåˆ—ï¼‰æ•°é‡ï¼Œå³æ¯æ¬¡è¾“å…¥å¤šå°‘ä¸ªå¥å­ï¼Œä¸Šä¾‹ä¸­ä¸º 2ï¼›Sequence length è¡¨ç¤ºæ–‡æœ¬åºåˆ—çš„é•¿åº¦ï¼Œå³æ¯ä¸ªå¥å­è¢«åˆ†ä¸ºå¤šå°‘ä¸ª tokenï¼Œä¸Šä¾‹ä¸­ä¸º 16ï¼›Hidden size è¡¨ç¤ºæ¯ä¸€ä¸ª token ç»è¿‡æ¨¡å‹ç¼–ç åçš„è¾“å‡ºå‘é‡ï¼ˆè¯­ä¹‰è¡¨ç¤ºï¼‰çš„ç»´åº¦ã€‚</p>
<blockquote>
<p>é¢„è®­ç»ƒæ¨¡å‹ç¼–ç åçš„è¾“å‡ºå‘é‡çš„ç»´åº¦é€šå¸¸éƒ½å¾ˆå¤§ï¼Œä¾‹å¦‚ Bert æ¨¡å‹ base ç‰ˆæœ¬çš„è¾“å‡ºä¸º 768 ç»´ï¼Œä¸€äº›å¤§æ¨¡å‹çš„è¾“å‡ºç»´åº¦ä¸º 3072 ç”šè‡³æ›´é«˜ã€‚</p></blockquote>
<p>æˆ‘ä»¬å¯ä»¥æ‰“å°å‡ºè¿™é‡Œä½¿ç”¨çš„ distilbert-base æ¨¡å‹çš„è¾“å‡ºç»´åº¦ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import AutoTokenizer, AutoModel

checkpoint = &#34;distilbert-base-uncased-finetuned-sst-2-english&#34;
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModel.from_pretrained(checkpoint)

raw_inputs = [
    &#34;I&#39;ve been waiting for a HuggingFace course my whole life.&#34;,
    &#34;I hate this so much!&#34;,
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=&#34;pt&#34;)
outputs = model(**inputs)
print(outputs.last_hidden_state.shape)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>torch.Size([2, 16, 768])</code></pre></div>
<p>Transformers æ¨¡å‹çš„è¾“å‡ºæ ¼å¼ç±»ä¼¼ <code>namedtuple</code> æˆ–å­—å…¸ï¼Œå¯ä»¥åƒä¸Šé¢é‚£æ ·é€šè¿‡å±æ€§è®¿é—®ï¼Œä¹Ÿå¯ä»¥é€šè¿‡é”®ï¼ˆ<code>outputs[&quot;last_hidden_state&quot;]</code>ï¼‰ï¼Œç”šè‡³ç´¢å¼•è®¿é—®ï¼ˆ<code>outputs[0]</code>ï¼‰ã€‚</p>
<p>å¯¹äºæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼Œå¾ˆæ˜æ˜¾æˆ‘ä»¬æœ€åéœ€è¦ä½¿ç”¨çš„æ˜¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±» headã€‚å› æ­¤ï¼Œå®é™…ä¸Šæˆ‘ä»¬ä¸ä¼šä½¿ç”¨ <code>AutoModel</code> ç±»ï¼Œè€Œæ˜¯ä½¿ç”¨ <code>AutoModelForSequenceClassification</code>ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification

checkpoint = &#34;distilbert-base-uncased-finetuned-sst-2-english&#34;
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

raw_inputs = [
    &#34;I&#39;ve been waiting for a HuggingFace course my whole life.&#34;,
    &#34;I hate this so much!&#34;,
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=&#34;pt&#34;)
outputs = model(**inputs)
print(outputs.logits.shape)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>torch.Size([2, 2])</code></pre></div>
<p>å¯ä»¥çœ‹åˆ°ï¼Œå¯¹äº batch ä¸­çš„æ¯ä¸€ä¸ªæ ·æœ¬ï¼Œæ¨¡å‹éƒ½ä¼šè¾“å‡ºä¸€ä¸ªä¸¤ç»´çš„å‘é‡ï¼ˆæ¯ä¸€ç»´å¯¹åº”ä¸€ä¸ªæ ‡ç­¾ï¼Œpositive æˆ– negativeï¼‰ã€‚</p>
<h2 id="å¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œåå¤„ç†">å¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œåå¤„ç†</h2>
<p>ç”±äºæ¨¡å‹çš„è¾“å‡ºåªæ˜¯ä¸€äº›æ•°å€¼ï¼Œå› æ­¤å¹¶ä¸é€‚åˆäººç±»é˜…è¯»ã€‚ä¾‹å¦‚æˆ‘ä»¬æ‰“å°å‡ºä¸Šé¢ä¾‹å­çš„è¾“å‡ºï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification

checkpoint = &#34;distilbert-base-uncased-finetuned-sst-2-english&#34;
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

raw_inputs = [
    &#34;I&#39;ve been waiting for a HuggingFace course my whole life.&#34;,
    &#34;I hate this so much!&#34;,
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=&#34;pt&#34;)
outputs = model(**inputs)
print(outputs.logits)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>tensor([[-1.5607,  1.6123],
        [ 4.1692, -3.3464]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre></div>
<p>æ¨¡å‹å¯¹ç¬¬ä¸€ä¸ªå¥å­è¾“å‡º [âˆ’1.5607,1.6123]ï¼Œå¯¹ç¬¬äºŒä¸ªå¥å­è¾“å‡º [4.1692,âˆ’3.3464]ï¼Œå®ƒä»¬å¹¶ä¸æ˜¯æ¦‚ç‡å€¼ï¼Œè€Œæ˜¯æ¨¡å‹æœ€åä¸€å±‚è¾“å‡ºçš„ logits å€¼ã€‚è¦å°†ä»–ä»¬è½¬æ¢ä¸ºæ¦‚ç‡å€¼ï¼Œè¿˜éœ€è¦è®©å®ƒä»¬ç»è¿‡ä¸€ä¸ª <a href="https://zh.wikipedia.org/wiki/Softmax%E5%87%BD%E6%95%B0" rel="external" target="_blank">SoftMax</a> å±‚ï¼Œä¾‹å¦‚ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>import torch
predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
print(predictions)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>tensor([[4.0195e-02, 9.5980e-01],
        [9.9946e-01, 5.4418e-04]], grad_fn=&lt;SoftmaxBackward0&gt;)</code></pre></div>
<blockquote>
<p>æ‰€æœ‰ Transformers æ¨¡å‹éƒ½ä¼šè¾“å‡º logits å€¼ï¼Œå› ä¸ºè®­ç»ƒæ—¶çš„æŸå¤±å‡½æ•°é€šå¸¸ä¼šè‡ªåŠ¨ç»“åˆæ¿€æ´»å‡½æ•°ï¼ˆä¾‹å¦‚ SoftMaxï¼‰ä¸å®é™…çš„æŸå¤±å‡½æ•°ï¼ˆä¾‹å¦‚äº¤å‰ç†µ cross entropyï¼‰ã€‚</p></blockquote>
<p>è¿™æ ·æ¨¡å‹çš„é¢„æµ‹ç»“æœå°±æ˜¯å®¹æ˜“ç†è§£çš„æ¦‚ç‡å€¼ï¼šç¬¬ä¸€ä¸ªå¥å­ [0.0402,0.9598]ï¼Œç¬¬äºŒä¸ªå¥å­ [0.9995,0.0005]ã€‚æœ€åï¼Œä¸ºäº†å¾—åˆ°å¯¹åº”çš„æ ‡ç­¾ï¼Œå¯ä»¥è¯»å–æ¨¡å‹ config ä¸­æä¾›çš„ id2label å±æ€§ï¼š</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>print(model.config.id2label)</code></pre></div>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>{0: &#39;NEGATIVE&#39;, 1: &#39;POSITIVE&#39;}</code></pre></div>
<p>äºæ˜¯æˆ‘ä»¬å¯ä»¥å¾—åˆ°æœ€ç»ˆçš„é¢„æµ‹ç»“æœï¼š</p>
<ul>
<li>ç¬¬ä¸€ä¸ªå¥å­: NEGATIVE: 0.0402, POSITIVE: 0.9598</li>
<li>ç¬¬äºŒä¸ªå¥å­: NEGATIVE: 0.9995, POSITIVE: 0.0005</li>
</ul>
<p>æœ¬æ–‡éƒ¨åˆ†æ–‡æœ¬å¼•ç”¨è‡ªï¼šhttps://transformers.run/</p>

  <footer class="footline">
              <i class='fa-fw fas fa-calendar'></i> Sep 18, 2025
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/docs/index.html">
            <div class="logo-title">liaomin416100569åšå®¢</div>
          </a>
        </div>
        <search><form action="/docs/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/docs/index.html"><a class="padding" href="/docs/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="parent " data-nav-id="/docs/programming/index.html"><a class="padding" href="/docs/programming/index.html">ç¼–ç¨‹å¼€å‘</a><ul id="R-subsections-e3fc01b477dbaf64a8f5013a3dab5c5b" class="collapsible-menu">
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/tools_libraries/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/index.html">å·¥å…·åº“</a><ul id="R-subsections-e43804740042696aa314af8cc1e28fa9" class="collapsible-menu">
            <li class="parent alwaysopen " data-nav-id="/docs/programming/ai/tools_libraries/transformers/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/index.html">transformers</a><ul id="R-subsections-c93b786975796f9b9f81f28585ce698d" class="collapsible-menu">
            <li class="" data-nav-id="/docs/programming/ai/tools_libraries/transformers/basic/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/basic/index.html">transformersæ¨¡å‹è¯¦è§£</a></li>
            <li class="" data-nav-id="/docs/programming/ai/tools_libraries/transformers/actions/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/actions/index.html">transformerså®æˆ˜</a></li>
            <li class="active " data-nav-id="/docs/programming/ai/tools_libraries/transformers/transformers_actions_01/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/transformers_actions_01/index.html">Transformerså®æˆ˜01-å¼€ç®±å³ç”¨çš„ pipelines</a></li>
            <li class="" data-nav-id="/docs/programming/ai/tools_libraries/transformers/transformers_actions_02/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/transformers_actions_02/index.html">Transformerså®æˆ˜02-BERTé¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ</a></li>
            <li class="" data-nav-id="/docs/programming/ai/tools_libraries/transformers/transformers_actions_03/index.html"><a class="padding" href="/docs/programming/ai/tools_libraries/transformers/transformers_actions_03/index.html">Transformerså®æˆ˜03-PEFTåº“ä½¿ç”¨LORAæ–¹æ³•å¾®è°ƒVITå›¾åƒåˆ†ç±»ã€‚</a></li></ul></li></ul></li>
            <li class="alwaysopen " data-nav-id="/docs/programming/languages/index.html"><a class="padding" href="/docs/programming/languages/index.html">ç¼–ç¨‹è¯­è¨€</a><ul id="R-subsections-1bbde7fb0c312ba940b425df5a4caf67" class="collapsible-menu"></ul></li>
            <li class="alwaysopen " data-nav-id="/docs/programming/plugins/index.html"><a class="padding" href="/docs/programming/plugins/index.html">æ’ä»¶å¼€å‘</a><ul id="R-subsections-de66f54cff99288ca68bfcb5bb0439ae" class="collapsible-menu"></ul></li></ul></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script src="/docs/js/clipboard/clipboard.min.js?1758265020" defer></script>
    <script src="/docs/js/perfect-scrollbar/perfect-scrollbar.min.js?1758265020" defer></script>
    <script src="/docs/js/theme.js?1758265020" defer></script>
  </body>
</html>
